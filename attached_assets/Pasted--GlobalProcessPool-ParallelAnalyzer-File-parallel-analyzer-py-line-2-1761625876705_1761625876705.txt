問題在GlobalProcessPool 或 ParallelAnalyzer 類本身被間接序列化了。

 根本原因分析
File ".../parallel_analyzer.py", line 216, in analyze_batch
    future = self.global_pool.submit_safe(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
File ".../global_pool.py", line 136, in submit_safe
    return executor.submit(func, *args, **kwargs)
...
TypeError: cannot pickle '_thread.lock' object

關鍵點：
* 錯誤發生在 executor.submit(func, *args, **kwargs)
* 但您說 func = _analyze_single_symbol_worker（模塊級函數）
* 問題不在 args/kwargs，而在 func 的綁定方式！

最可能的原因：閉包捕獲了類實例
情境重現
即使您定義了模塊級函數，但在調用時可能 意外創建了閉包：

# ❌ 錯誤示範：在類方法內定義 lambda 或 partial
class ParallelAnalyzer:
    def analyze_batch(self, symbols):
        # 這會創建閉包，捕獲 self（包含 logger、lock 等）
        func = lambda symbol: _analyze_single_symbol_worker(symbol, self.config_dict)
        future = self.global_pool.submit_safe(func, symbol)  # ← 錯誤！
或：

# ❌ 錯誤示範：使用 functools.partial 捕獲 self
from functools import partial

class ParallelAnalyzer:
    def analyze_batch(self, symbols):
        func = partial(_analyze_single_symbol_worker, config_dict=self.config_dict)
        future = self.global_pool.submit_safe(func, symbol)  # ← 錯誤！

partial 或 lambda 會捕獲外部變量（如 self.config_dict），但若 self 被間接引用，就會序列化整個類！ 

✅ 正確做法：所有參數必須顯式傳遞
修正後的 ParallelAnalyzer.analyze_batch
# src/services/parallel_analyzer.py

# ✅ 模塊級工作函數（無閉包）
def _analyze_single_symbol_worker(symbol: str, config_dict: dict, market_data: dict):
    """獨立函數，不依賴任何類或模塊級狀態"""
    # 在子進程內創建 logger
    import logging
    logger = logging.getLogger(f"worker.{symbol}")
    
    try:
        # 重建 DataFrame
        reconstructed_data = {}
        for tf_key, tf_dict in market_data.items():
            df = pd.DataFrame(tf_dict['data'])
            df.index = tf_dict['index']
            reconstructed_data[tf_key] = df
        
        # 執行分析（使用 config_dict）
        from src.strategies.strategy_factory import StrategyFactory
        strategy = StrategyFactory.create("hybrid")
        signals = strategy.generate_signals(reconstructed_data, config_dict)
        return signals
    except Exception as e:
        logger.error(f"Worker failed for {symbol}: {e}")
        return []

class ParallelAnalyzer:
    def __init__(self, config: Config):
        self.config = config
        self.global_pool = GlobalProcessPool()

    def analyze_batch(self, symbols: List[str], all_market_data: Dict[str, Dict]):
        futures = []
        for symbol in symbols:
            # ✅ 顯式傳遞所有參數（無閉包！）
            config_dict = {
                'MIN_CONFIDENCE': self.config.MIN_CONFIDENCE,
                'ENABLE_SELF_LEARNING': self.config.ENABLE_SELF_LEARNING,
                # ... 只包含基本類型
            }
            market_data = all_market_data[symbol]  # 已轉為 dict
            
            # ✅ 直接傳遞函數 + 參數（無 lambda, 無 partial）
            future = self.global_pool.submit_safe(
                _analyze_single_symbol_worker,  # 函數對象
                symbol,                         # args
                config_dict,
                market_data
            )
            futures.append(future)
        
        # 收集結果
        results = []
        for future in futures:
            try:
                result = future.result(timeout=25)
                results.extend(result)
            except Exception as e:
                logger.error(f"Future failed: {e}")
        return results


🔧 額外檢查：GlobalProcessPool.submit_safe 實現
確保 submit_safe 沒有包裝函數：
# src/core/global_pool.py
class GlobalProcessPool:
    def __init__(self):
        self.io_pool = ProcessPoolExecutor(max_workers=12)

    def submit_safe(self, func, *args, **kwargs):
        # ✅ 直接提交，不要包裝！
        return self.io_pool.submit(func, *args, **kwargs)

❌ 錯誤示範： 
def submit_safe(self, func, *args, **kwargs):
    def wrapper():
        return func(*args, **kwargs)
    return self.io_pool.submit(wrapper)  # ← 會序列化 wrapper 閉包！

🛠️ 調試技巧：強制驗證可序列化性
在提交前加 debug 檢查：

import pickle

# 在 analyze_batch 中
try:
    pickle.dumps(_analyze_single_symbol_worker)
    pickle.dumps(config_dict)
    pickle.dumps(market_data)
    print("✅ All arguments are serializable")
except Exception as e:
    print(f"❌ Serialization failed: {e}")
    raise

最終建議
1. 刪除所有 lambda 和 functools.partial
2. 工作函數只接受基本類型（str, int, float, bool, list, dict）
3. 在子進程內重建所有複雜對象（logger, DataFrame, strategy）
4. 用 pickle.dumps() 做提交前驗證

💡 多進程的黃金法則： 「子進程應該像一個全新啟動的程式，不依賴主進程的任何狀態」 

如果按照上述修正，cannot pickle '_thread.lock' object 錯誤 一定會消失。

