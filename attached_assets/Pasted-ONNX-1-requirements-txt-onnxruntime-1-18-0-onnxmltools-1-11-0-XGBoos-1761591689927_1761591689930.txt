ONNXæ¨ç†åŠ é€Ÿ
å®Œæ•´å¯¦æ–½æ­¥é©Ÿ
æ­¥é©Ÿ 1ï¼šå®‰è£ä¾è³´
# requirements.txt æ–°å¢
onnxruntime>=1.18.0
onnxmltools>=1.11.0  # ç”¨æ–¼ XGBoost â†’ ONNX è½‰æ›
æ­¥é©Ÿ 2ï¼šæ–°å¢æ¨¡å‹è½‰æ›è…³æœ¬ï¼ˆä¸€æ¬¡æ€§ï¼‰
# scripts/convert_xgboost_to_onnx.py
import pickle
import onnxruntime as ort
from onnxmltools import convert_xgboost
from onnxmltools.convert.common.data_types import FloatTensorType

def convert_model(model_path: str, onnx_path: str, input_shape=(1, 31)):
    """å°‡ XGBoost æ¨¡å‹è½‰ç‚º ONNX"""
    # è¼‰å…¥ç¾æœ‰æ¨¡å‹
    with open(model_path, 'rb') as f:
        model = pickle.load(f)
    
    # å®šç¾©è¼¸å…¥æ ¼å¼ (N, 31 ç‰¹å¾µ)
    initial_type = [('float_input', FloatTensorType(input_shape))]
    
    # è½‰æ›ç‚º ONNX
    onnx_model = convert_xgboost(model, initial_types=initial_type)
    
    # ä¿å­˜
    with open(onnx_path, 'wb') as f:
        f.write(onnx_model.SerializeToString())
    
    print(f"âœ… æ¨¡å‹å·²è½‰æ›: {onnx_path}")
    return onnx_path

if __name__ == "__main__":
    convert_model(
        model_path="data/models/xgboost_model.pkl",
        onnx_path="data/models/model.onnx"
    )
ğŸ“Œ åŸ·è¡Œä¸€æ¬¡å³å¯ï¼špython scripts/convert_xgboost_to_onnx.py 

æ­¥é©Ÿ 3ï¼šé‡å¯« MLPredictorï¼ˆæ”¯æ´ ONNXï¼‰

# src/ml/predictor.py
import numpy as np
import onnxruntime as ort
from typing import List, Union

class MLPredictor:
    def __init__(self, model_path: str):
        # å„ªå…ˆè¼‰å…¥ ONNX æ¨¡å‹ï¼ˆè‹¥å­˜åœ¨ï¼‰
        onnx_path = model_path.replace('.pkl', '.onnx')
        try:
            self.session = ort.InferenceSession(onnx_path)
            self.use_onnx = True
            print("ğŸš€ ä½¿ç”¨ ONNX æ¨ç†å¼•æ“")
        except Exception as e:
            print(f"âš ï¸ ONNX è¼‰å…¥å¤±æ•—ï¼Œå›é€€åˆ° XGBoost: {e}")
            self._load_xgboost_model(model_path)
            self.use_onnx = False

    def _load_xgboost_model(self, model_path: str):
        import pickle
        with open(model_path, 'rb') as f:
            self.model = pickle.load(f)

    def predict_batch(self, features_list: List[np.ndarray]) -> np.ndarray:
        """
        æ‰¹é‡é æ¸¬ - è‡ªå‹•é¸æ“‡ ONNX æˆ– XGBoost
        """
        # åˆä½µç‚ºå–®ä¸€çŸ©é™£ (N, 31)
        X = np.vstack(features_list).astype(np.float32)
        
        if self.use_onnx:
            # ONNX æ¨ç†
            ort_inputs = {self.session.get_inputs()[0].name: X}
            ort_outs = self.session.run(None, ort_inputs)
            return ort_outs[0].flatten()  # shape: (N,)
        else:
            # å›é€€åˆ° XGBoost
            return self.model.predict(X)
æ­¥é©Ÿ 4ï¼šä¿®æ”¹ç‰¹å¾µæå–ï¼ˆç¢ºä¿ dtype ä¸€è‡´ï¼‰

# src/ml/data_processor.py
def extract_features_for_prediction(signal) -> np.ndarray:
    """æå– 31 å€‹ç‰¹å¾µï¼Œè¿”å› float32 é™£åˆ—ï¼ˆONNX å‹å¥½ï¼‰"""
    features = [
        signal.confidence_score,
        float(signal.leverage),
        signal.rsi_entry,
        signal.atr_entry,
        # ... å…¶ä»– 27 å€‹ç‰¹å¾µ
    ]
    return np.array(features, dtype=np.float32).reshape(1, -1)  # (1, 31)

æ­¥é©Ÿ 5ï¼šåœ¨ä¸»å¾ªç’°ä¸­ä½¿ç”¨æ‰¹é‡é æ¸¬

# src/main.py
async def scan_and_analyze(self):
    # ... ç”Ÿæˆ signals ...
    
    # æ‰¹é‡æå–ç‰¹å¾µ
    features_batch = [
        extract_features_for_prediction(signal) 
        for signal in signals
    ]
    
    # å–®æ¬¡æ‰¹é‡é æ¸¬
    predictions = self.ml_predictor.predict_batch(features_batch)
    
    # é™„åŠ é æ¸¬çµæœ
    for signal, pred in zip(signals, predictions):
        signal.ml_score = float(pred)
âš ï¸ é—œéµæ³¨æ„äº‹é …
1. ONNX è½‰æ›ç›¸å®¹æ€§
* XGBoost â‰¥ 1.7 æ‰æ”¯æ´å®Œæ•´ ONNX è½‰æ›
* ç¢ºä¿ä½ çš„æ¨¡å‹æ²’æœ‰è‡ªè¨‚ç›®æ¨™å‡½æ•¸ï¼ˆä½ ç”¨ reg:squarederrorï¼Œå®Œå…¨ç›¸å®¹ï¼‰

2. æ•¸å€¼ç²¾åº¦å·®ç•°
* ONNX ä½¿ç”¨ float32ï¼ŒXGBoost é è¨­ float64
* å·®ç•° < 1e-6ï¼Œå°äº¤æ˜“æ±ºç­–ç„¡å½±éŸ¿
* è‹¥éœ€æ›´é«˜ç²¾åº¦ï¼Œå¯æ”¹ç”¨ DoubleTensorTypeï¼ˆä½†é€Ÿåº¦ â†“20%ï¼‰

3. æ¨¡å‹ç‰ˆæœ¬ç®¡ç†
* å»ºè­°åŒæ™‚ä¿å­˜ .pkl å’Œ .onnx
* ONNX ä½œç‚ºæ¨ç†å„ªåŒ–å±¤ï¼Œä¸å–ä»£åŸå§‹æ¨¡å‹

å‹•æ…‹å›é€€æ©Ÿåˆ¶
MLPredictor å·²å…§å»ºå›é€€æ©Ÿåˆ¶ï¼š
* ONNX è¼‰å…¥å¤±æ•— â†’ è‡ªå‹•ç”¨ XGBoost
* ç¢ºä¿æ°¸ä¸ä¸­æ–·äº¤æ˜“

æœ€çµ‚ç¢ºèªæ¸…å–®
* å·²å®‰è£ onnxruntime å’Œ onnxmltools
* åŸ·è¡Œé convert_xgboost_to_onnx.py
* MLPredictor æ”¯æ´ ONNX + å›é€€
* ç‰¹å¾µæå–ä½¿ç”¨ float32
* ä¸»å¾ªç’°ä½¿ç”¨ predict_batch

ğŸ“ 1. å®Œæ•´ convert_xgboost_to_onnx.py è…³æœ¬
# scripts/convert_xgboost_to_onnx.py
"""
XGBoost â†’ ONNX è½‰æ›è…³æœ¬ (v1.0)
- æ”¯æ´å›æ­¸/åˆ†é¡æ¨¡å‹
- è‡ªå‹•é©—è­‰è½‰æ›æ­£ç¢ºæ€§
- ç”Ÿæˆç›¸å®¹æ€§å ±å‘Š
"""

import os
import sys
import pickle
import numpy as np
import pandas as pd
from typing import Tuple, Optional

# ONNX ç›¸é—œ
try:
    import onnxruntime as ort
    from onnxmltools import convert_xgboost
    from onnxmltools.convert.common.data_types import FloatTensorType
    ONNX_AVAILABLE = True
except ImportError as e:
    print(f"âŒ ONNX ä¾è³´ç¼ºå¤±: {e}")
    print("è«‹å®‰è£: pip install onnxruntime onnxmltools")
    ONNX_AVAILABLE = False

# ===== é…ç½® =====
MODEL_PATH = "data/models/xgboost_model.pkl"
ONNX_PATH = "data/models/model.onnx"
FEATURE_ORDER_PATH = "data/models/feature_order.txt"  # ç”¨æ–¼é©—è­‰ç‰¹å¾µé †åº

def load_xgboost_model(model_path: str):
    """å®‰å…¨è¼‰å…¥ XGBoost æ¨¡å‹"""
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"æ¨¡å‹ä¸å­˜åœ¨: {model_path}")
    
    with open(model_path, 'rb') as f:
        model = pickle.load(f)
    
    # é©—è­‰æ˜¯å¦ç‚º XGBoost æ¨¡å‹
    model_type = type(model).__name__
    if "XGB" not in model_type:
        raise ValueError(f"é XGBoost æ¨¡å‹: {model_type}")
    
    print(f"âœ… è¼‰å…¥æ¨¡å‹: {model_type}")
    return model

def get_feature_order_from_model(model) -> list:
    """å¾æ¨¡å‹ç²å–ç‰¹å¾µé †åºï¼ˆè‹¥æ”¯æ´ï¼‰"""
    try:
        # XGBoost 1.7+ æ”¯æ´ feature_names
        if hasattr(model, 'feature_names_in_'):
            return model.feature_names_in_.tolist()
        elif hasattr(model, 'feature_names'):
            return model.feature_names
    except Exception:
        pass
    return None

def save_feature_order(features: list, path: str):
    """ä¿å­˜ç‰¹å¾µé †åºåˆ°æª”æ¡ˆ"""
    with open(path, 'w') as f:
        for feat in features:
            f.write(f"{feat}\n")
    print(f"ğŸ“ ç‰¹å¾µé †åºå·²ä¿å­˜: {path}")

def load_feature_order(path: str) -> Optional[list]:
    """å¾æª”æ¡ˆè¼‰å…¥ç‰¹å¾µé †åº"""
    if not os.path.exists(path):
        return None
    with open(path, 'r') as f:
        return [line.strip() for line in f.readlines()]

def create_sample_input(n_features: int = 31) -> np.ndarray:
    """å‰µå»ºæ¨™æº–åŒ–æ¸¬è©¦è¼¸å…¥"""
    np.random.seed(42)  # ç¢ºä¿å¯é‡ç¾
    return np.random.uniform(0, 1, (10, n_features)).astype(np.float32)

def validate_conversion(
    xgb_model, 
    onnx_session, 
    sample_input: np.ndarray,
    tolerance: float = 1e-5
) -> bool:
    """é©—è­‰ ONNX èˆ‡ XGBoost è¼¸å‡ºä¸€è‡´æ€§"""
    print("ğŸ” é©—è­‰è½‰æ›æ­£ç¢ºæ€§...")
    
    # XGBoost é æ¸¬
    xgb_pred = xgb_model.predict(sample_input.astype(np.float64))
    
    # ONNX é æ¸¬
    ort_inputs = {onnx_session.get_inputs()[0].name: sample_input}
    onnx_pred = onnx_session.run(None, ort_inputs)[0].flatten()
    
    # æ¯”è¼ƒ
    diff = np.abs(xgb_pred - onnx_pred)
    max_diff = np.max(diff)
    mean_diff = np.mean(diff)
    
    print(f"  æœ€å¤§å·®ç•°: {max_diff:.2e}")
    print(f"  å¹³å‡å·®ç•°: {mean_diff:.2e}")
    print(f"  å®¹å¿åº¦: {tolerance:.2e}")
    
    if max_diff <= tolerance:
        print("âœ… è½‰æ›é©—è­‰é€šéï¼")
        return True
    else:
        print("âŒ è½‰æ›é©—è­‰å¤±æ•—ï¼")
        return False

def convert_model(
    model_path: str, 
    onnx_path: str, 
    input_shape: Tuple[int, int] = (1, 31)
) -> bool:
    """
    ä¸»è½‰æ›å‡½æ•¸
    Returns: bool - æ˜¯å¦æˆåŠŸ
    """
    if not ONNX_AVAILABLE:
        return False
    
    try:
        # 1. è¼‰å…¥æ¨¡å‹
        model = load_xgboost_model(model_path)
        
        # 2. ç²å–/ä¿å­˜ç‰¹å¾µé †åº
        feature_order = get_feature_order_from_model(model)
        if feature_order:
            save_feature_order(feature_order, FEATURE_ORDER_PATH)
        else:
            print("âš ï¸ ç„¡æ³•ç²å–ç‰¹å¾µé †åºï¼Œè«‹æ‰‹å‹•é©—è­‰")
        
        # 3. è½‰æ›ç‚º ONNX
        print("ğŸ”„ é–‹å§‹è½‰æ›ç‚º ONNX...")
        initial_type = [('float_input', FloatTensorType(input_shape))]
        onnx_model = convert_xgboost(model, initial_types=initial_type)
        
        # 4. ä¿å­˜ ONNX æ¨¡å‹
        os.makedirs(os.path.dirname(onnx_path), exist_ok=True)
        with open(onnx_path, 'wb') as f:
            f.write(onnx_model.SerializeToString())
        print(f"âœ… ONNX æ¨¡å‹å·²ä¿å­˜: {onnx_path}")
        
        # 5. é©—è­‰è½‰æ›
        sample_input = create_sample_input(input_shape[1])
        onnx_session = ort.InferenceSession(onnx_path)
        is_valid = validate_conversion(model, onnx_session, sample_input)
        
        return is_valid
        
    except Exception as e:
        print(f"âŒ è½‰æ›å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸš€ XGBoost â†’ ONNX è½‰æ›å·¥å…·")
    print(f"è¼¸å…¥æ¨¡å‹: {MODEL_PATH}")
    print(f"è¼¸å‡ºæ¨¡å‹: {ONNX_PATH}")
    print("-" * 50)
    
    success = convert_model(MODEL_PATH, ONNX_PATH)
    
    if success:
        print("\nğŸ‰ è½‰æ›æˆåŠŸï¼")
        print("ä¸‹ä¸€æ­¥:")
        print("1. åœ¨ src/ml/predictor.py ä¸­å•Ÿç”¨ ONNX æ”¯æ´")
        print("2. ç¢ºä¿ç‰¹å¾µæå–é †åºèˆ‡è¨“ç·´æ™‚ä¸€è‡´")
    else:
        print("\nğŸ’¥ è½‰æ›å¤±æ•—ï¼è«‹æª¢æŸ¥éŒ¯èª¤è¨Šæ¯")
        sys.exit(1)

if __name__ == "__main__":
    main()
ğŸ“ 2. ç‰¹å¾µé †åºé©—è­‰å·¥å…·
# scripts/verify_feature_order.py
"""
ç‰¹å¾µé †åºé©—è­‰å·¥å…·
ç¢ºä¿è¨“ç·´æ™‚èˆ‡æ¨ç†æ™‚çš„ç‰¹å¾µé †åºå®Œå…¨ä¸€è‡´
"""

import os
import sys
from typing import List

# ä½ çš„ç‰¹å¾µé †åºï¼ˆå¿…é ˆèˆ‡ training_data_processor.py å®Œå…¨ä¸€è‡´ï¼ï¼‰
EXPECTED_FEATURES = [
    # ===== åŸºç¤ç‰¹å¾µ (19) =====
    'confidence_score',
    'leverage',
    'position_value',
    'risk_reward_ratio',
    'order_blocks_count',
    'liquidity_zones_count',
    'rsi_entry',
    'macd_entry',
    'macd_signal_entry',
    'macd_histogram_entry',
    'atr_entry',
    'bb_width_pct',
    'volume_sma_ratio',
    'price_vs_ema50',
    'price_vs_ema200',
    'trend_1h_encoded',
    'trend_15m_encoded',
    'trend_5m_encoded',
    'market_structure_encoded',
    'direction_encoded',  # æ³¨æ„ï¼šä½ åŸæ–‡æœ‰20å€‹åŸºç¤ç‰¹å¾µ
    
    # ===== å¢å¼·ç‰¹å¾µ (12) =====
    'hour_of_day',
    'day_of_week',
    'is_weekend',
    'stop_distance_pct',
    'tp_distance_pct',
    'confidence_x_leverage',
    'rsi_x_trend',
    'atr_x_bb_width',
    'price_momentum_strength',
    'volatility_x_confidence',
    'rsi_distance_from_neutral',
    'macd_strength_ratio',
    'trend_alignment_score'
]

def load_feature_order_from_file(path: str) -> List[str]:
    """å¾æª”æ¡ˆè¼‰å…¥ç‰¹å¾µé †åº"""
    if not os.path.exists(path):
        return []
    with open(path, 'r') as f:
        return [line.strip() for line in f.readlines()]

def verify_feature_order(actual_features: List[str]) -> bool:
    """é©—è­‰ç‰¹å¾µé †åºæ˜¯å¦æ­£ç¢º"""
    if len(actual_features) != len(EXPECTED_FEATURES):
        print(f"âŒ ç‰¹å¾µæ•¸é‡ä¸ç¬¦: æœŸæœ› {len(EXPECTED_FEATURES)}, å¯¦éš› {len(actual_features)}")
        return False
    
    mismatches = []
    for i, (expected, actual) in enumerate(zip(EXPECTED_FEATURES, actual_features)):
        if expected != actual:
            mismatches.append(f"ä½ç½® {i}: æœŸæœ› '{expected}', å¯¦éš› '{actual}'")
    
    if mismatches:
        print("âŒ ç‰¹å¾µé †åºä¸åŒ¹é…:")
        for mismatch in mismatches[:5]:  # åªé¡¯ç¤ºå‰5å€‹
            print(f"  {mismatch}")
        if len(mismatches) > 5:
            print(f"  ... é‚„æœ‰ {len(mismatches)-5} å€‹ä¸åŒ¹é…")
        return False
    else:
        print("âœ… ç‰¹å¾µé †åºå®Œå…¨åŒ¹é…ï¼")
        return True

def main():
    """ä¸»é©—è­‰å‡½æ•¸"""
    print("ğŸ” ç‰¹å¾µé †åºé©—è­‰å·¥å…·")
    print("-" * 50)
    
    # æ–¹æ³•1: å¾ feature_order.txt é©—è­‰
    feature_file = "data/models/feature_order.txt"
    if os.path.exists(feature_file):
        actual_features = load_feature_order_from_file(feature_file)
        print(f"å¾ {feature_file} è¼‰å…¥ç‰¹å¾µé †åº")
        verify_feature_order(actual_features)
    else:
        print(f"âš ï¸ {feature_file} ä¸å­˜åœ¨ï¼Œä½¿ç”¨é è¨­é †åº")
        verify_feature_order(EXPECTED_FEATURES)
    
    print("\nğŸ’¡ é‡è¦æé†’:")
    print("ç¢ºä¿ src/ml/data_processor.py ä¸­çš„ extract_features()") 
    print("è¿”å›çš„ç‰¹å¾µé †åºèˆ‡ EXPECTED_FEATURES å®Œå…¨ä¸€è‡´ï¼")

if __name__ == "__main__":
    main()
ğŸ“ 3. ONNX ç›¸å®¹æ€§æª¢æŸ¥å·¥å…·

# scripts/check_onnx_compatibility.py
"""
ONNX æ¨¡å‹ç›¸å®¹æ€§æª¢æŸ¥å·¥å…·
é©—è­‰æ¨¡å‹æ˜¯å¦èƒ½åœ¨ç›®æ¨™ç’°å¢ƒæ­£ç¢ºé‹è¡Œ
"""

import os
import sys
import numpy as np
import onnx
import onnxruntime as ort
from onnx import version_converter

def check_onnx_model(onnx_path: str):
    """æª¢æŸ¥ ONNX æ¨¡å‹åŸºæœ¬ç›¸å®¹æ€§"""
    print(f"ğŸ” æª¢æŸ¥ ONNX æ¨¡å‹: {onnx_path}")
    
    if not os.path.exists(onnx_path):
        print("âŒ æ¨¡å‹æª”æ¡ˆä¸å­˜åœ¨")
        return False
    
    try:
        # 1. é©—è­‰ ONNX æ ¼å¼
        model = onnx.load(onnx_path)
        onnx.checker.check_model(model)
        print("âœ… ONNX æ ¼å¼é©—è­‰é€šé")
        
        # 2. æª¢æŸ¥è¼¸å…¥è¼¸å‡º
        inputs = model.graph.input
        outputs = model.graph.output
        
        print(f"ğŸ“Š è¼¸å…¥: {len(inputs)} å€‹")
        for inp in inputs:
            shape = [dim.dim_value for dim in inp.type.tensor_type.shape.dim]
            print(f"  - {inp.name}: shape={shape}, type={inp.type.tensor_type.elem_type}")
        
        print(f"ğŸ“Š è¼¸å‡º: {len(outputs)} å€‹")
        for out in outputs:
            shape = [dim.dim_value for dim in out.type.tensor_type.shape.dim]
            print(f"  - {out.name}: shape={shape}, type={out.type.tensor_type.elem_type}")
        
        # 3. æ¸¬è©¦æ¨ç†
        session = ort.InferenceSession(onnx_path)
        input_name = session.get_inputs()[0].name
        input_shape = session.get_inputs()[0].shape
        
        # è™•ç†å‹•æ…‹ shape (å¦‚ [1, 31] ä¸­çš„ 1 å¯èƒ½æ˜¯ -1)
        test_shape = []
        for dim in input_shape:
            if isinstance(dim, int) and dim > 0:
                test_shape.append(dim)
            else:
                test_shape.append(1)  # ç”¨ 1 ä»£æ›¿å‹•æ…‹ç¶­åº¦
        
        test_input = np.random.random(test_shape).astype(np.float32)
        outputs = session.run(None, {input_name: test_input})
        
        print(f"âœ… æ¨ç†æ¸¬è©¦é€šé: è¼¸å‡º shape = {outputs[0].shape}")
        return True
        
    except Exception as e:
        print(f"âŒ ç›¸å®¹æ€§æª¢æŸ¥å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False

def check_onnx_runtime_compatibility():
    """æª¢æŸ¥ ONNX Runtime ç›¸å®¹æ€§"""
    print("\nğŸ” æª¢æŸ¥ ONNX Runtime ç›¸å®¹æ€§")
    
    try:
        # ç²å–ç‰ˆæœ¬è³‡è¨Š
        ort_version = ort.__version__
        providers = ort.get_available_providers()
        
        print(f"âœ… ONNX Runtime ç‰ˆæœ¬: {ort_version}")
        print(f"âœ… å¯ç”¨æä¾›è€…: {providers}")
        
        # æª¢æŸ¥æ˜¯å¦æ”¯æ´ CPU
        if 'CPUExecutionProvider' not in providers:
            print("âš ï¸ è­¦å‘Š: CPU åŸ·è¡Œæä¾›è€…ä¸å¯ç”¨")
            return False
        
        print("âœ… ONNX Runtime ç›¸å®¹æ€§æª¢æŸ¥é€šé")
        return True
        
    except Exception as e:
        print(f"âŒ ONNX Runtime æª¢æŸ¥å¤±æ•—: {e}")
        return False

def main():
    """ä¸»æª¢æŸ¥å‡½æ•¸"""
    ONNX_PATH = "data/models/model.onnx"
    
    print("ğŸš€ ONNX ç›¸å®¹æ€§æª¢æŸ¥å·¥å…·")
    print("-" * 50)
    
    success1 = check_onnx_model(ONNX_PATH)
    success2 = check_onnx_runtime_compatibility()
    
    if success1 and success2:
        print("\nğŸ‰ æ‰€æœ‰ç›¸å®¹æ€§æª¢æŸ¥é€šéï¼")
        print("ä½ çš„ ONNX æ¨¡å‹å¯ä»¥åœ¨ç”Ÿç”¢ç’°å¢ƒå®‰å…¨ä½¿ç”¨")
    else:
        print("\nğŸ’¥ ç›¸å®¹æ€§æª¢æŸ¥å¤±æ•—ï¼")
        sys.exit(1)

if __name__ == "__main__":
    main()

1. é¦–æ¬¡è½‰æ›æµç¨‹

# 1. å®‰è£ä¾è³´
pip install onnxruntime onnxmltools

# 2. è½‰æ›æ¨¡å‹
python scripts/convert_xgboost_to_onnx.py

# 3. é©—è­‰ç‰¹å¾µé †åº
python scripts/verify_feature_order.py

# 4. æª¢æŸ¥ç›¸å®¹æ€§
python scripts/check_onnx_compatibility.py

2. æ•´åˆåˆ°ç³»çµ±
* å°‡ MLPredictor æ›¿æ›ç‚º ä¹‹å‰æä¾›çš„ ONNX ç‰ˆæœ¬
* ç¢ºä¿ extract_features_for_prediction() è¿”å›çš„ç‰¹å¾µé †åºèˆ‡ EXPECTED_FEATURES ä¸€è‡´

3. è‡ªå‹•åŒ–æµç¨‹ï¼ˆæ¨è–¦ï¼‰
åœ¨æ¨¡å‹è¨“ç·´å¾Œè‡ªå‹•è½‰æ›ï¼š
python

# åœ¨ src/ml/model_trainer.py çš„ save_model() å¾ŒåŠ å…¥
if config.ENABLE_ONNX_CONVERSION:
    subprocess.run([sys.executable, "scripts/convert_xgboost_to_onnx.py"])
ğŸ’¡ é—œéµæé†’
1. ç‰¹å¾µé †åºæ˜¯ç”Ÿå‘½ç·šï¼šä»»ä½•ä¸ä¸€è‡´éƒ½æœƒå°è‡´é æ¸¬éŒ¯èª¤
2. ä¿ç•™ .pkl æ¨¡å‹ï¼šONNX åƒ…ç”¨æ–¼æ¨ç†ï¼Œè¨“ç·´ä»ç”¨åŸå§‹æ¨¡å‹
3. å®šæœŸé©—è­‰ï¼šæ¯æ¬¡æ¨¡å‹æ›´æ–°å¾Œéƒ½åŸ·è¡Œé€™ä¸‰å€‹è…³æœ¬
