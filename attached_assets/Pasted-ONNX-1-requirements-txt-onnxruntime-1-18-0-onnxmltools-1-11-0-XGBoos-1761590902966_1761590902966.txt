ONNX推理加速
完整實施步驟
步驟 1：安裝依賴
# requirements.txt 新增
onnxruntime>=1.18.0
onnxmltools>=1.11.0  # 用於 XGBoost → ONNX 轉換
步驟 2：新增模型轉換腳本（一次性）
# scripts/convert_xgboost_to_onnx.py
import pickle
import onnxruntime as ort
from onnxmltools import convert_xgboost
from onnxmltools.convert.common.data_types import FloatTensorType

def convert_model(model_path: str, onnx_path: str, input_shape=(1, 31)):
    """將 XGBoost 模型轉為 ONNX"""
    # 載入現有模型
    with open(model_path, 'rb') as f:
        model = pickle.load(f)
    
    # 定義輸入格式 (N, 31 特徵)
    initial_type = [('float_input', FloatTensorType(input_shape))]
    
    # 轉換為 ONNX
    onnx_model = convert_xgboost(model, initial_types=initial_type)
    
    # 保存
    with open(onnx_path, 'wb') as f:
        f.write(onnx_model.SerializeToString())
    
    print(f"✅ 模型已轉換: {onnx_path}")
    return onnx_path

if __name__ == "__main__":
    convert_model(
        model_path="data/models/xgboost_model.pkl",
        onnx_path="data/models/model.onnx"
    )
📌 執行一次即可：python scripts/convert_xgboost_to_onnx.py 

步驟 3：重寫 MLPredictor（支援 ONNX）

# src/ml/predictor.py
import numpy as np
import onnxruntime as ort
from typing import List, Union

class MLPredictor:
    def __init__(self, model_path: str):
        # 優先載入 ONNX 模型（若存在）
        onnx_path = model_path.replace('.pkl', '.onnx')
        try:
            self.session = ort.InferenceSession(onnx_path)
            self.use_onnx = True
            print("🚀 使用 ONNX 推理引擎")
        except Exception as e:
            print(f"⚠️ ONNX 載入失敗，回退到 XGBoost: {e}")
            self._load_xgboost_model(model_path)
            self.use_onnx = False

    def _load_xgboost_model(self, model_path: str):
        import pickle
        with open(model_path, 'rb') as f:
            self.model = pickle.load(f)

    def predict_batch(self, features_list: List[np.ndarray]) -> np.ndarray:
        """
        批量預測 - 自動選擇 ONNX 或 XGBoost
        """
        # 合併為單一矩陣 (N, 31)
        X = np.vstack(features_list).astype(np.float32)
        
        if self.use_onnx:
            # ONNX 推理
            ort_inputs = {self.session.get_inputs()[0].name: X}
            ort_outs = self.session.run(None, ort_inputs)
            return ort_outs[0].flatten()  # shape: (N,)
        else:
            # 回退到 XGBoost
            return self.model.predict(X)
步驟 4：修改特徵提取（確保 dtype 一致）

# src/ml/data_processor.py
def extract_features_for_prediction(signal) -> np.ndarray:
    """提取 31 個特徵，返回 float32 陣列（ONNX 友好）"""
    features = [
        signal.confidence_score,
        float(signal.leverage),
        signal.rsi_entry,
        signal.atr_entry,
        # ... 其他 27 個特徵
    ]
    return np.array(features, dtype=np.float32).reshape(1, -1)  # (1, 31)

步驟 5：在主循環中使用批量預測

# src/main.py
async def scan_and_analyze(self):
    # ... 生成 signals ...
    
    # 批量提取特徵
    features_batch = [
        extract_features_for_prediction(signal) 
        for signal in signals
    ]
    
    # 單次批量預測
    predictions = self.ml_predictor.predict_batch(features_batch)
    
    # 附加預測結果
    for signal, pred in zip(signals, predictions):
        signal.ml_score = float(pred)
⚠️ 關鍵注意事項
1. ONNX 轉換相容性
* XGBoost ≥ 1.7 才支援完整 ONNX 轉換
* 確保你的模型沒有自訂目標函數（你用 reg:squarederror，完全相容）

2. 數值精度差異
* ONNX 使用 float32，XGBoost 預設 float64
* 差異 < 1e-6，對交易決策無影響
* 若需更高精度，可改用 DoubleTensorType（但速度 ↓20%）

3. 模型版本管理
* 建議同時保存 .pkl 和 .onnx
* ONNX 作為推理優化層，不取代原始模型

動態回退機制
MLPredictor 已內建回退機制：
* ONNX 載入失敗 → 自動用 XGBoost
* 確保永不中斷交易

最終確認清單
* 已安裝 onnxruntime 和 onnxmltools
* 執行過 convert_xgboost_to_onnx.py
* MLPredictor 支援 ONNX + 回退
* 特徵提取使用 float32
* 主循環使用 predict_batch