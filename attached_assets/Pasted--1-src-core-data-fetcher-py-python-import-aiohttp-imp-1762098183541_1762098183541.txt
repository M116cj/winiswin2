ç«‹å³è§£æ±ºæ–¹æ¡ˆï¼šç›´æ¥ç²å–æ­·å²æ•¸æ“š
æ–¹æ¡ˆ1: ä¿®æ”¹æ•¸æ“šç²å–é‚è¼¯ï¼ˆæ¨è–¦ï¼‰
åœ¨ src/core/data_fetcher.py ä¸­æ·»åŠ æ­·å²æ•¸æ“šç²å–åŠŸèƒ½ï¼š

python
import aiohttp
import pandas as pd
from datetime import datetime, timedelta
import logging

logger = logging.getLogger(__name__)

class DataFetcher:
    def __init__(self, config):
        self.config = config
        self.binance_base_url = "https://api.binance.com/api/v3"
        
    async def get_historical_klines(self, symbol: str, interval: str, limit: int = 50) -> pd.DataFrame:
        """ç›´æ¥å¾Binanceç²å–æ­·å²Kç·šæ•¸æ“š"""
        try:
            url = f"{self.binance_base_url}/klines"
            params = {
                'symbol': symbol,
                'interval': interval,
                'limit': limit
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.get(url, params=params) as response:
                    if response.status == 200:
                        data = await response.json()
                        df = pd.DataFrame(data, columns=[
                            'open_time', 'open', 'high', 'low', 'close', 'volume',
                            'close_time', 'quote_asset_volume', 'number_of_trades',
                            'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'ignore'
                        ])
                        
                        # è½‰æ›æ•¸æ“šé¡å‹
                        df['open'] = df['open'].astype(float)
                        df['high'] = df['high'].astype(float)
                        df['low'] = df['low'].astype(float)
                        df['close'] = df['close'].astype(float)
                        df['volume'] = df['volume'].astype(float)
                        
                        logger.info(f"âœ… æ­·å²æ•¸æ“šç²å–æˆåŠŸ: {symbol} {interval} {len(df)}è¡Œ")
                        return df
                    else:
                        logger.error(f"âŒ æ­·å²æ•¸æ“šç²å–å¤±æ•—: {symbol} {interval} - HTTP {response.status}")
                        return None
                        
        except Exception as e:
            logger.error(f"âŒ æ­·å²æ•¸æ“šç²å–ç•°å¸¸: {symbol} {interval} - {e}")
            return None
    
    async def get_multi_timeframe_data_with_history(self, symbol: str, timeframes: List[str] = None) -> Dict[str, pd.DataFrame]:
        """ç²å–å¤šæ™‚é–“æ¡†æ¶æ•¸æ“šï¼ˆåŒ…å«æ­·å²æ•¸æ“šï¼‰"""
        if timeframes is None:
            timeframes = ['1h', '15m', '5m']
            
        result = {}
        
        for tf in timeframes:
            # å…ˆå˜—è©¦ç²å–æ­·å²æ•¸æ“š
            historical_data = await self.get_historical_klines(symbol, tf, limit=50)
            
            if historical_data is not None and len(historical_data) >= 10:
                result[tf] = historical_data
                logger.info(f"âœ… {symbol} {tf}: ä½¿ç”¨æ­·å²æ•¸æ“š {len(historical_data)}è¡Œ")
            else:
                # å‚™ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨WebSocketå¯¦æ™‚æ•¸æ“š
                realtime_data = await self.get_realtime_data(symbol, tf)
                result[tf] = realtime_data
                logger.warning(f"âš ï¸ {symbol} {tf}: æ­·å²æ•¸æ“šä¸è¶³ï¼Œä½¿ç”¨å¯¦æ™‚æ•¸æ“š {len(realtime_data) if realtime_data else 0}è¡Œ")
                
        return result
æ–¹æ¡ˆ2: æ›´æ–°çµ±ä¸€èª¿åº¦å™¨
åœ¨ src/core/unified_scheduler.py ä¸­æ›´æ–°æ•¸æ“šç²å–é‚è¼¯ï¼š

python
async def scan_symbols(self, symbols: List[str]) -> List[Dict]:
    """æƒææ‰€æœ‰äº¤æ˜“å°ï¼ˆä½¿ç”¨æ­·å²æ•¸æ“šç«‹å³å•Ÿå‹•ï¼‰"""
    valid_signals = []
    
    logger.info("ğŸš€ ä½¿ç”¨Binanceæ­·å²æ•¸æ“šç«‹å³å•Ÿå‹•ç³»çµ±...")
    
    for i, symbol in enumerate(symbols):
        try:
            # ä½¿ç”¨åŒ…å«æ­·å²æ•¸æ“šçš„ç²å–æ–¹æ³•
            multi_tf_data = await self.data_fetcher.get_multi_timeframe_data_with_history(symbol)
            
            # æ•¸æ“šè¨ºæ–·ï¼ˆå‰3å€‹symbolï¼‰
            if i < 3:
                logger.info(f"ğŸ” æ•¸æ“šè¨ºæ–· #{i+1} - {symbol}:")
                for tf, df in multi_tf_data.items():
                    if df is not None:
                        logger.info(f"   {tf}: {len(df)}è¡Œ, æœ€æ–°æ”¶ç›¤={df['close'].iloc[-1]:.2f}")
                    else:
                        logger.warning(f"   {tf}: æ•¸æ“šç‚ºNone")
            
            # ç”Ÿæˆä¿¡è™Ÿ
            signal = self.signal_generator.generate_signal(symbol, multi_tf_data)
            
            if signal and signal.get('direction') != 'NONE':
                valid_signals.append(signal)
                
        except Exception as e:
            logger.error(f"âŒ æƒæ{symbol}æ™‚å‡ºéŒ¯: {e}")
            continue
            
    return valid_signals
æ–¹æ¡ˆ3: ç·Šæ€¥éƒ¨ç½²è…³æœ¬
bash
#!/bin/bash
echo "ğŸš€ ç·Šæ€¥éƒ¨ç½²ï¼šä½¿ç”¨Binanceæ­·å²æ•¸æ“šç«‹å³å•Ÿå‹•ç³»çµ±..."

# æ›´æ–°data_fetcher.py
cat >> src/core/data_fetcher.py << 'EOF'

# æ·»åŠ æ­·å²æ•¸æ“šç²å–æ–¹æ³•ï¼ˆä¸Šé¢çš„ä»£ç¢¼ï¼‰
EOF

# éƒ¨ç½²åˆ°Railway
git add src/core/data_fetcher.py
git add src/core/unified_scheduler.py
git commit -m "feat: æ·»åŠ Binanceæ­·å²æ•¸æ“šç²å–ï¼Œç«‹å³å•Ÿå‹•ç³»çµ±"
git push origin main

echo "âœ… éƒ¨ç½²å®Œæˆï¼ç³»çµ±å°‡ç«‹å³é–‹å§‹å·¥ä½œï¼ˆç„¡éœ€ç­‰å¾…10å°æ™‚ï¼‰"
ğŸ“Š Binance API æ™‚é–“æ¡†æ¶å°æ‡‰è¡¨
æ™‚é–“æ¡†æ¶	APIåƒæ•¸	ç²å–50æ ¹Kç·šçš„æ™‚é–“è·¨åº¦	æ•¸æ“šé‡
1å°æ™‚	1h	50å°æ™‚	50è¡Œ
15åˆ†é˜	15m	12.5å°æ™‚	50è¡Œ
5åˆ†é˜	5m	4.2å°æ™‚	50è¡Œ
1åˆ†é˜	1m	50åˆ†é˜	50è¡Œ
ğŸ¯ é æœŸç«‹å³æ•ˆæœ
éƒ¨ç½²å¾Œç«‹å³çœ‹åˆ°çš„æ—¥èªŒï¼š
text
ğŸš€ ä½¿ç”¨Binanceæ­·å²æ•¸æ“šç«‹å³å•Ÿå‹•ç³»çµ±...
ğŸ” æ•¸æ“šè¨ºæ–· #1 - BTCUSDT:
   1h: 50è¡Œ, æœ€æ–°æ”¶ç›¤=95234.50
   15m: 50è¡Œ, æœ€æ–°æ”¶ç›¤=95236.20  
   5m: 50è¡Œ, æœ€æ–°æ”¶ç›¤=95238.10
âœ… BTCUSDT æ•¸æ“šé©—è­‰é€šé (#1)

ğŸ” ç‰¹å¾µè¨ˆç®—è¨ºæ–· - BTCUSDT:
   æ•¸æ“šå½¢ç‹€: 1h=(50,5), 15m=(50,5), 5m=(50,5)
   1hæŠ€è¡“æŒ‡æ¨™: 8å€‹è¨ˆç®—æˆåŠŸ
     âœ… ema_20: 50
     âœ… ema_50: 50
     âœ… rsi_14: 50
     âœ… å¸ƒæ—å¸¶: 50
   âœ… ä¿¡è™Ÿç”ŸæˆæˆåŠŸ: LONG

ğŸ“Š Pipelineé€²åº¦å¿«ç…§ï¼ˆå·²æƒæ50å€‹ï¼‰
   Stage1é©—è­‰: æœ‰æ•ˆ=50, æ‹’çµ•=0
   Stage3æ–¹å‘: æœ‰=15, ç„¡=35

â±ï¸  å¹³å‡åˆ†ææ™‚é–“: 45.9ms  â† âœ… ç«‹å³æ­£å¸¸ï¼
ğŸ”§ å„ªå‹¢åˆ†æ
å‚³çµ±æ–¹å¼ï¼ˆç­‰å¾…10å°æ™‚ï¼‰ï¼š
âŒ éœ€è¦çœŸå¯¦ç­‰å¾…10å°æ™‚

âŒ WebSocketæ•¸æ“šå¯èƒ½ä¸å®Œæ•´

âŒ ç³»çµ±ç„¡æ³•ç«‹å³æ¸¬è©¦

æ­·å²æ•¸æ“šæ–¹å¼ï¼ˆç«‹å³å•Ÿå‹•ï¼‰ï¼š
âœ… ç«‹å³å•Ÿå‹•ï¼šéƒ¨ç½²å¾Œ5åˆ†é˜å…§é–‹å§‹å·¥ä½œ

âœ… æ•¸æ“šå®Œæ•´ï¼šç¢ºä¿50è¡Œå®Œæ•´æ­·å²æ•¸æ“š

âœ… æŒ‡æ¨™æº–ç¢ºï¼šEMA50ã€RSIç­‰éœ€è¦é•·é€±æœŸçš„æŒ‡æ¨™å¯æ­£ç¢ºè¨ˆç®—

âœ… æ··åˆæ¨¡å¼ï¼šæ­·å²æ•¸æ“š + å¯¦æ™‚WebSocketæ›´æ–°

ğŸš€ ç«‹å³åŸ·è¡Œæ­¥é©Ÿ
bash
# 1. æ·»åŠ æ­·å²æ•¸æ“šç²å–åŠŸèƒ½åˆ° data_fetcher.py
# 2. æ›´æ–° unified_scheduler.py ä½¿ç”¨æ–°æ–¹æ³•
# 3. éƒ¨ç½²åˆ°Railway

git add src/core/data_fetcher.py
git add src/core/unified_scheduler.py
git commit -m "ç·Šæ€¥ä¿®å¾©: ä½¿ç”¨Binanceæ­·å²æ•¸æ“šç«‹å³å•Ÿå‹•ï¼Œè·³é10å°æ™‚ç­‰å¾…"
git push origin main

# 4. ç›£æ§æ—¥èªŒï¼ˆ5åˆ†é˜å…§æ‡‰è©²çœ‹åˆ°æ•ˆæœï¼‰
railway logs --follow | grep -E "æ­·å²æ•¸æ“š|æ•¸æ“šè¨ºæ–·|Pipeline|å¹³å‡åˆ†ææ™‚é–“"
ğŸ“‹ é©—è­‰æ¸…å–®
éƒ¨ç½²å¾Œæª¢æŸ¥ï¼š

çœ‹åˆ°"ä½¿ç”¨Binanceæ­·å²æ•¸æ“šç«‹å³å•Ÿå‹•ç³»çµ±"

æ•¸æ“šè¨ºæ–·é¡¯ç¤ºæ¯å€‹æ™‚é–“æ¡†æ¶éƒ½æœ‰â‰¥50è¡Œæ•¸æ“š

Stage1é©—è­‰: æœ‰æ•ˆ=530, æ‹’çµ•=0

å¹³å‡åˆ†ææ™‚é–“ >10msï¼ˆä¸å†æ˜¯0.0msï¼‰

ç”Ÿæˆ3-10å€‹äº¤æ˜“ä¿¡è™Ÿ

