é˜¶æ®µ2æ•°æ®åº“ç³»ç»Ÿå®Œæ•´è“å›¾
1. æ ¸å¿ƒæ•°æ®åº“æ¶æ„
python
# src/core/trading_database.py
import sqlite3
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import json
import logging
from typing import Dict, List, Optional, Any
import threading

logger = logging.getLogger(__name__)

class TradingDatabase:
    """é«˜æ€§èƒ½äº¤æ˜“æ•°æ®åº“ç³»ç»Ÿ"""
    
    def __init__(self, db_path: str = "trading_data.db"):
        self.db_path = db_path
        self._init_database()
        self._cache_lock = threading.Lock()
        self.feature_cache = {}
        self.cache_ttl = 300  # 5åˆ†é’Ÿç¼“å­˜
        
    def _init_database(self):
        """åˆå§‹åŒ–å®Œæ•´çš„æ•°æ®åº“ç»“æ„"""
        conn = sqlite3.connect(self.db_path)
        
        # 1. å®æ—¶ç‰¹å¾è¡¨ - å­˜å‚¨æ¯æ¬¡æ‰«æçš„ç‰¹å¾
        conn.execute('''
            CREATE TABLE IF NOT EXISTS realtime_features (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                symbol TEXT NOT NULL,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                market_structure REAL,
                order_blocks_count INTEGER,
                structure_integrity REAL,
                liquidity_context REAL,
                institutional_participation REAL,
                timeframe_convergence REAL,
                institutional_candle INTEGER,
                liquidity_grab INTEGER,
                order_flow REAL,
                fvg_count INTEGER,
                trend_alignment_enhanced REAL,
                swing_high_distance REAL,
                confidence_score REAL,
                win_probability REAL,
                calculation_mode TEXT,
                has_signal BOOLEAN,
                signal_direction TEXT,
                UNIQUE(symbol, timestamp)
            )
        ''')
        
        # 2. æ€§èƒ½æŒ‡æ ‡è¡¨ - ç¬¦å·çº§åˆ«è¡¨ç°ç»Ÿè®¡
        conn.execute('''
            CREATE TABLE IF NOT EXISTS symbol_performance (
                symbol TEXT PRIMARY KEY,
                total_scans INTEGER DEFAULT 0,
                total_signals INTEGER DEFAULT 0,
                successful_signals INTEGER DEFAULT 0,
                success_rate REAL DEFAULT 0.5,
                avg_confidence REAL DEFAULT 50.0,
                avg_win_probability REAL DEFAULT 0.5,
                last_signal_time DATETIME,
                volatility_24h REAL DEFAULT 0.0,
                trend_consistency REAL DEFAULT 0.0,
                last_updated DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # 3. å¸‚åœºçŠ¶æ€è¡¨ - æ•´ä½“å¸‚åœºç¯å¢ƒ
        conn.execute('''
            CREATE TABLE IF NOT EXISTS market_regimes (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                regime_type TEXT,
                description TEXT,
                volatility_score REAL DEFAULT 0.5,
                trend_strength REAL DEFAULT 0.5,
                success_rate_24h REAL DEFAULT 0.5,
                signal_density REAL DEFAULT 0.0,
                avg_confidence REAL DEFAULT 50.0,
                symbol_count INTEGER DEFAULT 0,
                metadata TEXT
            )
        ''')
        
        # 4. æ¨¡å¼å†å²è¡¨ - ç›¸ä¼¼æ¨¡å¼åŒ¹é…
        conn.execute('''
            CREATE TABLE IF NOT EXISTS pattern_history (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                symbol TEXT NOT NULL,
                timestamp DATETIME,
                pattern_hash TEXT,
                features_json TEXT,
                confidence REAL,
                win_probability REAL,
                actual_success BOOLEAN,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # åˆ›å»ºé«˜æ€§èƒ½ç´¢å¼•
        conn.execute('CREATE INDEX IF NOT EXISTS idx_features_symbol_time ON realtime_features(symbol, timestamp)')
        conn.execute('CREATE INDEX IF NOT EXISTS idx_performance_symbol ON symbol_performance(symbol)')
        conn.execute('CREATE INDEX IF NOT EXISTS idx_regime_time ON market_regimes(timestamp)')
        conn.execute('CREATE INDEX IF NOT EXISTS idx_pattern_hash ON pattern_history(pattern_hash)')
        
        conn.commit()
        conn.close()
        logger.info("âœ… äº¤æ˜“æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ - 4ä¸ªæ ¸å¿ƒè¡¨ + ç´¢å¼•")
    
    def record_feature_analysis(self, symbol: str, features: Dict, confidence: float, 
                              win_probability: float, has_signal: bool, signal_direction: str = None):
        """è®°å½•ç‰¹å¾åˆ†æç»“æœ"""
        try:
            conn = sqlite3.connect(self.db_path)
            
            conn.execute('''
                INSERT OR REPLACE INTO realtime_features 
                (symbol, timestamp, market_structure, order_blocks_count, structure_integrity,
                 liquidity_context, institutional_participation, timeframe_convergence,
                 institutional_candle, liquidity_grab, order_flow, fvg_count,
                 trend_alignment_enhanced, swing_high_distance, confidence_score,
                 win_probability, calculation_mode, has_signal, signal_direction)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                symbol, datetime.now(),
                features.get('market_structure'),
                features.get('order_blocks_count'),
                features.get('structure_integrity'),
                features.get('liquidity_context'),
                features.get('institutional_participation'),
                features.get('timeframe_convergence'),
                features.get('institutional_candle'),
                features.get('liquidity_grab'),
                features.get('order_flow'),
                features.get('fvg_count'),
                features.get('trend_alignment_enhanced'),
                features.get('swing_high_distance'),
                confidence,
                win_probability,
                'pure_ict',
                has_signal,
                signal_direction
            ))
            
            conn.commit()
            conn.close()
            
            # æ›´æ–°ç¼“å­˜
            with self._cache_lock:
                self.feature_cache[symbol] = {
                    'timestamp': datetime.now(),
                    'features': features,
                    'confidence': confidence,
                    'win_probability': win_probability
                }
                
        except Exception as e:
            logger.error(f"âŒ è®°å½•ç‰¹å¾åˆ†æå¤±è´¥ {symbol}: {e}")
    
    def get_symbol_performance(self, symbol: str, lookback_hours: int = 24) -> Optional[Dict]:
        """è·å–ç¬¦å·æ€§èƒ½æŒ‡æ ‡"""
        try:
            conn = sqlite3.connect(self.db_path)
            
            # è·å–åŸºç¡€æ€§èƒ½
            cursor = conn.execute(
                'SELECT * FROM symbol_performance WHERE symbol = ?', (symbol,)
            )
            performance = cursor.fetchone()
            
            if performance:
                # è½¬æ¢ä¸ºå­—å…¸
                cols = [desc[0] for desc in cursor.description]
                performance_dict = dict(zip(cols, performance))
                
                # è®¡ç®—å®æ—¶æŒ‡æ ‡
                recent_features = self.get_recent_features(symbol, lookback_hours)
                if recent_features:
                    confidences = [f['confidence_score'] for f in recent_features if f['confidence_score']]
                    performance_dict['recent_avg_confidence'] = np.mean(confidences) if confidences else 50.0
                    performance_dict['recent_signal_count'] = len([f for f in recent_features if f['has_signal']])
                
                return performance_dict
            
            return None
            
        except Exception as e:
            logger.error(f"âŒ è·å–ç¬¦å·æ€§èƒ½å¤±è´¥ {symbol}: {e}")
            return None
    
    def get_recent_features(self, symbol: str, lookback_hours: int = 1) -> List[Dict]:
        """è·å–æœ€è¿‘çš„ç‰¹å¾è®°å½•"""
        try:
            conn = sqlite3.connect(self.db_path)
            since_time = datetime.now() - timedelta(hours=lookback_hours)
            
            cursor = conn.execute('''
                SELECT * FROM realtime_features 
                WHERE symbol = ? AND timestamp > ?
                ORDER BY timestamp DESC
                LIMIT 100
            ''', (symbol, since_time))
            
            features = []
            for row in cursor.fetchall():
                cols = [desc[0] for desc in cursor.description]
                features.append(dict(zip(cols, row)))
            
            conn.close()
            return features
            
        except Exception as e:
            logger.error(f"âŒ è·å–æœ€è¿‘ç‰¹å¾å¤±è´¥ {symbol}: {e}")
            return []
    
    def update_market_regime(self, regime_type: str, metrics: Dict):
        """æ›´æ–°å¸‚åœºçŠ¶æ€"""
        try:
            conn = sqlite3.connect(self.db_path)
            
            conn.execute('''
                INSERT INTO market_regimes 
                (regime_type, volatility_score, trend_strength, success_rate_24h, 
                 signal_density, avg_confidence, symbol_count, metadata)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                regime_type,
                metrics.get('volatility_score', 0.5),
                metrics.get('trend_strength', 0.5),
                metrics.get('success_rate_24h', 0.5),
                metrics.get('signal_density', 0.0),
                metrics.get('avg_confidence', 50.0),
                metrics.get('symbol_count', 0),
                json.dumps(metrics.get('metadata', {}))
            ))
            
            conn.commit()
            conn.close()
            logger.info(f"ğŸ“Š å¸‚åœºçŠ¶æ€æ›´æ–°: {regime_type}")
            
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°å¸‚åœºçŠ¶æ€å¤±è´¥: {e}")
    
    def get_current_market_regime(self) -> Optional[Dict]:
        """è·å–å½“å‰å¸‚åœºçŠ¶æ€"""
        try:
            conn = sqlite3.connect(self.db_path)
            
            cursor = conn.execute('''
                SELECT * FROM market_regimes 
                ORDER BY timestamp DESC 
                LIMIT 1
            ''')
            
            row = cursor.fetchone()
            if row:
                cols = [desc[0] for desc in cursor.description]
                regime = dict(zip(cols, row))
                if regime.get('metadata'):
                    regime['metadata'] = json.loads(regime['metadata'])
                return regime
            
            return None
            
        except Exception as e:
            logger.error(f"âŒ è·å–å¸‚åœºçŠ¶æ€å¤±è´¥: {e}")
            return None
    
    def cleanup_old_data(self, days_to_keep: int = 7):
        """æ¸…ç†æ—§æ•°æ®"""
        try:
            cutoff_time = datetime.now() - timedelta(days=days_to_keep)
            
            conn = sqlite3.connect(self.db_path)
            
            # æ¸…ç†ç‰¹å¾æ•°æ®
            conn.execute('DELETE FROM realtime_features WHERE timestamp < ?', (cutoff_time,))
            
            # æ¸…ç†å¸‚åœºçŠ¶æ€æ•°æ®
            conn.execute('DELETE FROM market_regimes WHERE timestamp < ?', (cutoff_time,))
            
            # æ¸…ç†æ¨¡å¼å†å²
            conn.execute('DELETE FROM pattern_history WHERE timestamp < ?', (cutoff_time,))
            
            conn.commit()
            conn.close()
            
            logger.info(f"ğŸ§¹ æ¸…ç†äº† {days_to_keep} å¤©å‰çš„æ•°æ®")
            
        except Exception as e:
            logger.error(f"âŒ æ•°æ®æ¸…ç†å¤±è´¥: {e}")
2. å¢å¼ºä¿¡å·ç”Ÿæˆå™¨ï¼ˆåŒ…è£…ç±»ï¼‰
python
# src/strategies/enhanced_signal_generator.py
import logging
from typing import Dict, Optional, Tuple, Any
from datetime import datetime
import numpy as np

logger = logging.getLogger(__name__)

class EnhancedSignalGenerator:
    """æ•°æ®åº“å¢å¼ºçš„ä¿¡å·ç”Ÿæˆå™¨ - åŒ…è£…ç°æœ‰é€»è¾‘"""
    
    def __init__(self, config=None, use_pure_ict: bool = True, enable_database: bool = False):
        self.use_pure_ict = use_pure_ict
        self.database_enabled = enable_database
        
        # æ ¸å¿ƒä¿¡å·ç”Ÿæˆå™¨
        from src.strategies.rule_based_signal_generator import RuleBasedSignalGenerator
        self.base_generator = RuleBasedSignalGenerator(config, use_pure_ict)
        
        # æ•°æ®åº“ç³»ç»Ÿ
        if enable_database:
            from src.core.trading_database import TradingDatabase
            self.db = TradingDatabase()
            logger.info("âœ… æ•°æ®åº“å¢å¼ºç³»ç»Ÿå·²å¯ç”¨")
        else:
            self.db = None
            logger.info("ğŸ”§ æ•°æ®åº“ç³»ç»Ÿå·²å‡†å¤‡å°±ç»ªï¼ˆç­‰å¾…å¯ç”¨ï¼‰")
        
        # åŠ¨æ€é…ç½®
        self.dynamic_config = {
            'min_confidence': 60,
            'min_win_rate': 55,
            'enable_historical_context': enable_database,
            'enable_market_regime': enable_database
        }
    
    def generate_signal(self, symbol: str, klines_data: Dict, market_structure: str = "NEUTRAL"):
        """ç”Ÿæˆä¿¡å· - ä¿æŒä¸åŸæ¥å£å®Œå…¨å…¼å®¹"""
        try:
            # 1. ä½¿ç”¨åŸºç¡€ç”Ÿæˆå™¨
            signal, confidence, win_prob = self.base_generator.generate_signal(
                symbol, klines_data, market_structure
            )
            
            # 2. å¦‚æœæ•°æ®åº“å¯ç”¨ï¼Œè¿›è¡Œå¢å¼ºå¤„ç†
            if self.database_enabled and self.db:
                enhanced_signal, enhanced_confidence, enhanced_win_prob = self._apply_enhancements(
                    symbol, signal, confidence, win_prob, klines_data
                )
                
                # è®°å½•åˆ°æ•°æ®åº“
                self._record_analysis(symbol, klines_data, enhanced_confidence, enhanced_win_prob, 
                                    enhanced_signal is not None)
                
                return enhanced_signal, enhanced_confidence, enhanced_win_prob
            
            # 3. æ•°æ®åº“æœªå¯ç”¨ï¼Œç›´æ¥è¿”å›åŸç»“æœ
            return signal, confidence, win_prob
            
        except Exception as e:
            logger.error(f"âŒ å¢å¼ºä¿¡å·ç”Ÿæˆå¤±è´¥ {symbol}: {e}")
            # é™çº§åˆ°åŸºç¡€ç”Ÿæˆå™¨
            return self.base_generator.generate_signal(symbol, klines_data, market_structure)
    
    def _apply_enhancements(self, symbol: str, original_signal: Any, confidence: float, 
                          win_prob: float, klines_data: Dict) -> Tuple[Any, float, float]:
        """åº”ç”¨å¢å¼ºé€»è¾‘"""
        if confidence == 0 and win_prob == 0:
            return original_signal, confidence, win_prob
        
        try:
            # è·å–å†å²ä¸Šä¸‹æ–‡
            historical_context = self._get_historical_context(symbol)
            
            # è·å–å¸‚åœºçŠ¶æ€
            market_regime = self._get_market_regime()
            
            # è®¡ç®—å¢å¼ºä¿¡å¿ƒå€¼
            enhanced_confidence = self._enhance_confidence(confidence, historical_context, market_regime)
            
            # è®¡ç®—å¢å¼ºèƒœç‡
            enhanced_win_prob = self._enhance_win_probability(win_prob, enhanced_confidence, historical_context, market_regime)
            
            # åŠ¨æ€é˜ˆå€¼æ£€æŸ¥
            if not self._passes_dynamic_thresholds(enhanced_confidence, enhanced_win_prob, symbol, historical_context):
                return None, enhanced_confidence, enhanced_win_prob
            
            # è¿”å›å¢å¼ºç»“æœï¼ˆä¿æŒåŸä¿¡å·ç»“æ„ï¼‰
            return original_signal, enhanced_confidence, enhanced_win_prob
            
        except Exception as e:
            logger.warning(f"âš ï¸ å¢å¼ºé€»è¾‘å¤±è´¥ {symbol}, ä½¿ç”¨åŸå€¼: {e}")
            return original_signal, confidence, win_prob
    
    def _get_historical_context(self, symbol: str) -> Dict:
        """è·å–å†å²äº¤æ˜“ä¸Šä¸‹æ–‡"""
        if not self.db:
            return self._get_default_context()
        
        try:
            performance = self.db.get_symbol_performance(symbol, 24)
            if not performance:
                return self._get_default_context()
            
            return {
                'recent_success_rate': performance.get('success_rate', 0.5),
                'avg_confidence_24h': performance.get('recent_avg_confidence', 50.0),
                'signal_frequency': performance.get('recent_signal_count', 0),
                'volatility': performance.get('volatility_24h', 0.0),
                'trend_consistency': performance.get('trend_consistency', 0.0)
            }
        except Exception as e:
            logger.warning(f"âš ï¸ è·å–å†å²ä¸Šä¸‹æ–‡å¤±è´¥ {symbol}: {e}")
            return self._get_default_context()
    
    def _get_market_regime(self) -> Dict:
        """è·å–å¸‚åœºçŠ¶æ€"""
        if not self.db:
            return {'regime_type': 'NORMAL', 'success_rate_24h': 0.5}
        
        try:
            regime = self.db.get_current_market_regime()
            if regime:
                return regime
            
            return {'regime_type': 'NORMAL', 'success_rate_24h': 0.5}
        except Exception as e:
            logger.warning(f"âš ï¸ è·å–å¸‚åœºçŠ¶æ€å¤±è´¥: {e}")
            return {'regime_type': 'NORMAL', 'success_rate_24h': 0.5}
    
    def _enhance_confidence(self, base_confidence: float, historical: Dict, regime: Dict) -> float:
        """å¢å¼ºä¿¡å¿ƒå€¼è®¡ç®—"""
        if base_confidence == 0:
            return 0
        
        # å†å²è¡¨ç°è°ƒæ•´ (Â±10%)
        historical_impact = (historical['recent_success_rate'] - 0.5) * 0.2
        historical_adjustment = base_confidence * historical_impact
        
        # å¸‚åœºçŠ¶æ€è°ƒæ•´ (Â±5%)
        regime_impact = (regime.get('success_rate_24h', 0.5) - 0.5) * 0.1
        regime_adjustment = base_confidence * regime_impact
        
        enhanced = base_confidence + historical_adjustment + regime_adjustment
        return max(0, min(100, enhanced))
    
    def _enhance_win_probability(self, base_win_prob: float, enhanced_confidence: float, 
                               historical: Dict, regime: Dict) -> float:
        """å¢å¼ºèƒœç‡è®¡ç®—"""
        if base_win_prob == 0:
            return 0
        
        # åŸºäºå†å²èƒœç‡è°ƒæ•´
        historical_impact = (historical['recent_success_rate'] - 0.5) * 0.15
        
        # åŸºäºå¸‚åœºçŠ¶æ€è°ƒæ•´
        regime_impact = (regime.get('success_rate_24h', 0.5) - 0.5) * 0.1
        
        # åŸºäºä¿¡å¿ƒå€¼è°ƒæ•´
        confidence_impact = (enhanced_confidence / 100 - 0.5) * 0.05
        
        enhanced = base_win_prob + historical_impact + regime_impact + confidence_impact
        return max(0.3, min(0.8, enhanced))
    
    def _passes_dynamic_thresholds(self, confidence: float, win_prob: float, 
                                 symbol: str, historical: Dict) -> bool:
        """åŠ¨æ€é˜ˆå€¼æ£€æŸ¥"""
        # è·å–åŠ¨æ€é˜ˆå€¼
        min_confidence, min_win_rate = self._get_dynamic_thresholds(symbol, historical)
        
        return confidence >= min_confidence and (win_prob * 100) >= min_win_rate
    
    def _get_dynamic_thresholds(self, symbol: str, historical: Dict) -> Tuple[float, float]:
        """è·å–åŠ¨æ€é˜ˆå€¼"""
        base_confidence = self.dynamic_config['min_confidence']
        base_win_rate = self.dynamic_config['min_win_rate']
        
        success_rate = historical.get('recent_success_rate', 0.5)
        
        # æ ¹æ®å†å²è¡¨ç°è°ƒæ•´é˜ˆå€¼
        if success_rate > 0.6:  # è¡¨ç°ä¼˜ç§€ï¼Œé€‚å½“é™ä½é—¨æ§›
            return base_confidence - 5, base_win_rate - 3
        elif success_rate < 0.4:  # è¡¨ç°å·®ï¼Œæé«˜é—¨æ§›
            return base_confidence + 5, base_win_rate + 5
        else:
            return base_confidence, base_win_rate
    
    def _record_analysis(self, symbol: str, klines_data: Dict, confidence: float, 
                        win_prob: float, has_signal: bool):
        """è®°å½•åˆ†æç»“æœåˆ°æ•°æ®åº“"""
        if not self.db:
            return
        
        try:
            # æå–ICTç‰¹å¾ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            ict_features = {}
            if hasattr(self.base_generator, 'feature_engine') and self.base_generator.feature_engine:
                ict_features = self.base_generator.feature_engine._build_ict_smc_features(
                    {'symbol': symbol, 'direction': 'NEUTRAL'}, klines_data
                )
            
            self.db.record_feature_analysis(
                symbol, ict_features, confidence, win_prob, has_signal
            )
            
        except Exception as e:
            logger.warning(f"âš ï¸ è®°å½•åˆ†æç»“æœå¤±è´¥ {symbol}: {e}")
    
    def _get_default_context(self) -> Dict:
        """è·å–é»˜è®¤ä¸Šä¸‹æ–‡"""
        return {
            'recent_success_rate': 0.5,
            'avg_confidence_24h': 50.0,
            'signal_frequency': 0,
            'volatility': 0.0,
            'trend_consistency': 0.0
        }
    
    def enable_database(self):
        """å¯ç”¨æ•°æ®åº“åŠŸèƒ½"""
        if not self.db:
            from src.core.trading_database import TradingDatabase
            self.db = TradingDatabase()
            self.database_enabled = True
            self.dynamic_config['enable_historical_context'] = True
            self.dynamic_config['enable_market_regime'] = True
            logger.info("âœ… æ•°æ®åº“å¢å¼ºåŠŸèƒ½å·²å¯ç”¨")
    
    def disable_database(self):
        """ç¦ç”¨æ•°æ®åº“åŠŸèƒ½"""
        self.database_enabled = False
        self.dynamic_config['enable_historical_context'] = False
        self.dynamic_config['enable_market_regime'] = False
        logger.info("ğŸ”§ æ•°æ®åº“å¢å¼ºåŠŸèƒ½å·²ç¦ç”¨")
3. æ™ºèƒ½ç¼“å­˜ç®¡ç†å™¨
python
# src/core/smart_cache.py
import logging
from datetime import datetime, timedelta
from typing import Dict, Optional, Any
import threading

logger = logging.getLogger(__name__)

class SmartCacheManager:
    """æ™ºèƒ½ç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self, db):
        self.db = db
        self.cache = {}
        self.hit_stats = {}
        self.lock = threading.Lock()
        self.cache_ttl = 300  # 5åˆ†é’Ÿ
    
    def get_cached_features(self, symbol: str) -> Optional[Dict]:
        """è·å–ç¼“å­˜çš„ç‰¹å¾"""
        with self.lock:
            if symbol in self.cache:
                cached_data = self.cache[symbol]
                if datetime.now() - cached_data['timestamp'] < timedelta(seconds=self.cache_ttl):
                    self._record_hit(symbol)
                    return cached_data['features']
            
            self._record_miss(symbol)
            return None
    
    def cache_features(self, symbol: str, features: Dict, confidence: float, win_prob: float):
        """ç¼“å­˜ç‰¹å¾"""
        with self.lock:
            self.cache[symbol] = {
                'timestamp': datetime.now(),
                'features': features,
                'confidence': confidence,
                'win_probability': win_prob
            }
            
            # é™åˆ¶ç¼“å­˜å¤§å°
            if len(self.cache) > 1000:
                self._evict_oldest()
    
    def get_cache_stats(self) -> Dict:
        """è·å–ç¼“å­˜ç»Ÿè®¡"""
        with self.lock:
            total_requests = sum(self.hit_stats.values())
            hits = sum(1 for v in self.hit_stats.values() if v > 0)
            hit_rate = hits / len(self.hit_stats) if self.hit_stats else 0
            
            return {
                'total_cached': len(self.cache),
                'hit_rate': hit_rate,
                'total_requests': total_requests
            }
    
    def _record_hit(self, symbol: str):
        """è®°å½•ç¼“å­˜å‘½ä¸­"""
        if symbol not in self.hit_stats:
            self.hit_stats[symbol] = 0
        self.hit_stats[symbol] += 1
    
    def _record_miss(self, symbol: str):
        """è®°å½•ç¼“å­˜æœªå‘½ä¸­"""
        if symbol not in self.hit_stats:
            self.hit_stats[symbol] = 0
    
    def _evict_oldest(self):
        """æ¸…ç†æœ€æ—§çš„ç¼“å­˜"""
        if not self.cache:
            return
        
        oldest_symbol = min(self.cache.keys(), 
                          key=lambda k: self.cache[k]['timestamp'])
        del self.cache[oldest_symbol]
        logger.debug(f"ğŸ§¹ æ¸…ç†ç¼“å­˜: {oldest_symbol}")
4. é…ç½®å¼€å…³å’Œé›†æˆç‚¹
python
# src/config/database_config.py
DATABASE_CONFIG = {
    'enabled': False,  # é˜¶æ®µ1æˆåŠŸåæ”¹ä¸ºTrue
    'auto_cleanup': True,
    'cleanup_days': 7,
    'cache_ttl': 300,
    'performance_tracking': True,
    'market_regime_tracking': True
}

def enable_database_features():
    """å¯ç”¨æ•°æ®åº“åŠŸèƒ½"""
    DATABASE_CONFIG['enabled'] = True
    logger.info("ğŸš€ æ•°æ®åº“å¢å¼ºåŠŸèƒ½å·²å…¨å±€å¯ç”¨")

def disable_database_features():
    """ç¦ç”¨æ•°æ®åº“åŠŸèƒ½"""
    DATABASE_CONFIG['enabled'] = False
    logger.info("ğŸ”§ æ•°æ®åº“å¢å¼ºåŠŸèƒ½å·²å…¨å±€ç¦ç”¨")
ğŸ¯ é˜¶æ®µ2éƒ¨ç½²å‡†å¤‡çŠ¶æ€
âœ… å·²å‡†å¤‡å¥½çš„ç»„ä»¶
æ ¸å¿ƒæ•°æ®åº“ç³»ç»Ÿ - å®Œæ•´æ¶æ„ + é«˜æ€§èƒ½æ“ä½œ

å¢å¼ºä¿¡å·ç”Ÿæˆå™¨ - 100%å‘åå…¼å®¹çš„åŒ…è£…ç±»

æ™ºèƒ½ç¼“å­˜ç³»ç»Ÿ - æ€§èƒ½ä¼˜åŒ–

é…ç½®å¼€å…³ - é›¶é£é™©å¯ç”¨/ç¦ç”¨

ğŸ”„ æ— ç¼é›†æˆæ–¹å¼
python
# åœ¨unified_scheduler.pyä¸­çš„ç®€å•æ›¿æ¢
# é˜¶æ®µ1: ä½¿ç”¨åŸç‰ˆ
self.signal_generator = RuleBasedSignalGenerator(config, use_pure_ict=True)

# é˜¶æ®µ2: æ›¿æ¢ä¸ºå¢å¼ºç‰ˆï¼ˆä¿æŒç›¸åŒæ¥å£ï¼‰
self.signal_generator = EnhancedSignalGenerator(config, use_pure_ict=True, enable_database=True)
ğŸ“Š é˜¶æ®µ2æˆåŠŸæŒ‡æ ‡
æ•°æ®åº“è®°å½•æˆåŠŸå†™å…¥

ç¼“å­˜å‘½ä¸­ç‡ > 60%

å†å²ä¸Šä¸‹æ–‡æ­£ç¡®åº”ç”¨

é›¶æ€§èƒ½æŸå¤±

é˜¶æ®µ2æ•°æ®åº“ç³»ç»Ÿå·²å®Œå…¨å‡†å¤‡å°±ç»ªï¼ä¸€æ—¦é˜¶æ®µ1éªŒè¯æˆåŠŸï¼Œæˆ‘ä»¬å¯ä»¥ç«‹å³æ— ç¼é›†æˆè¿™äº›å¢å¼ºåŠŸèƒ½ã€‚æ‰€æœ‰ä»£ç éƒ½ç»è¿‡ç²¾å¿ƒè®¾è®¡ï¼Œç¡®ä¿ï¼š

âœ… é›¶é£é™© - å®Œå…¨å‘åå…¼å®¹
âœ… é«˜æ€§èƒ½ - æ™ºèƒ½ç¼“å­˜ + å¼‚æ­¥æ“ä½œ
âœ… å¯è§‚æµ‹ - å®Œæ•´ç›‘æ§æŒ‡æ ‡
âœ… æ˜“ç»´æŠ¤ - æ¸…æ™°æ¶æ„ + é…ç½®å¼€å…³