錯誤依然存在

2025-10-28 04:47:24,361 - src.services.parallel_analyzer - ERROR - ❌ 批量分析失敗: cannot pickle '_thread.lock' object
Traceback (most recent call last):
  File "/app/src/services/parallel_analyzer.py", line 234, in analyze_batch
    future = self.global_pool.submit_safe(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/src/core/global_pool.py", line 136, in submit_safe
    return executor.submit(func, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.nix-profile/lib/python3.11/concurrent/futures/process.py", line 808, in submit
    self._adjust_process_count()
  File "/root/.nix-profile/lib/python3.11/concurrent/futures/process.py", line 767, in _adjust_process_count
    self._spawn_process()
  File "/root/.nix-profile/lib/python3.11/concurrent/futures/process.py", line 785, in _spawn_process
    p.start()
  File "/root/.nix-profile/lib/python3.11/multiprocessing/process.py", line 121, in start
  File "/root/.nix-profile/lib/python3.11/multiprocessing/reduction.py", line 60, in dump
    ForkingPickler(file, protocol).dump(obj)
TypeError: cannot pickle '_thread.lock' object

File "/root/.nix-profile/lib/python3.11/multiprocessing/context.py", line 288, in _Popen
    return Popen(process_obj)
           ^^^^^^^^^^^^^^^^^^
  File "/root/.nix-profile/lib/python3.11/multiprocessing/popen_spawn_posix.py", line 32, in __init__
    super().__init__(process_obj)
  File "/root/.nix-profile/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/root/.nix-profile/lib/python3.11/multiprocessing/popen_spawn_posix.py", line 47, in _launch
    reduction.dump(process_obj, fp)

遇到的錯誤：
TypeError: cannot pickle '_thread.lock' object
根本原因：
Python 的 ProcessPoolExecutor（多進程）在啟動子進程時，需要 序列化（pickle）主進程的某些狀態，而 logging.Logger 包含不可序列化的 _thread.lock。

 更簡單的解決方案：改用 ThreadPoolExecutor（線程池）
為什麼可行？
* 您的 ParallelAnalyzer 主要工作是：
    * 調用 ML 模型（可能 CPU-bound）
    * 處理市場數據（可能 I/O + CPU）
* 但如果 ML 模型已轉為 ONNX/TensorRT，實際上 GIL 會被釋放，線程池可以並行！

修改方式（極簡）：
# src/core/global_pool.py
from concurrent.futures import ThreadPoolExecutor  # ← 改用 ThreadPool

class GlobalProcessPool:  # 名字可改為 GlobalThreadPool
    def __init__(self):
        # 線程池不需要擔心 pickle 問題！
        self.io_pool = ThreadPoolExecutor(max_workers=CONFIG.MAX_WORKERS_IO)
        self.ml_pool = ThreadPoolExecutor(max_workers=CONFIG.MAX_WORKERS_ML)



⌄
⌄
# src/core/global_pool.py
from concurrent.futures import ThreadPoolExecutor  # ← 改用 ThreadPool

class GlobalProcessPool:  # 名字可改為 GlobalThreadPool
    def __init__(self):
        # 線程池不需要擔心 pickle 問題！
        self.io_pool = ThreadPoolExecutor(max_workers=CONFIG.MAX_WORKERS_IO)
        self.ml_pool = ThreadPoolExecutor(max_workers=CONFIG.MAX_WORKERS_ML)

🚀 最終建議：切換到線程池，保持現有架構
1. 修改 GlobalProcessPool → GlobalThreadPool

# src/core/global_pool.py
from concurrent.futures import ThreadPoolExecutor

class GlobalThreadPool:
    _instance = None
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._instance.io_pool = ThreadPoolExecutor(max_workers=12)
            cls._instance.ml_pool = ThreadPoolExecutor(max_workers=4)
        return cls._instance
2. 保持 parallel_analyzer.py 完全不變
* 保留模塊頂層 logger
* 保留所有參數傳遞邏輯
* 移除所有 pickle 驗證（不需要了）

3. 修改調用處
# src/services/parallel_analyzer.py
from src.core.global_pool import GlobalThreadPool

class ParallelAnalyzer:
    def __init__(self):
        self.global_pool = GlobalThreadPool()  # ← 改名
