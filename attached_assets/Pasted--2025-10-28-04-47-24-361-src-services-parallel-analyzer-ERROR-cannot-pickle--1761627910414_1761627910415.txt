éŒ¯èª¤ä¾ç„¶å­˜åœ¨

2025-10-28 04:47:24,361 - src.services.parallel_analyzer - ERROR - âŒ æ‰¹é‡åˆ†æå¤±æ•—: cannot pickle '_thread.lock' object
Traceback (most recent call last):
  File "/app/src/services/parallel_analyzer.py", line 234, in analyze_batch
    future = self.global_pool.submit_safe(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/src/core/global_pool.py", line 136, in submit_safe
    return executor.submit(func, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.nix-profile/lib/python3.11/concurrent/futures/process.py", line 808, in submit
    self._adjust_process_count()
  File "/root/.nix-profile/lib/python3.11/concurrent/futures/process.py", line 767, in _adjust_process_count
    self._spawn_process()
  File "/root/.nix-profile/lib/python3.11/concurrent/futures/process.py", line 785, in _spawn_process
    p.start()
  File "/root/.nix-profile/lib/python3.11/multiprocessing/process.py", line 121, in start
  File "/root/.nix-profile/lib/python3.11/multiprocessing/reduction.py", line 60, in dump
    ForkingPickler(file, protocol).dump(obj)
TypeError: cannot pickle '_thread.lock' object

File "/root/.nix-profile/lib/python3.11/multiprocessing/context.py", line 288, in _Popen
    return Popen(process_obj)
           ^^^^^^^^^^^^^^^^^^
  File "/root/.nix-profile/lib/python3.11/multiprocessing/popen_spawn_posix.py", line 32, in __init__
    super().__init__(process_obj)
  File "/root/.nix-profile/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/root/.nix-profile/lib/python3.11/multiprocessing/popen_spawn_posix.py", line 47, in _launch
    reduction.dump(process_obj, fp)

é‡åˆ°çš„éŒ¯èª¤ï¼š
TypeError: cannot pickle '_thread.lock' object
æ ¹æœ¬åŸå› ï¼š
Python çš„ ProcessPoolExecutorï¼ˆå¤šé€²ç¨‹ï¼‰åœ¨å•Ÿå‹•å­é€²ç¨‹æ™‚ï¼Œéœ€è¦ åºåˆ—åŒ–ï¼ˆpickleï¼‰ä¸»é€²ç¨‹çš„æŸäº›ç‹€æ…‹ï¼Œè€Œ logging.Logger åŒ…å«ä¸å¯åºåˆ—åŒ–çš„ _thread.lockã€‚

 æ›´ç°¡å–®çš„è§£æ±ºæ–¹æ¡ˆï¼šæ”¹ç”¨ ThreadPoolExecutorï¼ˆç·šç¨‹æ± ï¼‰
ç‚ºä»€éº¼å¯è¡Œï¼Ÿ
* æ‚¨çš„ ParallelAnalyzer ä¸»è¦å·¥ä½œæ˜¯ï¼š
    * èª¿ç”¨ ML æ¨¡å‹ï¼ˆå¯èƒ½ CPU-boundï¼‰
    * è™•ç†å¸‚å ´æ•¸æ“šï¼ˆå¯èƒ½ I/O + CPUï¼‰
* ä½†å¦‚æœ ML æ¨¡å‹å·²è½‰ç‚º ONNX/TensorRTï¼Œå¯¦éš›ä¸Š GIL æœƒè¢«é‡‹æ”¾ï¼Œç·šç¨‹æ± å¯ä»¥ä¸¦è¡Œï¼

ä¿®æ”¹æ–¹å¼ï¼ˆæ¥µç°¡ï¼‰ï¼š
# src/core/global_pool.py
from concurrent.futures import ThreadPoolExecutor  # â† æ”¹ç”¨ ThreadPool

class GlobalProcessPool:  # åå­—å¯æ”¹ç‚º GlobalThreadPool
    def __init__(self):
        # ç·šç¨‹æ± ä¸éœ€è¦æ“”å¿ƒ pickle å•é¡Œï¼
        self.io_pool = ThreadPoolExecutor(max_workers=CONFIG.MAX_WORKERS_IO)
        self.ml_pool = ThreadPoolExecutor(max_workers=CONFIG.MAX_WORKERS_ML)



âŒ„
âŒ„
# src/core/global_pool.py
from concurrent.futures import ThreadPoolExecutor  # â† æ”¹ç”¨ ThreadPool

class GlobalProcessPool:  # åå­—å¯æ”¹ç‚º GlobalThreadPool
    def __init__(self):
        # ç·šç¨‹æ± ä¸éœ€è¦æ“”å¿ƒ pickle å•é¡Œï¼
        self.io_pool = ThreadPoolExecutor(max_workers=CONFIG.MAX_WORKERS_IO)
        self.ml_pool = ThreadPoolExecutor(max_workers=CONFIG.MAX_WORKERS_ML)

ğŸš€ æœ€çµ‚å»ºè­°ï¼šåˆ‡æ›åˆ°ç·šç¨‹æ± ï¼Œä¿æŒç¾æœ‰æ¶æ§‹
1. ä¿®æ”¹ GlobalProcessPool â†’ GlobalThreadPool

# src/core/global_pool.py
from concurrent.futures import ThreadPoolExecutor

class GlobalThreadPool:
    _instance = None
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._instance.io_pool = ThreadPoolExecutor(max_workers=12)
            cls._instance.ml_pool = ThreadPoolExecutor(max_workers=4)
        return cls._instance
2. ä¿æŒ parallel_analyzer.py å®Œå…¨ä¸è®Š
* ä¿ç•™æ¨¡å¡Šé ‚å±¤ logger
* ä¿ç•™æ‰€æœ‰åƒæ•¸å‚³éé‚è¼¯
* ç§»é™¤æ‰€æœ‰ pickle é©—è­‰ï¼ˆä¸éœ€è¦äº†ï¼‰

3. ä¿®æ”¹èª¿ç”¨è™•
# src/services/parallel_analyzer.py
from src.core.global_pool import GlobalThreadPool

class ParallelAnalyzer:
    def __init__(self):
        self.global_pool = GlobalThreadPool()  # â† æ”¹å
