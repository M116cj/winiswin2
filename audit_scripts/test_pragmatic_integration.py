"""
v4.6.0 Phase 1A3-1A5 å®ç”¨ä¸»ä¹‰ç‰ˆæœ¬é›†æˆæµ‹è¯•
éªŒè¯ä¸‰ä¸ªæ–°ç»„ä»¶çš„åŠŸèƒ½å’Œæ€§èƒ½
"""

import time
import numpy as np
from src.config import Config
from src.ml.hybrid_ml_processor import HybridMLProcessor
from src.utils.pragmatic_resource_pool import PragmaticResourcePool
from src.core.on_demand_cache_warmer import OnDemandCacheWarmer


class MockMLModel:
    """æ¨¡æ‹ŸMLæ¨¡å‹ç”¨äºæµ‹è¯•"""
    def predict(self, features):
        """å•ä¸ªé¢„æµ‹"""
        time.sleep(0.01)  # æ¨¡æ‹Ÿè®¡ç®—æ—¶é—´
        return 0.75
    
    def predict_batch(self, features_batch):
        """æ‰¹é‡é¢„æµ‹"""
        time.sleep(0.015 * len(features_batch))  # æ‰¹é‡ç¨å¿«
        return [0.75 + i * 0.01 for i in range(len(features_batch))]


class MockCache:
    """æ¨¡æ‹Ÿç¼“å­˜ç®¡ç†å™¨"""
    def __init__(self):
        self.cache = {}
        self.hits = 0
        self.misses = 0
    
    def get(self, symbol, timeframe):
        key = f"{symbol}_{timeframe}"
        if key in self.cache:
            self.hits += 1
            return self.cache[key]
        self.misses += 1
        return None
    
    def prefetch(self, symbol, timeframe):
        key = f"{symbol}_{timeframe}"
        self.cache[key] = {"data": "cached"}
    
    def get_latest_timestamp(self, symbol, timeframe):
        return time.time()


def test_hybrid_ml_processor():
    """æµ‹è¯•HybridMLProcessor"""
    print("\n" + "="*60)
    print("æµ‹è¯•1: HybridMLProcessor (æ··åˆæ‰¹é‡MLæ¨ç†)")
    print("="*60)
    
    model = MockMLModel()
    processor = HybridMLProcessor(
        model=model,
        batch_size=5,
        max_buffer_time=0.1,
        enable_batching=True
    )
    
    # æµ‹è¯•åœºæ™¯1ï¼šå•ä¸ªé¢„æµ‹ï¼ˆæ‰¹é‡æœªæ»¡ï¼‰
    print("\nåœºæ™¯1: å•ä¸ªé¢„æµ‹ï¼ˆæ‰¹é‡æœªæ»¡ï¼‰")
    start = time.time()
    result1 = processor.predict("BTCUSDT", {"feature1": 1.0})
    elapsed1 = time.time() - start
    print(f"  ç»“æœ: {result1:.2f}, è€—æ—¶: {elapsed1*1000:.1f}ms")
    
    # æµ‹è¯•åœºæ™¯2ï¼šè§¦å‘æ‰¹é‡å¤„ç†
    print("\nåœºæ™¯2: è¿ç»­5ä¸ªé¢„æµ‹ï¼ˆè§¦å‘æ‰¹é‡ï¼‰")
    start = time.time()
    symbols = ["BTCUSDT", "ETHUSDT", "BNBUSDT", "ADAUSDT", "SOLUSDT"]
    results = []
    for symbol in symbols:
        result = processor.predict(symbol, {"feature1": 1.0})
        results.append(result)
    elapsed2 = time.time() - start
    print(f"  ç»“æœ: {[f'{r:.2f}' for r in results]}")
    print(f"  æ€»è€—æ—¶: {elapsed2*1000:.1f}ms, å¹³å‡: {elapsed2/5*1000:.1f}ms/ä¸ª")
    
    # Flushå‰©ä½™è¯·æ±‚
    processor.flush()
    
    # æ‰“å°ç»Ÿè®¡
    processor.log_stats()
    
    return processor.get_stats()


def test_pragmatic_resource_pool():
    """æµ‹è¯•PragmaticResourcePool"""
    print("\n" + "="*60)
    print("æµ‹è¯•2: PragmaticResourcePool (å®ç”¨ä¸»ä¹‰èµ„æºæ± )")
    print("="*60)
    
    pool = PragmaticResourcePool(
        array_pool_size=10,
        feature_buffer_pool_size=20,
        kline_buffer_pool_size=15,
        enable_pooling=True
    )
    
    # æµ‹è¯•ç§»åŠ¨å¹³å‡è®¡ç®—ï¼ˆä½¿ç”¨æ± åŒ–æ•°ç»„ï¼‰
    print("\nåœºæ™¯1: æ± åŒ–numpyæ•°ç»„è®¡ç®—")
    price_data = np.random.randn(100) * 100 + 50000
    
    start = time.time()
    for i in range(10):
        ma = pool.compute_moving_average_optimized(price_data, window=20)
    elapsed_pooled = time.time() - start
    print(f"  æ± åŒ–ç‰ˆæœ¬: 10æ¬¡è®¡ç®—è€—æ—¶ {elapsed_pooled*1000:.2f}ms")
    
    # å¯¹æ¯”æ ‡å‡†ç‰ˆæœ¬
    start = time.time()
    for i in range(10):
        ma = pool._compute_ma_standard(price_data, window=20)
    elapsed_standard = time.time() - start
    print(f"  æ ‡å‡†ç‰ˆæœ¬: 10æ¬¡è®¡ç®—è€—æ—¶ {elapsed_standard*1000:.2f}ms")
    print(f"  æ€§èƒ½æå‡: {(elapsed_standard/elapsed_pooled - 1)*100:.1f}%")
    
    # æµ‹è¯•ç‰¹å¾æ„å»º
    print("\nåœºæ™¯2: æ± åŒ–ç‰¹å¾å­—å…¸æ„å»º")
    
    def extract_features(data):
        return {"f1": 1.0, "f2": 2.0, "f3": 3.0}
    
    market_data = {"price": 50000}
    extractors = [extract_features]
    
    start = time.time()
    for i in range(100):
        features = pool.build_features_optimized(market_data, extractors)
    elapsed = time.time() - start
    print(f"  100æ¬¡ç‰¹å¾æ„å»ºè€—æ—¶: {elapsed*1000:.2f}ms")
    
    # æ‰“å°æ± ç»Ÿè®¡
    pool.log_stats()
    
    return pool.get_pool_stats()


def test_on_demand_cache_warmer():
    """æµ‹è¯•OnDemandCacheWarmer"""
    print("\n" + "="*60)
    print("æµ‹è¯•3: OnDemandCacheWarmer (äº‹ä»¶é©±åŠ¨ç¼“å­˜é¢„çƒ­)")
    print("="*60)
    
    cache = MockCache()
    warmer = OnDemandCacheWarmer(
        cache_manager=cache,
        warm_threshold=3,
        cooldown_seconds=1,
        top_n_warm=3,
        enable_warming=True
    )
    
    # åœºæ™¯1: è®°å½•å¸‚åœºæ‰«æ
    print("\nåœºæ™¯1: æ¨¡æ‹Ÿå¸‚åœºæ‰«æè§¦å‘é¢„çƒ­")
    symbols = ["BTCUSDT", "ETHUSDT", "BNBUSDT"]
    
    # æ‰«æ3æ¬¡ï¼ˆæœªè¾¾é˜ˆå€¼ï¼‰
    for i in range(3):
        warmer.record_market_scan(symbols, "1m")
        print(f"  æ‰«æ #{i+1}")
    
    # ç¬¬4æ¬¡æ‰«æåº”è§¦å‘é¢„çƒ­
    print("  æ‰«æ #4 (åº”è§¦å‘é¢„çƒ­)")
    warmer.record_market_scan(symbols, "1m")
    
    # æ£€æŸ¥ç¼“å­˜å‘½ä¸­ç‡
    time.sleep(0.1)  # ç­‰å¾…é¢„çƒ­å®Œæˆ
    
    # åœºæ™¯2: äº¤æ˜“ä¿¡å·è§¦å‘é¢„çƒ­
    print("\nåœºæ™¯2: äº¤æ˜“ä¿¡å·è§¦å‘ç«‹å³é¢„çƒ­")
    warmer.record_trading_signal("ADAUSDT", "1m")
    
    # æ‰“å°ç»Ÿè®¡
    warmer.log_stats()
    
    return warmer.get_stats()


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("\n" + "="*60)
    print("ğŸš€ v4.6.0 Phase 1A3-1A5 å®ç”¨ä¸»ä¹‰ç‰ˆæœ¬é›†æˆæµ‹è¯•")
    print("="*60)
    
    # æ‰“å°é…ç½®
    print(f"\né…ç½®çŠ¶æ€:")
    print(f"  HYBRID_ML_ENABLED: {Config.HYBRID_ML_ENABLED}")
    print(f"  HYBRID_ML_BATCH_SIZE: {Config.HYBRID_ML_BATCH_SIZE}")
    print(f"  PRAGMATIC_POOL_ENABLED: {Config.PRAGMATIC_POOL_ENABLED}")
    print(f"  ON_DEMAND_CACHE_WARMING: {Config.ON_DEMAND_CACHE_WARMING}")
    
    # è¿è¡Œæµ‹è¯•
    stats1 = test_hybrid_ml_processor()
    stats2 = test_pragmatic_resource_pool()
    stats3 = test_on_demand_cache_warmer()
    
    # æ±‡æ€»ç»“æœ
    print("\n" + "="*60)
    print("ğŸ“Š æµ‹è¯•æ±‡æ€»")
    print("="*60)
    
    print(f"\n1. HybridMLProcessor:")
    print(f"   - æ‰¹é‡æ•ˆç‡: {stats1['batch_efficiency']:.1f}%")
    print(f"   - ç¼“å­˜å‘½ä¸­ç‡: {stats1['cache_hit_rate']:.1f}%")
    print(f"   - æ€»é¢„æµ‹æ•°: {stats1['total_predictions']}")
    
    print(f"\n2. PragmaticResourcePool:")
    if stats2['enabled']:
        print(f"   - å¯ç”¨çŠ¶æ€: âœ…")
        for pool_name, pool_stats in stats2['pools'].items():
            print(f"   - {pool_name}: å¤ç”¨ç‡ {pool_stats['reuse_rate']*100:.1f}%")
    else:
        print(f"   - å¯ç”¨çŠ¶æ€: âŒ")
    
    print(f"\n3. OnDemandCacheWarmer:")
    print(f"   - é¢„çƒ­è§¦å‘: {stats3['warmings_triggered']}æ¬¡")
    print(f"   - æˆåŠŸç‡: {stats3['warm_success_rate']:.1f}%")
    print(f"   - è®¿é—®æ¨¡å¼: {stats3['access_patterns_count']}ä¸ª")
    
    print("\n" + "="*60)
    print("âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
    print("="*60)


if __name__ == "__main__":
    main()
