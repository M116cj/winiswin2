"""
æ€§èƒ½ç›£æ§å™¨ï¼ˆv3.3.7å„ªåŒ–ç‰ˆï¼‰
è·è²¬ï¼šç³»çµ±æ€§èƒ½æŒ‡æ¨™è¿½è¹¤ã€è³‡æºä½¿ç”¨ç›£æ§ã€ç“¶é ¸æª¢æ¸¬ã€å¯¦æ™‚æ€§èƒ½è¿½è¸ª
"""

import psutil
import asyncio
import logging
from typing import Dict, List, Optional
from datetime import datetime
import time
from collections import deque

logger = logging.getLogger(__name__)


class OperationTimer:
    """æ“ä½œè¨ˆæ™‚å™¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
    
    def __init__(self, monitor: 'PerformanceMonitor', operation_name: str):
        self.monitor = monitor
        self.operation_name = operation_name
        self.start_time = None
    
    def __enter__(self):
        self.start_time = time.time()
        return self
    
    def __exit__(self, *args):
        duration = time.time() - self.start_time
        self.monitor.record_operation(self.operation_name, duration)


class PerformanceMonitor:
    """ç³»çµ±æ€§èƒ½ç›£æ§å™¨ï¼ˆv3.3.7å¢å¼·ç‰ˆï¼‰"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ€§èƒ½ç›£æ§å™¨"""
        self.start_time = time.time()
        
        # åŸºç¤çµ±è¨ˆ
        self.total_signals_generated = 0
        self.total_trades_executed = 0
        self.total_api_calls = 0
        self.total_errors = 0
        
        # âœ¨ v3.3.7æ–°å¢ï¼šè©³ç´°æ€§èƒ½è¿½è¸ª
        self.operation_times = deque(maxlen=1000)  # æœ€è¿‘1000æ¬¡æ“ä½œ
        self.cache_hits = 0
        self.cache_misses = 0
        self.total_latency = 0.0
        self.operation_count = 0
        
        # æ“ä½œé¡å‹çµ±è¨ˆ
        self.operation_stats = {}  # {operation_name: [durations]}
    
    def get_system_metrics(self) -> Dict:
        """
        ç²å–ç³»çµ±è³‡æºä½¿ç”¨æŒ‡æ¨™
        
        Returns:
            Dict: ç³»çµ±æŒ‡æ¨™
        """
        try:
            cpu_percent = psutil.cpu_percent(interval=1)
            cpu_count = psutil.cpu_count()
            
            memory = psutil.virtual_memory()
            memory_percent = memory.percent
            memory_used_gb = memory.used / (1024 ** 3)
            memory_total_gb = memory.total / (1024 ** 3)
            
            disk = psutil.disk_usage('/')
            disk_percent = disk.percent
            
            net_io = psutil.net_io_counters()
            
            metrics = {
                'timestamp': datetime.now().isoformat(),
                'cpu': {
                    'percent': cpu_percent,
                    'count': cpu_count,
                    'per_core': psutil.cpu_percent(percpu=True)
                },
                'memory': {
                    'percent': memory_percent,
                    'used_gb': round(memory_used_gb, 2),
                    'total_gb': round(memory_total_gb, 2),
                    'available_gb': round(memory.available / (1024 ** 3), 2)
                },
                'disk': {
                    'percent': disk_percent,
                    'used_gb': round(disk.used / (1024 ** 3), 2),
                    'total_gb': round(disk.total / (1024 ** 3), 2)
                },
                'network': {
                    'bytes_sent_mb': round(net_io.bytes_sent / (1024 ** 2), 2),
                    'bytes_recv_mb': round(net_io.bytes_recv / (1024 ** 2), 2)
                }
            }
            
            return metrics
            
        except Exception as e:
            logger.error(f"ç²å–ç³»çµ±æŒ‡æ¨™å¤±æ•—: {e}")
            return {}
    
    def get_application_metrics(self) -> Dict:
        """
        ç²å–æ‡‰ç”¨ç¨‹åºæ€§èƒ½æŒ‡æ¨™
        
        Returns:
            Dict: æ‡‰ç”¨ç¨‹åºæŒ‡æ¨™
        """
        uptime_seconds = time.time() - self.start_time
        uptime_hours = uptime_seconds / 3600
        
        metrics = {
            'uptime': {
                'seconds': round(uptime_seconds, 2),
                'hours': round(uptime_hours, 2),
                'days': round(uptime_hours / 24, 2)
            },
            'statistics': {
                'signals_generated': self.total_signals_generated,
                'trades_executed': self.total_trades_executed,
                'api_calls': self.total_api_calls,
                'errors': self.total_errors
            },
            'rates': {
                'signals_per_hour': round(self.total_signals_generated / max(uptime_hours, 0.01), 2),
                'trades_per_hour': round(self.total_trades_executed / max(uptime_hours, 0.01), 2)
            }
        }
        
        return metrics
    
    def record_signal(self):
        """è¨˜éŒ„ä¿¡è™Ÿç”Ÿæˆ"""
        self.total_signals_generated += 1
    
    def record_trade(self):
        """è¨˜éŒ„äº¤æ˜“åŸ·è¡Œ"""
        self.total_trades_executed += 1
    
    def record_api_call(self):
        """è¨˜éŒ„ API èª¿ç”¨"""
        self.total_api_calls += 1
    
    def record_error(self):
        """è¨˜éŒ„éŒ¯èª¤"""
        self.total_errors += 1
    
    def record_operation(self, operation_name: str, duration: float):
        """
        è¨˜éŒ„æ“ä½œæ™‚é–“ï¼ˆv3.3.7æ–°å¢ï¼‰
        
        Args:
            operation_name: æ“ä½œåç¨±
            duration: æŒçºŒæ™‚é–“ï¼ˆç§’ï¼‰
        """
        self.operation_times.append({
            'name': operation_name,
            'duration': duration,
            'timestamp': time.time()
        })
        
        self.total_latency += duration
        self.operation_count += 1
        
        # è¨˜éŒ„åˆ°æ“ä½œçµ±è¨ˆ
        if operation_name not in self.operation_stats:
            self.operation_stats[operation_name] = deque(maxlen=100)
        self.operation_stats[operation_name].append(duration)
    
    def track_operation(self, operation_name: str) -> OperationTimer:
        """
        è¿½è¹¤æ“ä½œæ™‚é–“çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼ˆv3.3.7æ–°å¢ï¼‰
        
        Args:
            operation_name: æ“ä½œåç¨±
        
        Returns:
            OperationTimer: è¨ˆæ™‚å™¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨
        
        Example:
            with perf_monitor.track_operation("get_klines_BTCUSDT"):
                data = await client.get_klines(...)
        """
        return OperationTimer(self, operation_name)
    
    def record_cache_hit(self):
        """è¨˜éŒ„ç·©å­˜å‘½ä¸­ï¼ˆv3.3.7æ–°å¢ï¼‰"""
        self.cache_hits += 1
    
    def record_cache_miss(self):
        """è¨˜éŒ„ç·©å­˜æœªå‘½ä¸­ï¼ˆv3.3.7æ–°å¢ï¼‰"""
        self.cache_misses += 1
    
    def get_cache_hit_rate(self) -> float:
        """
        ç²å–ç·©å­˜å‘½ä¸­ç‡ï¼ˆv3.3.7æ–°å¢ï¼‰
        
        Returns:
            float: ç·©å­˜å‘½ä¸­ç‡ï¼ˆ0.0-1.0ï¼‰
        """
        total = self.cache_hits + self.cache_misses
        if total == 0:
            return 0.0
        return self.cache_hits / total
    
    def get_avg_latency(self) -> float:
        """
        ç²å–å¹³å‡å»¶é²ï¼ˆv3.3.7æ–°å¢ï¼‰
        
        Returns:
            float: å¹³å‡å»¶é²ï¼ˆæ¯«ç§’ï¼‰
        """
        if self.operation_count == 0:
            return 0.0
        return (self.total_latency / self.operation_count) * 1000
    
    def get_operation_stats(self, operation_name: str) -> Dict:
        """
        ç²å–ç‰¹å®šæ“ä½œçš„çµ±è¨ˆä¿¡æ¯ï¼ˆv3.3.7æ–°å¢ï¼‰
        
        Args:
            operation_name: æ“ä½œåç¨±
        
        Returns:
            Dict: çµ±è¨ˆä¿¡æ¯
        """
        if operation_name not in self.operation_stats:
            return {}
        
        durations = list(self.operation_stats[operation_name])
        if not durations:
            return {}
        
        return {
            'count': len(durations),
            'avg_ms': sum(durations) / len(durations) * 1000,
            'min_ms': min(durations) * 1000,
            'max_ms': max(durations) * 1000,
            'total_s': sum(durations)
        }
    
    def detect_bottlenecks(self) -> List[str]:
        """
        æª¢æ¸¬æ€§èƒ½ç“¶é ¸ï¼ˆv3.3.7æ–°å¢ï¼‰
        
        Returns:
            List[str]: ç“¶é ¸åˆ—è¡¨
        """
        bottlenecks = []
        
        # 1. æª¢æŸ¥å¹³å‡å»¶é²
        avg_latency_ms = self.get_avg_latency()
        if avg_latency_ms > 1000:  # è¶…é1ç§’
            bottlenecks.append(
                f"âš ï¸  å¹³å‡æ“ä½œå»¶é²éé«˜: {avg_latency_ms:.0f}ms"
            )
        
        # 2. æª¢æŸ¥ç·©å­˜å‘½ä¸­ç‡
        cache_hit_rate = self.get_cache_hit_rate()
        if cache_hit_rate < 0.5 and (self.cache_hits + self.cache_misses) > 100:
            bottlenecks.append(
                f"âš ï¸  ç·©å­˜å‘½ä¸­ç‡éä½: {cache_hit_rate:.1%}"
            )
        
        # 3. æª¢æŸ¥CPUä½¿ç”¨
        try:
            cpu = psutil.cpu_percent(interval=0.1)
            if cpu > 90:
                bottlenecks.append(f"âš ï¸  CPUä½¿ç”¨ç‡éé«˜: {cpu:.1f}%")
        except:
            pass
        
        # 4. æª¢æŸ¥å…§å­˜ä½¿ç”¨
        try:
            mem = psutil.virtual_memory().percent
            if mem > 85:
                bottlenecks.append(f"âš ï¸  å…§å­˜ä½¿ç”¨ç‡éé«˜: {mem:.1f}%")
        except:
            pass
        
        # 5. æª¢æŸ¥æ…¢æ“ä½œ
        for op_name, durations in self.operation_stats.items():
            if durations:
                avg_duration = sum(durations) / len(durations)
                if avg_duration > 2.0:  # è¶…é2ç§’
                    bottlenecks.append(
                        f"âš ï¸  æ“ä½œéæ…¢: {op_name} ({avg_duration:.2f}s)"
                    )
        
        return bottlenecks
    
    def generate_recommendations(self, bottlenecks: List[str]) -> List[str]:
        """
        ç”Ÿæˆå„ªåŒ–å»ºè­°ï¼ˆv3.3.7æ–°å¢ï¼‰
        
        Args:
            bottlenecks: ç“¶é ¸åˆ—è¡¨
        
        Returns:
            List[str]: å„ªåŒ–å»ºè­°
        """
        recommendations = []
        
        for bottleneck in bottlenecks:
            if 'CPU' in bottleneck:
                recommendations.append("ğŸ’¡ å»ºè­°: æ¸›å°‘ä¸¦è¡Œå·¥ä½œç·šç¨‹æ•¸æˆ–å„ªåŒ–CPUå¯†é›†å‹æ“ä½œ")
            elif 'ç·©å­˜' in bottleneck:
                recommendations.append("ğŸ’¡ å»ºè­°: å¢åŠ ç·©å­˜TTLæˆ–é å–æ•¸æ“š")
            elif 'å»¶é²' in bottleneck or 'æ“ä½œéæ…¢' in bottleneck:
                recommendations.append("ğŸ’¡ å»ºè­°: å•Ÿç”¨æ•¸æ“šé å–ã€å¢åŠ æ‰¹æ¬¡å¤§å°æˆ–å„ªåŒ–ç®—æ³•")
            elif 'å…§å­˜' in bottleneck:
                recommendations.append("ğŸ’¡ å»ºè­°: å•Ÿç”¨æµå¼è™•ç†æˆ–æ¸›å°æ‰¹æ¬¡å¤§å°")
        
        return recommendations
    
    def get_full_report(self) -> Dict:
        """
        ç²å–å®Œæ•´æ€§èƒ½å ±å‘Šï¼ˆv3.3.7å¢å¼·ç‰ˆï¼‰
        
        Returns:
            Dict: å®Œæ•´å ±å‘Š
        """
        bottlenecks = self.detect_bottlenecks()
        
        return {
            'system': self.get_system_metrics(),
            'application': self.get_application_metrics(),
            'performance': {
                'avg_latency_ms': self.get_avg_latency(),
                'cache_hit_rate': self.get_cache_hit_rate(),
                'operations_per_second': (
                    self.operation_count / 
                    max(time.time() - self.start_time, 1)
                ),
                'total_operations': self.operation_count
            },
            'bottlenecks': bottlenecks,
            'recommendations': self.generate_recommendations(bottlenecks)
        }
    
    def log_metrics(self):
        """è¨˜éŒ„æ€§èƒ½æŒ‡æ¨™åˆ°æ—¥èªŒï¼ˆv3.3.7å¢å¼·ç‰ˆï¼‰"""
        try:
            metrics = self.get_full_report()
            
            logger.info("=" * 60)
            logger.info("ğŸ“Š æ€§èƒ½ç›£æ§å ±å‘Š (v3.3.7)")
            logger.info("=" * 60)
            
            sys_metrics = metrics.get('system', {})
            app_metrics = metrics.get('application', {})
            perf_metrics = metrics.get('performance', {})
            
            # CPU
            cpu = sys_metrics.get('cpu', {})
            logger.info(f"CPU: {cpu.get('percent', 0):.1f}% ({cpu.get('count', 0)} æ ¸å¿ƒ)")
            
            # å…§å­˜
            mem = sys_metrics.get('memory', {})
            logger.info(
                f"å…§å­˜: {mem.get('used_gb', 0):.2f}/{mem.get('total_gb', 0):.2f} GB "
                f"({mem.get('percent', 0):.1f}%)"
            )
            
            # æ‡‰ç”¨çµ±è¨ˆ
            uptime = app_metrics.get('uptime', {})
            stats = app_metrics.get('statistics', {})
            rates = app_metrics.get('rates', {})
            
            logger.info(f"é‹è¡Œæ™‚é–“: {uptime.get('hours', 0):.2f} å°æ™‚")
            logger.info(f"ä¿¡è™Ÿç”Ÿæˆ: {stats.get('signals_generated', 0)} å€‹")
            logger.info(f"äº¤æ˜“åŸ·è¡Œ: {stats.get('trades_executed', 0)} ç­†")
            logger.info(f"API èª¿ç”¨: {stats.get('api_calls', 0)} æ¬¡")
            logger.info(f"ä¿¡è™Ÿé€Ÿç‡: {rates.get('signals_per_hour', 0):.2f} å€‹/å°æ™‚")
            
            # âœ¨ v3.3.7æ–°å¢ï¼šæ€§èƒ½æŒ‡æ¨™
            logger.info("â”€" * 60)
            logger.info("âš¡ æ€§èƒ½æŒ‡æ¨™:")
            logger.info(f"  å¹³å‡å»¶é²: {perf_metrics.get('avg_latency_ms', 0):.2f}ms")
            logger.info(f"  ç·©å­˜å‘½ä¸­ç‡: {perf_metrics.get('cache_hit_rate', 0):.1%}")
            logger.info(f"  æ“ä½œé€Ÿç‡: {perf_metrics.get('operations_per_second', 0):.2f} ops/s")
            logger.info(f"  ç¸½æ“ä½œæ•¸: {perf_metrics.get('total_operations', 0)}")
            
            # âœ¨ v3.3.7æ–°å¢ï¼šç“¶é ¸å’Œå»ºè­°
            bottlenecks = metrics.get('bottlenecks', [])
            if bottlenecks:
                logger.info("â”€" * 60)
                logger.warning("âš ï¸  æª¢æ¸¬åˆ°æ€§èƒ½ç“¶é ¸:")
                for bottleneck in bottlenecks:
                    logger.warning(f"  {bottleneck}")
                
                recommendations = metrics.get('recommendations', [])
                if recommendations:
                    logger.info("ğŸ’¡ å„ªåŒ–å»ºè­°:")
                    for rec in recommendations:
                        logger.info(f"  {rec}")
            else:
                logger.info("â”€" * 60)
                logger.info("âœ… ç³»çµ±æ€§èƒ½è‰¯å¥½ï¼Œç„¡æ˜é¡¯ç“¶é ¸")
            
            logger.info("=" * 60)
            
        except Exception as e:
            logger.error(f"è¨˜éŒ„æ€§èƒ½æŒ‡æ¨™å¤±æ•—: {e}")
    
    async def start_monitoring(self, interval: int = 300):
        """
        å•Ÿå‹•å®šæœŸç›£æ§ï¼ˆæ¯ 5 åˆ†é˜ï¼‰
        
        Args:
            interval: ç›£æ§é–“éš”ï¼ˆç§’ï¼‰
        """
        logger.info(f"å•Ÿå‹•æ€§èƒ½ç›£æ§ï¼Œé–“éš” {interval} ç§’")
        
        while True:
            try:
                await asyncio.sleep(interval)
                self.log_metrics()
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"æ€§èƒ½ç›£æ§ç•°å¸¸: {e}")
