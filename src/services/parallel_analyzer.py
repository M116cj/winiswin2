"""
ä¸¦è¡Œåˆ†æå™¨ï¼ˆv3.16.1 BrokenProcessPool ä¿®å¤ç‰ˆï¼‰
è·è²¬ï¼šæ‰¹é‡è™•ç†å¤§é‡äº¤æ˜“å°åˆ†æã€è‡ªå‹•é‡å»ºæå£é€²ç¨‹æ± ã€å…§å­˜ç›£æ§

v3.16.1 ä¿®å¾©ï¼š
- é‡æ–°å•Ÿç”¨é€²ç¨‹æ± ï¼ˆä½¿ç”¨å®‰å…¨æäº¤æ©Ÿåˆ¶ï¼‰
- æ·»åŠ  BrokenProcessPool è‡ªå‹•æ¢å¾©
- æ·»åŠ å­é€²ç¨‹å…§å­˜ç›£æ§
- æ·»åŠ  fallback é™ç´šç­–ç•¥
- æ·»åŠ è¶…æ™‚æ©Ÿåˆ¶ï¼ˆ30ç§’/ä»»å‹™ï¼‰
"""

import asyncio
from typing import List, Dict, Optional
import logging
import time
from concurrent.futures import BrokenProcessPool, TimeoutError

from src.core.global_pool import GlobalProcessPool
from src.config import Config

logger = logging.getLogger(__name__)


class ParallelAnalyzer:
    """ä¸¦è¡Œåˆ†æå™¨ - v3.16.1 BrokenProcessPool ä¿®å¾©ç‰ˆ"""
    
    def __init__(self, max_workers: Optional[int] = None, perf_monitor=None):
        """
        åˆå§‹åŒ–ä¸¦è¡Œåˆ†æå™¨
        
        Args:
            max_workers: æœ€å¤§å·¥ä½œé€²ç¨‹æ•¸ï¼ˆæœªä½¿ç”¨ï¼Œç”± GlobalProcessPool ç®¡ç†ï¼‰
            perf_monitor: æ€§èƒ½ç›£æ§å™¨
        """
        self.config = Config
        self.global_pool = GlobalProcessPool()
        self._model_path = "data/models/model.onnx"
        
        # âœ¨ æ€§èƒ½ç›£æ§
        self.perf_monitor = perf_monitor
        
        logger.info("âœ… ä¸¦è¡Œåˆ†æå™¨åˆå§‹åŒ–: ä½¿ç”¨å…¨å±€é€²ç¨‹æ± ï¼ˆv3.16.1 å®‰å…¨ç‰ˆæœ¬ï¼‰")
        logger.info(f"   é€²ç¨‹æ± ç‹€æ…‹: {self.global_pool.get_pool_health()}")
    
    async def analyze_batch(
        self,
        symbols_data: List[Dict],
        data_manager
    ) -> List[Dict]:
        """
        æ‰¹é‡ä¸¦è¡Œåˆ†æå¤šå€‹äº¤æ˜“å°ï¼ˆv3.16.1 å®‰å…¨ç‰ˆæœ¬ï¼‰
        
        Args:
            symbols_data: äº¤æ˜“å°åˆ—è¡¨
            data_manager: æ•¸æ“šç®¡ç†å™¨å¯¦ä¾‹
        
        Returns:
            List[Dict]: ç”Ÿæˆçš„äº¤æ˜“ä¿¡è™Ÿåˆ—è¡¨
        """
        try:
            start_time = time.time()
            total_symbols = len(symbols_data)
            
            logger.info(f"é–‹å§‹æ‰¹é‡åˆ†æ {total_symbols} å€‹äº¤æ˜“å°")
            
            signals = []
            loop = asyncio.get_event_loop()
            tasks = []
            
            # ğŸ”¥ æ­¥é©Ÿ1ï¼šä¸¦è¡Œç²å–æ‰€æœ‰æ•¸æ“š
            data_tasks = [
                data_manager.get_multi_timeframe_data(item['symbol'])
                for item in symbols_data
            ]
            
            multi_tf_data_list = await asyncio.gather(*data_tasks, return_exceptions=True)
            
            # ğŸ”¥ æ­¥é©Ÿ2ï¼šæäº¤æ‰€æœ‰åˆ†æä»»å‹™ï¼ˆä½¿ç”¨å®‰å…¨æäº¤ï¼‰
            for i, multi_tf_data in enumerate(multi_tf_data_list):
                # æª¢æŸ¥æ•¸æ“šæœ‰æ•ˆæ€§
                if isinstance(multi_tf_data, Exception) or multi_tf_data is None:
                    continue
                
                symbol = symbols_data[i]['symbol']
                symbol_data = {
                    'symbol': symbol,
                    'data': multi_tf_data
                }
                
                # ğŸ”¥ ä½¿ç”¨å®‰å…¨æäº¤ï¼ˆè‡ªå‹•è™•ç† BrokenProcessPoolï¼‰
                future = self.global_pool.submit_safe(
                    self._analyze_single_symbol,
                    symbol_data,
                    self._model_path,
                    self.config.__dict__
                )
                tasks.append((symbol, future))
            
            # ğŸ”¥ æ­¥é©Ÿ3ï¼šæ”¶é›†çµæœï¼ˆå¸¶è¶…æ™‚æ©Ÿåˆ¶ï¼‰
            for symbol, future in tasks:
                try:
                    # 30ç§’è¶…æ™‚
                    result = await loop.run_in_executor(None, future.result, 30)
                    if result:
                        signals.append(result)
                except TimeoutError:
                    logger.warning(f"âš ï¸ åˆ†æ {symbol} è¶…æ™‚ï¼ˆ30ç§’ï¼‰")
                except BrokenProcessPool:
                    logger.error(f"âŒ é€²ç¨‹æ± æå£ï¼ˆåˆ†æ {symbol}ï¼‰ï¼Œè·³éå‰©é¤˜ä»»å‹™")
                    break
                except Exception as e:
                    logger.error(f"âŒ åˆ†æ {symbol} å¤±æ•—: {e}")
            
            # âœ¨ æ€§èƒ½çµ±è¨ˆ
            total_duration = time.time() - start_time
            avg_per_symbol = total_duration / max(total_symbols, 1)
            
            logger.info(
                f"âœ… æ‰¹é‡åˆ†æå®Œæˆ: åˆ†æ {total_symbols} å€‹äº¤æ˜“å°, "
                f"ç”Ÿæˆ {len(signals)} å€‹ä¿¡è™Ÿ "
                f"âš¡ ç¸½è€—æ™‚: {total_duration:.2f}s "
                f"(å¹³å‡ {avg_per_symbol*1000:.1f}ms/äº¤æ˜“å°)"
            )
            
            # âœ¨ è¨˜éŒ„æ€§èƒ½
            if self.perf_monitor:
                self.perf_monitor.record_operation("analyze_batch", total_duration)
            
            return signals
            
        except BrokenProcessPool:
            logger.error("âŒ é€²ç¨‹æ± æå£ï¼Œè·³éæœ¬æ¬¡åˆ†æ")
            return []
        except Exception as e:
            logger.error(f"âŒ æ‰¹é‡åˆ†æå¤±æ•—: {e}", exc_info=True)
            return []
    
    @staticmethod
    def _analyze_single_symbol(symbol_data: Dict, model_path: str, config_dict: Dict) -> Optional[Dict]:
        """
        å–®ç¬¦è™Ÿåˆ†æ - å­é€²ç¨‹åŸ·è¡Œï¼ˆv3.16.1 å…§å­˜ç›£æ§ç‰ˆæœ¬ï¼‰
        
        Args:
            symbol_data: ç¬¦è™Ÿæ•¸æ“š {'symbol': str, 'data': dict}
            model_path: æ¨¡å‹è·¯å¾‘
            config_dict: é…ç½®å­—å…¸
        
        Returns:
            Optional[Dict]: äº¤æ˜“ä¿¡è™Ÿ
        """
        try:
            # ğŸ”¥ æ·»åŠ è¨˜æ†¶é«”ç›£æ§
            try:
                import psutil
                process = psutil.Process()
                initial_memory = process.memory_info().rss / 1024 / 1024  # MB
            except ImportError:
                initial_memory = None
            
            # é‡å»ºé…ç½®
            from src.config import Config
            config = Config()
            for key, value in config_dict.items():
                if hasattr(config, key):
                    setattr(config, key, value)
            
            # ğŸ”¥ å˜—è©¦ä½¿ç”¨è‡ªæˆ‘å­¸ç¿’äº¤æ˜“å“¡
            try:
                from src.strategies.self_learning_trader import SelfLearningTrader
                trader = SelfLearningTrader(config)
                result = trader.analyze(symbol_data['symbol'], symbol_data['data'])
                
            except (ImportError, MemoryError) as e:
                # ğŸ”¥ é™ç´šåˆ° ICT ç­–ç•¥
                logger.warning(f"âš ï¸ è‡ªæˆ‘å­¸ç¿’äº¤æ˜“å“¡ä¸å¯ç”¨ ({e})ï¼Œä½¿ç”¨é™ç´šç­–ç•¥")
                result = ParallelAnalyzer._fallback_analysis(symbol_data, config)
            
            # ğŸ”¥ è¨˜æ†¶é«”ç›£æ§
            if initial_memory is not None:
                try:
                    final_memory = process.memory_info().rss / 1024 / 1024  # MB
                    memory_increase = final_memory - initial_memory
                    
                    if memory_increase > 500:  # è¨˜æ†¶é«”å¢åŠ è¶…é 500MB
                        logger.warning(
                            f"âš ï¸ è¨˜æ†¶é«”æ´©æ¼è­¦å‘Š {symbol_data['symbol']}: +{memory_increase:.1f}MB"
                        )
                except Exception:
                    pass
            
            return result
            
        except MemoryError:
            logger.error(f"âŒ è¨˜æ†¶é«”ä¸è¶³: {symbol_data['symbol']}")
            return None
        except ImportError as e:
            logger.warning(f"âš ï¸ æ¨¡çµ„å°å…¥éŒ¯èª¤: {e}")
            # ä½¿ç”¨ fallback ç­–ç•¥
            try:
                return ParallelAnalyzer._fallback_analysis(symbol_data, config_dict)
            except Exception:
                return None
        except Exception as e:
            logger.error(f"âŒ åˆ†æéŒ¯èª¤ {symbol_data['symbol']}: {e}")
            return None
    
    @staticmethod
    def _fallback_analysis(symbol_data: Dict, config_or_dict) -> Optional[Dict]:
        """
        é™ç´šåˆ†æç­–ç•¥ï¼ˆç•¶æ·±åº¦å­¸ç¿’ä¸å¯ç”¨æ™‚ï¼‰
        
        Args:
            symbol_data: ç¬¦è™Ÿæ•¸æ“š
            config_or_dict: é…ç½®å°è±¡æˆ–å­—å…¸
        
        Returns:
            Optional[Dict]: äº¤æ˜“ä¿¡è™Ÿ
        """
        try:
            from src.strategies.ict_strategy import ICTStrategy
            from src.config import Config
            
            # è™•ç†é…ç½®
            if isinstance(config_or_dict, dict):
                config = Config()
                for key, value in config_or_dict.items():
                    if hasattr(config, key):
                        setattr(config, key, value)
            else:
                config = config_or_dict
            
            trader = ICTStrategy(config)
            result = trader.analyze(symbol_data['symbol'], symbol_data['data'])
            return result
            
        except Exception as e:
            logger.error(f"âŒ é™ç´šåˆ†æå¤±æ•—: {e}")
            return None
    
    async def close(self):
        """
        é—œé–‰åŸ·è¡Œå™¨
        
        æ³¨æ„ï¼šv3.16.1 ä¸é—œé–‰å…¨å±€é€²ç¨‹æ± ï¼ˆç”±æ‡‰ç”¨ç”Ÿå‘½é€±æœŸç®¡ç†ï¼‰
        """
        logger.info("ä¸¦è¡Œåˆ†æå™¨é—œé–‰ï¼ˆå…¨å±€é€²ç¨‹æ± ç¹¼çºŒé‹è¡Œï¼‰")
