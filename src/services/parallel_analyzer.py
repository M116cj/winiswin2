"""
ä¸¦è¡Œåˆ†æå™¨ï¼ˆv3.17+ ThreadPool ç‰ˆæœ¬ï¼‰
è·è²¬ï¼šæ‰¹é‡è™•ç†å¤§é‡äº¤æ˜“å°åˆ†æ

v3.17+ å„ªåŒ–ï¼š
- ä½¿ç”¨å…§å»º ThreadPoolExecutorï¼ˆç„¡å¤–éƒ¨ä¾è³´ï¼‰
- ç§»é™¤æ‰€æœ‰ ProcessPool éºç•™ä»£ç¢¼
- ç¢ºä¿èˆ‡ ICT ç­–ç•¥å…¼å®¹
"""

import asyncio
from typing import List, Dict, Optional
import logging
import time
from concurrent.futures import ThreadPoolExecutor, TimeoutError

from src.config import Config

logger = logging.getLogger(__name__)


# ğŸ”¥ v3.16.2 ä¿®å¾©ï¼šå·¥ä½œå‡½æ•¸ï¼ˆç·šç¨‹æ± ç‰ˆæœ¬ï¼Œç„¡åºåˆ—åŒ–å•é¡Œï¼‰
def _analyze_single_symbol_worker(symbol: str, market_data: dict, config_dict: dict) -> Optional[Dict]:
    """
    å–®å€‹äº¤æ˜“å°åˆ†æï¼ˆç·šç¨‹æ± å·¥ä½œå‡½æ•¸ï¼‰
    
    v3.16.2 ThreadPool ç‰ˆæœ¬ï¼š
    - ä½¿ç”¨ç·šç¨‹æ± ï¼Œå…±äº«å…§å­˜ï¼Œç„¡åºåˆ—åŒ–éœ€æ±‚
    - å¯ä»¥ç›´æ¥ä½¿ç”¨æ¨¡å¡Šç´š loggerï¼ˆç„¡ thread.lock å•é¡Œï¼‰
    - åƒæ•¸ä¿æŒæ‰å¹³åŒ–ä»¥ä¾¿èª¿ç”¨
    
    Args:
        symbol: äº¤æ˜“å°åç¨±ï¼ˆstrï¼‰
        market_data: å¸‚å ´æ•¸æ“šï¼ˆDict[str, Dict[str, Any]]ï¼‰ï¼Œå·²è½‰æ›ç‚ºç´”å­—å…¸
        config_dict: é…ç½®åƒæ•¸ï¼ˆDict[str, Union[int, float, str, bool]]ï¼‰ï¼ŒåªåŒ…å«åŸºæœ¬é¡å‹
    
    Returns:
        Optional[Dict]: äº¤æ˜“ä¿¡è™Ÿ
    """
    # ğŸ”¥ ç·šç¨‹æ± å¯ä»¥ç›´æ¥ä½¿ç”¨ loggerï¼ˆç„¡åºåˆ—åŒ–å•é¡Œï¼‰
    import logging
    import pandas as pd
    
    try:
        # ğŸ”¥ æ­¥é©Ÿ1ï¼šé‡å»º DataFrameï¼ˆå¾ç´”å­—å…¸æ¢å¾©ï¼‰
        reconstructed_data = {}
        for tf_key, tf_dict in market_data.items():
            if tf_dict is not None and isinstance(tf_dict, dict) and 'data' in tf_dict:
                # å¾ç´”å­—å…¸é‡å»º DataFrame
                df = pd.DataFrame(tf_dict['data'])
                if 'index' in tf_dict:
                    df.index = tf_dict['index']
                reconstructed_data[tf_key] = df
            else:
                reconstructed_data[tf_key] = None
        
        # ğŸ”¥ æ­¥é©Ÿ2ï¼šåœ¨ç·šç¨‹å…§é‡å»º Config å°è±¡
        from src.config import Config
        config = Config()
        # æ‡‰ç”¨å‚³å…¥çš„é…ç½®åƒæ•¸
        for key, value in config_dict.items():
            if hasattr(config, key):
                setattr(config, key, value)
        
        # ğŸ”¥ æ­¥é©Ÿ3ï¼šä½¿ç”¨ ICT ç­–ç•¥åŸ·è¡Œåˆ†æ
        result = None
        try:
            from src.strategies.ict_strategy import ICTStrategy
            trader = ICTStrategy()
            result = trader.analyze(symbol, reconstructed_data)
        except Exception as e:
            logger.error(f"âŒ {symbol} ICT ç­–ç•¥åˆ†æå¤±æ•—: {e}")
            result = None
        
        return result
        
    except MemoryError:
        logger.error(f"âŒ {symbol} è¨˜æ†¶é«”ä¸è¶³")
        return None
    except Exception as e:
        logger.error(f"âŒ {symbol} åˆ†æå¤±æ•—: {e}")
        return None


class ParallelAnalyzer:
    """ä¸¦è¡Œåˆ†æå™¨ - v3.17+ ThreadPool ç‰ˆæœ¬"""
    
    def __init__(self, max_workers: Optional[int] = None, perf_monitor=None):
        """
        åˆå§‹åŒ–ä¸¦è¡Œåˆ†æå™¨
        
        Args:
            max_workers: ç·šç¨‹æ± å·¥ä½œç·šç¨‹æ•¸ï¼ˆé è¨­ä½¿ç”¨ Config.MAX_WORKERSï¼‰
            perf_monitor: æ€§èƒ½ç›£æ§å™¨
        """
        self.config = Config()
        self.max_workers = max_workers or Config.MAX_WORKERS
        self.executor = ThreadPoolExecutor(max_workers=self.max_workers)
        
        # âœ¨ æ€§èƒ½ç›£æ§
        self.perf_monitor = perf_monitor
        
        logger.info("âœ… ä¸¦è¡Œåˆ†æå™¨åˆå§‹åŒ–ï¼ˆv3.17+ ThreadPoolï¼‰")
        logger.info(f"   ç·šç¨‹æ± å·¥ä½œç·šç¨‹: {self.max_workers}")
    
    async def analyze_batch(
        self,
        symbols_data: List[Dict],
        data_manager
    ) -> List[Dict]:
        """
        æ‰¹é‡ä¸¦è¡Œåˆ†æå¤šå€‹äº¤æ˜“å°ï¼ˆv3.16.1 å®‰å…¨ç‰ˆæœ¬ï¼‰
        
        Args:
            symbols_data: äº¤æ˜“å°åˆ—è¡¨
            data_manager: æ•¸æ“šç®¡ç†å™¨å¯¦ä¾‹
        
        Returns:
            List[Dict]: ç”Ÿæˆçš„äº¤æ˜“ä¿¡è™Ÿåˆ—è¡¨
        """
        try:
            start_time = time.time()
            total_symbols = len(symbols_data)
            
            logger.info(f"é–‹å§‹æ‰¹é‡åˆ†æ {total_symbols} å€‹äº¤æ˜“å°")
            
            signals = []
            loop = asyncio.get_event_loop()
            tasks = []
            
            # ğŸ”¥ æ­¥é©Ÿ1ï¼šä¸¦è¡Œç²å–æ‰€æœ‰æ•¸æ“š
            data_tasks = [
                data_manager.get_multi_timeframe_data(item['symbol'])
                for item in symbols_data
            ]
            
            multi_tf_data_list = await asyncio.gather(*data_tasks, return_exceptions=True)
            
            # ğŸ”¥ æ­¥é©Ÿ2ï¼šæäº¤æ‰€æœ‰åˆ†æä»»å‹™ï¼ˆä½¿ç”¨å®Œå…¨ç„¡é–‰åŒ…è¨­è¨ˆï¼‰
            for i, multi_tf_data in enumerate(multi_tf_data_list):
                # æª¢æŸ¥æ•¸æ“šæœ‰æ•ˆæ€§
                if isinstance(multi_tf_data, Exception) or multi_tf_data is None:
                    continue
                
                # ç¢ºä¿æ˜¯å­—å…¸é¡å‹
                if not isinstance(multi_tf_data, dict):
                    continue
                
                symbol = symbols_data[i]['symbol']
                
                # ğŸ”¥ è½‰æ› DataFrame ç‚ºç´”å­—å…¸ï¼ˆ100% å¯åºåˆ—åŒ–ï¼‰
                market_data = {}
                for tf_key, df in multi_tf_data.items():
                    if df is not None and hasattr(df, 'to_dict'):
                        # è½‰æ›ç‚ºç´” Python åŸºæœ¬é¡å‹
                        market_data[tf_key] = {
                            'data': df.to_dict('list'),  # list of lists/dicts
                            'index': df.index.tolist() if hasattr(df.index, 'tolist') else list(df.index)
                        }
                    else:
                        market_data[tf_key] = None
                
                # ğŸ”¥ å‰µå»ºé…ç½®å­—å…¸ï¼ˆåªåŒ…å«åŸºæœ¬é¡å‹ï¼šint, float, str, boolï¼‰
                config_dict = {
                    'MIN_CONFIDENCE': float(self.config.MIN_CONFIDENCE),
                    'MAX_LEVERAGE': int(self.config.MAX_LEVERAGE),
                    'MIN_LEVERAGE': int(self.config.MIN_LEVERAGE),
                    'BASE_MARGIN_PCT': float(self.config.BASE_MARGIN_PCT),
                    'MIN_MARGIN_PCT': float(self.config.MIN_MARGIN_PCT),
                    'MAX_MARGIN_PCT': float(self.config.MAX_MARGIN_PCT),
                    'RISK_REWARD_RATIO': float(self.config.RISK_REWARD_RATIO),
                    'TRADING_ENABLED': bool(self.config.TRADING_ENABLED)
                }
                
                # ğŸ”¥ v3.17+: ä½¿ç”¨æ¨™æº–ç·šç¨‹æ± æäº¤ä»»å‹™
                future = self.executor.submit(
                    _analyze_single_symbol_worker,
                    symbol,
                    market_data,
                    config_dict
                )
                tasks.append((symbol, future))
            
            # ğŸ”¥ æ­¥é©Ÿ3ï¼šæ”¶é›†çµæœï¼ˆå¸¶è¶…æ™‚æ©Ÿåˆ¶ï¼‰
            timeout_seconds = self.config.PROCESS_TIMEOUT_SECONDS
            for symbol, future in tasks:
                try:
                    # ä½¿ç”¨é…ç½®çš„è¶…æ™‚æ™‚é–“
                    result = await loop.run_in_executor(None, future.result, timeout_seconds)
                    if result:
                        signals.append(result)
                except TimeoutError:
                    logger.warning(f"âš ï¸ åˆ†æ {symbol} è¶…æ™‚ï¼ˆ{timeout_seconds}ç§’ï¼‰")
                except Exception as e:
                    logger.error(f"âŒ åˆ†æ {symbol} å¤±æ•—: {e}")
            
            # âœ¨ æ€§èƒ½çµ±è¨ˆ
            total_duration = time.time() - start_time
            avg_per_symbol = total_duration / max(total_symbols, 1)
            
            logger.info(
                f"âœ… æ‰¹é‡åˆ†æå®Œæˆ: åˆ†æ {total_symbols} å€‹äº¤æ˜“å°, "
                f"ç”Ÿæˆ {len(signals)} å€‹ä¿¡è™Ÿ "
                f"âš¡ ç¸½è€—æ™‚: {total_duration:.2f}s "
                f"(å¹³å‡ {avg_per_symbol*1000:.1f}ms/äº¤æ˜“å°)"
            )
            
            # âœ¨ è¨˜éŒ„æ€§èƒ½
            if self.perf_monitor:
                self.perf_monitor.record_operation("analyze_batch", total_duration)
            
            return signals
            
        except Exception as e:
            logger.error(f"âŒ æ‰¹é‡åˆ†æå¤±æ•—: {e}", exc_info=True)
            return []
    
    async def close(self):
        """é—œé–‰åŸ·è¡Œå™¨ï¼ˆv3.17+ï¼‰"""
        if self.executor:
            self.executor.shutdown(wait=True)
            logger.info("âœ… ä¸¦è¡Œåˆ†æå™¨ç·šç¨‹æ± å·²é—œé–‰")
