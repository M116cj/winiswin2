"""
ä¸¦è¡Œåˆ†æå™¨ï¼ˆv3.3.7æ€§èƒ½å„ªåŒ–ç‰ˆï¼‰
è·è²¬ï¼šåˆ©ç”¨ 32 æ ¸å¿ƒä¸¦è¡Œè™•ç†å¤§é‡äº¤æ˜“å°åˆ†æã€è‡ªé©æ‡‰æ‰¹æ¬¡å¤§å°ã€æ€§èƒ½è¿½è¹¤
"""

import asyncio
from typing import List, Dict, Optional
import logging
from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor
import multiprocessing as mp
import psutil
import time

from src.strategies.ict_strategy import ICTStrategy
from src.config import Config

logger = logging.getLogger(__name__)


class ParallelAnalyzer:
    """ä¸¦è¡Œåˆ†æå™¨ - å……åˆ†åˆ©ç”¨ 32vCPU è³‡æºï¼ˆv3.3.7æ€§èƒ½å„ªåŒ–ç‰ˆï¼‰"""
    
    def __init__(self, max_workers: Optional[int] = None, perf_monitor=None):
        """
        åˆå§‹åŒ–ä¸¦è¡Œåˆ†æå™¨
        
        Args:
            max_workers: æœ€å¤§å·¥ä½œç·šç¨‹æ•¸ï¼ˆNone è¡¨ç¤ºå¾é…ç½®è®€å–ï¼‰
            perf_monitor: æ€§èƒ½ç›£æ§å™¨ï¼ˆv3.3.7æ–°å¢ï¼‰
        """
        self.config = Config
        
        # å¾é…ç½®ç²å–é»˜èªå€¼
        default_workers = self.config.MAX_WORKERS
        
        # è‡ªå‹•æª¢æ¸¬ CPU æ ¸å¿ƒæ•¸
        cpu_count = mp.cpu_count()
        
        # å¦‚æœæœªæŒ‡å®šï¼Œä½¿ç”¨é…ç½®å€¼ï¼›å¦å‰‡å–æŒ‡å®šå€¼
        if max_workers is None:
            self.max_workers = min(default_workers, cpu_count)
        else:
            self.max_workers = min(max_workers, cpu_count)
        
        self.strategy = ICTStrategy()
        
        # ä½¿ç”¨ç·šç¨‹æ± è™•ç† I/O å¯†é›†å‹ä»»å‹™
        self.thread_executor = ThreadPoolExecutor(max_workers=self.max_workers)
        
        # âœ¨ v3.3.7æ–°å¢ï¼šæ€§èƒ½ç›£æ§
        self.perf_monitor = perf_monitor
        
        logger.info(
            f"ä¸¦è¡Œåˆ†æå™¨åˆå§‹åŒ–: {self.max_workers} å€‹å·¥ä½œç·šç¨‹ "
            f"(CPU æ ¸å¿ƒ: {cpu_count})"
        )
    
    def _calculate_optimal_batch_size(self, total_symbols: int) -> int:
        """
        è¨ˆç®—æœ€å„ªæ‰¹æ¬¡å¤§å°ï¼ˆv3.3.7æ–°å¢ - è‡ªé©æ‡‰æ‰¹æ¬¡å¤§å°ï¼‰
        
        Args:
            total_symbols: ç¸½äº¤æ˜“å°æ•¸é‡
        
        Returns:
            int: æœ€å„ªæ‰¹æ¬¡å¤§å°
        """
        try:
            # ç²å–ç•¶å‰ç³»çµ±è² è¼‰
            cpu_usage = psutil.cpu_percent(interval=0.1)
            mem_usage = psutil.virtual_memory().percent
            
            # åŸºç¤æ‰¹æ¬¡å¤§å°
            base_batch = self.max_workers * 2
            
            # æ ¹æ“šç³»çµ±è² è¼‰å‹•æ…‹èª¿æ•´ï¼ˆå†…å­˜ä¼˜åŒ–ï¼šé™ä½æ‰¹æ¬¡å¤§å°é˜ˆå€¼ï¼‰
            if cpu_usage < 40 and mem_usage < 50:
                # ç³»çµ±ç©ºé–’ï¼Œå¢å¤§æ‰¹æ¬¡
                multiplier = 2  # é™ä½å¾3åˆ°2
                logger.debug(f"ç³»çµ±è² è¼‰ä½ (CPU: {cpu_usage:.1f}%, MEM: {mem_usage:.1f}%)ï¼Œä½¿ç”¨å¤§æ‰¹æ¬¡")
            elif cpu_usage < 60 and mem_usage < 65:
                # æ­£å¸¸è² è¼‰
                multiplier = 1.5  # é™ä½å¾2åˆ°1.5
                logger.debug(f"ç³»çµ±è² è¼‰æ­£å¸¸ (CPU: {cpu_usage:.1f}%, MEM: {mem_usage:.1f}%)ï¼Œä½¿ç”¨æ¨™æº–æ‰¹æ¬¡")
            else:
                # é«˜è² è¼‰ï¼Œæ¸›å°æ‰¹æ¬¡
                multiplier = 1
                logger.warning(f"ç³»çµ±è² è¼‰é«˜ (CPU: {cpu_usage:.1f}%, MEM: {mem_usage:.1f}%)ï¼Œä½¿ç”¨å°æ‰¹æ¬¡")
            
            batch_size = int(base_batch * multiplier)
            
            # é‡å°å¤§é‡äº¤æ˜“å°å„ªåŒ–ï¼ˆé¿å…éå¤§æ‰¹æ¬¡ï¼‰
            if total_symbols > 500:
                batch_size = min(batch_size, 150)
            
            return int(batch_size)
            
        except Exception as e:
            logger.warning(f"è¨ˆç®—æœ€å„ªæ‰¹æ¬¡å¤§å°å¤±æ•—ï¼Œä½¿ç”¨é»˜èªå€¼: {e}")
            return self.max_workers * 2
    
    async def analyze_batch(
        self,
        symbols_data: List[Dict],
        data_manager
    ) -> List[Dict]:
        """
        æ‰¹é‡ä¸¦è¡Œåˆ†æå¤šå€‹äº¤æ˜“å°ï¼ˆv3.3.7å„ªåŒ–ç‰ˆ - è‡ªé©æ‡‰æ‰¹æ¬¡å¤§å°ï¼‰
        
        Args:
            symbols_data: äº¤æ˜“å°åˆ—è¡¨
            data_manager: æ•¸æ“šç®¡ç†å™¨å¯¦ä¾‹ï¼ˆDataService æˆ– SmartDataManagerï¼‰
        
        Returns:
            List[Dict]: ç”Ÿæˆçš„äº¤æ˜“ä¿¡è™Ÿåˆ—è¡¨
        """
        try:
            # âœ¨ v3.3.7ï¼šæ€§èƒ½è¿½è¹¤
            start_time = time.time()
            
            total_symbols = len(symbols_data)
            logger.info(f"é–‹å§‹æ‰¹é‡åˆ†æ {total_symbols} å€‹äº¤æ˜“å°")
            
            # âœ¨ v3.3.7ï¼šè‡ªé©æ‡‰æ‰¹æ¬¡å¤§å°
            batch_size = self._calculate_optimal_batch_size(total_symbols)
            
            signals = []
            total_batches = (total_symbols + batch_size - 1) // batch_size
            
            logger.info(
                f"âš¡ æ‰¹æ¬¡é…ç½®: {batch_size} å€‹/æ‰¹æ¬¡, å…± {total_batches} æ‰¹æ¬¡ "
                f"(å·¥ä½œç·šç¨‹: {self.max_workers})"
            )
            
            for batch_idx in range(total_batches):
                i = batch_idx * batch_size
                batch = symbols_data[i:i + batch_size]
                
                logger.info(f"è™•ç†æ‰¹æ¬¡ {batch_idx + 1}/{total_batches} ({len(batch)} å€‹äº¤æ˜“å°)")
                
                # ä¸¦è¡Œç²å–å¤šæ™‚é–“æ¡†æ¶æ•¸æ“šï¼ˆæ™ºèƒ½èª¿åº¦ï¼‰
                tasks = [
                    data_manager.get_multi_timeframe_data(item['symbol'])
                    for item in batch
                ]
                
                multi_tf_data_list = await asyncio.gather(*tasks, return_exceptions=True)
                
                # ä¸¦è¡Œåˆ†æä¿¡è™Ÿ
                analysis_tasks = []
                for j, multi_tf_data in enumerate(multi_tf_data_list):
                    # æ˜ç¢ºæª¢æŸ¥é¡å‹ï¼Œç¢ºä¿æ˜¯æœ‰æ•ˆå­—å…¸
                    if isinstance(multi_tf_data, Exception):
                        logger.debug(f"è·³é {batch[j]['symbol']}: æ•¸æ“šç²å–ç•°å¸¸ - {multi_tf_data}")
                        continue
                    
                    if multi_tf_data is None or not isinstance(multi_tf_data, dict):
                        logger.debug(f"è·³é {batch[j]['symbol']}: æ•¸æ“šç„¡æ•ˆ")
                        continue
                    
                    symbol = batch[j]['symbol']
                    analysis_tasks.append(
                        self._analyze_symbol(symbol, multi_tf_data)
                    )
                
                batch_signals = await asyncio.gather(*analysis_tasks, return_exceptions=True)
                
                # æ”¶é›†æœ‰æ•ˆä¿¡è™Ÿ
                batch_signal_count = 0
                for signal in batch_signals:
                    if signal and not isinstance(signal, Exception):
                        signals.append(signal)
                        batch_signal_count += 1
                
                batch_time = time.time() - start_time
                logger.info(
                    f"æ‰¹æ¬¡ {batch_idx + 1}/{total_batches} å®Œæˆ: "
                    f"ç”Ÿæˆ {batch_signal_count} å€‹ä¿¡è™Ÿ, "
                    f"ç´¯è¨ˆ {len(signals)} å€‹ "
                    f"âš¡ æ‰¹æ¬¡è€—æ™‚: {batch_time:.2f}s"
                )
                
                # ğŸ¯ v3.9.2.7æ€§èƒ½ä¼˜åŒ–ï¼šç®€åŒ–å†…å­˜ç®¡ç†
                # åˆ é™¤æ‰¹é‡ä¿¡å·å¼•ç”¨ï¼Œè®©Pythonè‡ªåŠ¨åƒåœ¾å›æ”¶
                del batch_signals
                # ç§»é™¤é¢‘ç¹æ‰‹åŠ¨gc.collect()ï¼Œé¿å…æ€§èƒ½æŸè€—
                
                # ğŸ¯ v3.9.2.7ä¼˜åŒ–ï¼šä»…åœ¨æå¤§é‡äº¤æ˜“å¯¹ä¸”é«˜è´Ÿè½½æ—¶æ‰å»¶è¿Ÿ
                if total_symbols > 500 and batch_idx < total_batches - 1:
                    # æ£€æŸ¥ç³»ç»Ÿè´Ÿè½½ï¼Œä»…åœ¨é«˜è´Ÿè½½æ—¶å»¶è¿Ÿ
                    cpu_usage = psutil.cpu_percent(interval=0)
                    if cpu_usage > 80:
                        await asyncio.sleep(0.05)  # å‡å°‘å»¶è¿Ÿæ—¶é—´ä»0.1åˆ°0.05
            
            # âœ¨ v3.3.7ï¼šæ€§èƒ½çµ±è¨ˆ
            total_duration = time.time() - start_time
            avg_per_symbol = total_duration / max(total_symbols, 1)
            
            logger.info(
                f"âœ… æ‰¹é‡åˆ†æå®Œæˆ: åˆ†æ {total_symbols} å€‹äº¤æ˜“å°, "
                f"ç”Ÿæˆ {len(signals)} å€‹ä¿¡è™Ÿ "
                f"âš¡ ç¸½è€—æ™‚: {total_duration:.2f}s "
                f"(å¹³å‡ {avg_per_symbol*1000:.1f}ms/äº¤æ˜“å°)"
            )
            
            # âœ¨ v3.3.7ï¼šè¨˜éŒ„æ€§èƒ½
            if self.perf_monitor:
                self.perf_monitor.record_operation("analyze_batch", total_duration)
            
            return signals
            
        except Exception as e:
            logger.error(f"æ‰¹é‡åˆ†æå¤±æ•—: {e}", exc_info=True)
            return []
    
    async def _analyze_symbol(self, symbol: str, multi_tf_data: Dict) -> Optional[Dict]:
        """
        åœ¨ç·šç¨‹æ± ä¸­åˆ†æå–®å€‹äº¤æ˜“å°
        
        Args:
            symbol: äº¤æ˜“å°
            multi_tf_data: å¤šæ™‚é–“æ¡†æ¶æ•¸æ“š
        
        Returns:
            Optional[Dict]: äº¤æ˜“ä¿¡è™Ÿï¼ˆå¯èƒ½ç‚º Noneï¼‰
        """
        try:
            loop = asyncio.get_event_loop()
            
            # åœ¨ç·šç¨‹æ± ä¸­åŸ·è¡Œ CPU å¯†é›†å‹åˆ†æ
            signal = await loop.run_in_executor(
                self.thread_executor,
                self.strategy.analyze,
                symbol,
                multi_tf_data
            )
            
            return signal
            
        except Exception as e:
            logger.error(f"åˆ†æ {symbol} å¤±æ•—: {e}")
            return None
    
    async def close(self):
        """é—œé–‰åŸ·è¡Œå™¨"""
        try:
            self.thread_executor.shutdown(wait=True)
            logger.info("ä¸¦è¡Œåˆ†æå™¨å·²é—œé–‰")
        except Exception as e:
            logger.error(f"é—œé–‰ä¸¦è¡Œåˆ†æå™¨å¤±æ•—: {e}")
