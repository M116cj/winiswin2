"""
æ•¸æ“šæœå‹™ï¼ˆv3.3.7æ€§èƒ½å„ªåŒ–ç‰ˆï¼‰
è·è²¬ï¼šå¸‚å ´æ•¸æ“šç²å–ã€æ‰¹é‡è™•ç†ã€å¤šæ™‚é–“æ¡†æ¶æ•¸æ“šå°é½Šã€æ€§èƒ½è¿½è¹¤
"""

import asyncio
from typing import List, Dict, Optional
import pandas as pd
from datetime import datetime, timedelta
import logging
import time

from src.clients.binance_client import BinanceClient
from src.core.cache_manager import CacheManager
from src.config import Config

logger = logging.getLogger(__name__)


class DataService:
    """æ•¸æ“šæœå‹™é¡ï¼ˆv3.3.7æ€§èƒ½å„ªåŒ–ç‰ˆï¼‰"""
    
    def __init__(self, binance_client: BinanceClient, perf_monitor=None):
        """
        åˆå§‹åŒ–æ•¸æ“šæœå‹™
        
        Args:
            binance_client: Binance å®¢æˆ¶ç«¯
            perf_monitor: æ€§èƒ½ç›£æ§å™¨ï¼ˆv3.3.7æ–°å¢ï¼‰
        """
        self.client = binance_client
        self.cache = binance_client.cache
        # ä½¿ç”¨ 1h/15m/5m ä¸‰ä¸ªæ—¶é—´æ¡†æ¶
        # 1h: è¶‹åŠ¿ç¡®è®¤ï¼ˆæ¯å°æ—¶ï¼‰
        # 15m: è¶‹åŠ¿ç¡®è®¤ï¼ˆæ¯15åˆ†é’Ÿï¼‰
        # 5m: è¶‹åŠ¿ç¬¦åˆç¡®è®¤ + å…¥åœºä¿¡å·
        self.timeframes = ["1h", "15m", "5m"]
        self.all_symbols: List[str] = []
        
        # âœ¨ v3.3.7æ–°å¢ï¼šæ€§èƒ½ç›£æ§
        self.perf_monitor = perf_monitor
    
    async def initialize(self):
        """åˆå§‹åŒ–æ•¸æ“šæœå‹™"""
        logger.info("åˆå§‹åŒ–æ•¸æ“šæœå‹™...")
        await self.load_all_symbols()
        logger.info(f"âœ… å·²åŠ è¼‰ {len(self.all_symbols)} å€‹ USDT æ°¸çºŒåˆç´„")
    
    async def load_all_symbols(self):
        """åŠ è¼‰æ‰€æœ‰ USDT æ°¸çºŒåˆç´„äº¤æ˜“å°"""
        try:
            exchange_info = await self.client.get_exchange_info()
            
            self.all_symbols = [
                symbol['symbol']
                for symbol in exchange_info.get('symbols', [])
                if symbol['symbol'].endswith('USDT') 
                and symbol['status'] == 'TRADING'
                and symbol.get('contractType') == 'PERPETUAL'
                and symbol['symbol'].isascii()  # æ’é™¤ä¸­æ–‡ç­‰éASCIIäº¤æ˜“å°ï¼ˆé¿å…ç°½åéŒ¯èª¤ï¼‰
            ]
            
            logger.info(f"æˆåŠŸåŠ è¼‰ {len(self.all_symbols)} å€‹äº¤æ˜“å°")
            
        except Exception as e:
            logger.error(f"åŠ è¼‰äº¤æ˜“å°å¤±æ•—: {e}")
            self.all_symbols = []
    
    async def get_multi_timeframe_data(
        self,
        symbol: str,
        timeframes: Optional[List[str]] = None
    ) -> Dict[str, pd.DataFrame]:
        """
        ç²å–å¤šæ™‚é–“æ¡†æ¶æ•¸æ“š
        
        Args:
            symbol: äº¤æ˜“å°
            timeframes: æ™‚é–“æ¡†æ¶åˆ—è¡¨ï¼ˆé»˜èªä½¿ç”¨æ‰€æœ‰æ™‚é–“æ¡†æ¶ï¼‰
        
        Returns:
            Dict[str, pd.DataFrame]: æ™‚é–“æ¡†æ¶åˆ°æ•¸æ“šæ¡†çš„æ˜ å°„
        """
        if timeframes is None:
            timeframes = self.timeframes
        
        tasks = [
            self.get_klines(symbol, tf, limit=200)
            for tf in timeframes
        ]
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        data = {}
        for tf, result in zip(timeframes, results):
            if isinstance(result, Exception):
                logger.error(f"ç²å– {symbol} {tf} æ•¸æ“šå¤±æ•—: {result}")
                data[tf] = pd.DataFrame()
            else:
                data[tf] = result
        
        return data
    
    async def get_klines(
        self,
        symbol: str,
        interval: str,
        limit: int = 200,
        start_time: Optional[int] = None,
        end_time: Optional[int] = None
    ) -> pd.DataFrame:
        """
        ç²å– Kç·šæ•¸æ“šï¼ˆæ™ºèƒ½ç·©å­˜ + æ€§èƒ½è¿½è¹¤ï¼‰v3.3.7å„ªåŒ–ç‰ˆ
        
        Args:
            symbol: äº¤æ˜“å°
            interval: æ™‚é–“é–“éš”
            limit: æ•¸æ“šæ¢æ•¸
            start_time: é–‹å§‹æ™‚é–“æˆ³
            end_time: çµæŸæ™‚é–“æˆ³
        
        Returns:
            pd.DataFrame: Kç·šæ•¸æ“šæ¡†
        """
        # âœ¨ v3.3.7ï¼šå•Ÿå‹•æ€§èƒ½è¿½è¹¤
        start_perf = time.time()
        
        # æ ¹æ“šæ™‚é–“æ¡†æ¶ä½¿ç”¨ä¸åŒçš„ TTL
        ttl_map = {
            '1h': Config.CACHE_TTL_KLINES_1H,
            '15m': Config.CACHE_TTL_KLINES_15M,
            '5m': Config.CACHE_TTL_KLINES_5M
        }
        ttl = ttl_map.get(interval, Config.CACHE_TTL_KLINES_DEFAULT)
        
        # âœ¨ v3.3.7å„ªåŒ–ï¼šæ™ºèƒ½ç·©å­˜éµï¼ˆåŒ…å«æ™‚é–“çª—å£ç‰ˆæœ¬ï¼‰
        # é€™æ¨£å¯ä»¥ç¢ºä¿æ•¸æ“šæ–°é®®åº¦ï¼ŒåŒæ™‚æé«˜ç·©å­˜å‘½ä¸­ç‡
        time_window = int(time.time() / ttl)  # æ™‚é–“çª—å£ç‰ˆæœ¬è™Ÿ
        cache_key = f"klines_v2_{symbol}_{interval}_{limit}_{time_window}"
        
        # æ­·å²è«‹æ±‚æˆ–æŒ‡å®šæ™‚é–“ç¯„åœæ™‚ï¼Œä¸ä½¿ç”¨ç·©å­˜
        if start_time is not None or end_time is not None:
            cache_key = None  # è·³éç·©å­˜
        
        # å˜—è©¦å¾ç·©å­˜ç²å–
        if cache_key:
            cached_data = self.cache.get(cache_key)
            if cached_data is not None:
                logger.debug(f"âœ… ç·©å­˜å‘½ä¸­: {symbol} {interval}")
                
                # âœ¨ v3.3.7ï¼šè¨˜éŒ„ç·©å­˜å‘½ä¸­
                if self.perf_monitor:
                    self.perf_monitor.record_cache_hit()
                    duration = time.time() - start_perf
                    self.perf_monitor.record_operation(
                        f"get_klines_{interval}_cached", 
                        duration
                    )
                
                return cached_data
            else:
                # âœ¨ v3.3.7ï¼šè¨˜éŒ„ç·©å­˜æœªå‘½ä¸­
                if self.perf_monitor:
                    self.perf_monitor.record_cache_miss()
        
        try:
            klines = await self.client.get_klines(
                symbol=symbol,
                interval=interval,
                limit=limit,
                start_time=start_time,
                end_time=end_time
            )
            
            if not klines:
                return pd.DataFrame()
            
            df = pd.DataFrame(klines, columns=[
                'timestamp', 'open', 'high', 'low', 'close', 'volume',
                'close_time', 'quote_volume', 'trades', 'taker_buy_volume',
                'taker_buy_quote_volume', 'ignore'
            ])
            
            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
            
            for col in ['open', 'high', 'low', 'close', 'volume']:
                df[col] = pd.to_numeric(df[col], errors='coerce')
            
            df = df[['timestamp', 'open', 'high', 'low', 'close', 'volume']]
            
            # ç·©å­˜æ•¸æ“š
            if cache_key:
                self.cache.set(cache_key, df, ttl=ttl)
                logger.debug(f"ğŸ’¾ ç·©å­˜ {symbol} {interval} æ•¸æ“šï¼ŒTTL={ttl}ç§’")
            
            # âœ¨ v3.3.7ï¼šè¨˜éŒ„æ€§èƒ½æŒ‡æ¨™
            if self.perf_monitor:
                duration = time.time() - start_perf
                self.perf_monitor.record_operation(
                    f"get_klines_{interval}_fetch", 
                    duration
                )
            
            return df
            
        except Exception as e:
            logger.error(f"ç²å– Kç·šæ•¸æ“šå¤±æ•— {symbol} {interval}: {e}")
            return pd.DataFrame()
    
    async def get_batch_tickers(self, symbols: List[str]) -> Dict[str, dict]:
        """
        æ‰¹é‡ç²å–è¡Œæƒ…æ•¸æ“š
        
        Args:
            symbols: äº¤æ˜“å°åˆ—è¡¨
        
        Returns:
            Dict[str, dict]: äº¤æ˜“å°åˆ°è¡Œæƒ…æ•¸æ“šçš„æ˜ å°„
        """
        cache_key = "batch_tickers"
        cached_data = self.cache.get(cache_key)
        
        if cached_data is not None:
            return {s: cached_data.get(s, {}) for s in symbols}
        
        try:
            all_tickers = await self.client.get_ticker_price()
            
            ticker_dict = {
                ticker['symbol']: ticker
                for ticker in all_tickers
                if ticker['symbol'] in symbols
            }
            
            self.cache.set(cache_key, ticker_dict, ttl=Config.CACHE_TTL_TICKER)
            
            return ticker_dict
            
        except Exception as e:
            logger.error(f"æ‰¹é‡ç²å–è¡Œæƒ…æ•¸æ“šå¤±æ•—: {e}")
            return {}
    
    async def get_market_data_batch(
        self,
        symbols: List[str],
        timeframe: str = "15m",
        limit: int = 200
    ) -> Dict[str, pd.DataFrame]:
        """
        æ‰¹é‡ç²å–å¸‚å ´æ•¸æ“š
        
        Args:
            symbols: äº¤æ˜“å°åˆ—è¡¨
            timeframe: æ™‚é–“æ¡†æ¶
            limit: æ•¸æ“šæ¢æ•¸
        
        Returns:
            Dict[str, pd.DataFrame]: äº¤æ˜“å°åˆ°æ•¸æ“šæ¡†çš„æ˜ å°„
        """
        batch_size = Config.BATCH_SIZE
        results = {}
        
        for i in range(0, len(symbols), batch_size):
            batch = symbols[i:i + batch_size]
            
            tasks = [
                self.get_klines(symbol, timeframe, limit)
                for symbol in batch
            ]
            
            batch_results = await asyncio.gather(*tasks, return_exceptions=True)
            
            for symbol, data in zip(batch, batch_results):
                if isinstance(data, Exception):
                    logger.error(f"ç²å– {symbol} æ•¸æ“šå¤±æ•—: {data}")
                    results[symbol] = pd.DataFrame()
                else:
                    results[symbol] = data
            
            if i + batch_size < len(symbols):
                await asyncio.sleep(0.1)
        
        return results
    
    async def scan_market(self, top_n: int = 200) -> List[Dict]:
        """
        æƒæå¸‚å ´ï¼ŒæŒ‰æµå‹•æ€§æ’åºï¼Œè¿”å›å‰Nå€‹äº¤æ˜“å°ï¼ˆv3.3.7æ€§èƒ½å„ªåŒ–ç‰ˆï¼‰
        
        ç­–ç•¥ï¼šå„ªå…ˆç›£æ§æµå‹•æ€§æœ€é«˜çš„å‰200å€‹æ¨™çš„
        - æµå‹•æ€§æŒ‡æ¨™ï¼š24h äº¤æ˜“é¡ï¼ˆquoteVolumeï¼Œä»¥ USDT è¨ˆï¼‰
        - å¾ 600+ å€‹ Uæœ¬ä½åˆç´„ä¸­é¸æ“‡æœ€æ´»èºçš„
        
        Args:
            top_n: è¿”å›å‰Nå€‹äº¤æ˜“å°ï¼ˆé»˜èª200ï¼‰
        
        Returns:
            List[Dict]: æŒ‰æµå‹•æ€§æ’åºçš„äº¤æ˜“å°åˆ—è¡¨
        """
        # âœ¨ v3.3.7ï¼šæ€§èƒ½è¿½è¹¤
        start_time = time.time()
        
        logger.info(f"é–‹å§‹æƒæ {len(self.all_symbols)} å€‹äº¤æ˜“å°ï¼ˆæµå‹•æ€§æ’åºï¼‰...")
        
        # ç²å–24h tickeræ•¸æ“šï¼ˆåŒ…å«äº¤æ˜“é‡æ•¸æ“šï¼‰
        try:
            exchange_info_data = await self.client.get_24h_tickers()
            
            market_data = []
            for ticker in exchange_info_data:
                symbol = ticker.get('symbol')
                if symbol not in self.all_symbols:
                    continue
                
                # æµå‹•æ€§æŒ‡æ¨™ï¼š24h äº¤æ˜“é¡ï¼ˆUSDTï¼‰
                quote_volume = float(ticker.get('quoteVolume', 0))
                volume_24h = float(ticker.get('volume', 0))
                price_change_pct = float(ticker.get('priceChangePercent', 0))
                
                market_data.append({
                    'symbol': symbol,
                    'price': float(ticker.get('lastPrice', 0)),
                    'change_24h': price_change_pct,
                    'volume_24h': volume_24h,
                    'quote_volume': quote_volume,  # æµå‹•æ€§æŒ‡æ¨™ï¼ˆUSDTï¼‰
                    'liquidity': quote_volume,     # ç”¨æ–¼æ’åº
                    'timestamp': datetime.now()
                })
            
            # æŒ‰æµå‹•æ€§æ’åºï¼ˆå¾é«˜åˆ°ä½ï¼‰
            market_data.sort(key=lambda x: x['liquidity'], reverse=True)
            
            # å–å‰Nå€‹
            top_liquidity = market_data[:top_n]
            
            avg_volume = sum(x['liquidity'] for x in top_liquidity) / len(top_liquidity) if top_liquidity else 0
            
            # âœ¨ v3.3.7ï¼šæ€§èƒ½æ—¥èªŒ
            duration = time.time() - start_time
            logger.info(
                f"âœ… å¸‚å ´æƒæå®Œæˆ: å¾ {len(market_data)} å€‹äº¤æ˜“å°ä¸­é¸æ“‡ "
                f"æµå‹•æ€§æœ€é«˜çš„å‰ {len(top_liquidity)} å€‹ "
                f"(å¹³å‡24häº¤æ˜“é¡: ${avg_volume:,.0f} USDT) "
                f"âš¡ è€—æ™‚: {duration:.2f}s"
            )
            
            # âœ¨ v3.3.7ï¼šè¨˜éŒ„æ€§èƒ½
            if self.perf_monitor:
                self.perf_monitor.record_operation("scan_market", duration)
            
            return top_liquidity
            
        except Exception as e:
            logger.error(f"å¸‚å ´æƒæå¤±æ•—: {e}", exc_info=True)
            # é™ç´šï¼šè¿”å›æ‰€æœ‰äº¤æ˜“å°
            return await self._fallback_scan_market()
    
    async def _fallback_scan_market(self) -> List[Dict]:
        """é™ç´šæƒæï¼šç•¶24h tickerå¤±æ•—æ™‚ä½¿ç”¨"""
        tickers = await self.get_batch_tickers(self.all_symbols)
        
        market_data = []
        for symbol in self.all_symbols:
            ticker = tickers.get(symbol, {})
            if ticker:
                market_data.append({
                    'symbol': symbol,
                    'price': float(ticker.get('price', 0)),
                    'liquidity': 0.0,
                    'quote_volume': 0.0,
                    'timestamp': datetime.now()
                })
        
        logger.warning(f"ä½¿ç”¨é™ç´šæƒæï¼Œç²å– {len(market_data)} å€‹äº¤æ˜“å°")
        return market_data
    
    async def get_account_info(self) -> dict:
        """
        ç²å–è³¬æˆ¶ä¿¡æ¯
        
        Returns:
            dict: è³¬æˆ¶ä¿¡æ¯
        """
        cache_key = "account_info"
        cached_data = self.cache.get(cache_key)
        
        if cached_data is not None:
            return cached_data
        
        try:
            account = await self.client.get_account_info()
            self.cache.set(cache_key, account, ttl=Config.CACHE_TTL_ACCOUNT)
            return account
        except Exception as e:
            logger.error(f"ç²å–è³¬æˆ¶ä¿¡æ¯å¤±æ•—: {e}")
            return {}
    
    async def get_positions(self) -> List[dict]:
        """
        ç²å–ç•¶å‰æŒå€‰
        
        Returns:
            List[dict]: æŒå€‰åˆ—è¡¨
        """
        try:
            account = await self.get_account_info()
            positions = account.get('positions', [])
            
            active_positions = [
                pos for pos in positions
                if float(pos.get('positionAmt', 0)) != 0
            ]
            
            return active_positions
        except Exception as e:
            logger.error(f"ç²å–æŒå€‰å¤±æ•—: {e}")
            return []
    
    def align_timeframes(
        self,
        data: Dict[str, pd.DataFrame]
    ) -> Dict[str, pd.DataFrame]:
        """
        å°é½Šå¤šæ™‚é–“æ¡†æ¶æ•¸æ“š
        
        Args:
            data: æ™‚é–“æ¡†æ¶åˆ°æ•¸æ“šæ¡†çš„æ˜ å°„
        
        Returns:
            Dict[str, pd.DataFrame]: å°é½Šå¾Œçš„æ•¸æ“š
        """
        if not data:
            return data
        
        aligned_data = {}
        
        for tf, df in data.items():
            if df.empty:
                aligned_data[tf] = df
                continue
            
            df = df.copy()
            df.set_index('timestamp', inplace=True)
            df.sort_index(inplace=True)
            
            aligned_data[tf] = df
        
        return aligned_data
