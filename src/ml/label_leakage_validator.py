"""
æ ‡ç­¾æ³„æ¼éªŒè¯å™¨
èŒè´£ï¼šæ£€æµ‹ç‰¹å¾æ˜¯å¦åŒ…å«æœªæ¥ä¿¡æ¯ï¼Œç¡®ä¿æ—¶é—´å¯¹é½
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Tuple
import logging
from datetime import datetime

logger = logging.getLogger(__name__)


class LabelLeakageValidator:
    """æ ‡ç­¾æ³„æ¼éªŒè¯å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–éªŒè¯å™¨"""
        # å®šä¹‰å¿…é¡»åœ¨å¼€ä»“æ—¶åˆ»å·²çŸ¥çš„ç‰¹å¾
        self.entry_time_features = [
            'confidence_score', 'leverage', 'position_value',
            'order_blocks_count', 'liquidity_zones_count',
            'rsi_entry', 'macd_entry', 'macd_signal_entry', 'macd_histogram_entry',
            'atr_entry', 'bb_width_pct', 'volume_sma_ratio',
            'price_vs_ema50', 'price_vs_ema200',
            'trend_1h_encoded', 'trend_15m_encoded', 'trend_5m_encoded',
            'market_structure_encoded', 'direction_encoded',
            'hour_of_day', 'day_of_week', 'is_weekend',
            'confidence_x_leverage', 'rsi_x_trend', 'atr_x_bb_width'
        ]
        
        # éœ€è¦éªŒè¯çš„è·ç¦»ç‰¹å¾ï¼ˆå¯èƒ½åŒ…å«æœªæ¥ä¿¡æ¯ï¼‰
        self.distance_features = ['stop_distance_pct', 'tp_distance_pct']
        
        # ç›®æ ‡å˜é‡
        self.target = 'is_winner'
    
    def validate_training_data(self, df: pd.DataFrame) -> Dict:
        """
        éªŒè¯è®­ç»ƒæ•°æ®æ˜¯å¦å­˜åœ¨æ ‡ç­¾æ³„æ¼
        
        Args:
            df: è®­ç»ƒæ•°æ®
        
        Returns:
            Dict: éªŒè¯æŠ¥å‘Š
        """
        report = {
            'total_samples': len(df),
            'has_leakage': False,
            'leakage_features': [],
            'warnings': [],
            'passed_checks': []
        }
        
        if df.empty:
            report['warnings'].append("æ•°æ®é›†ä¸ºç©º")
            return report
        
        # æ£€æŸ¥1ï¼šç›®æ ‡å˜é‡ä¸è·ç¦»ç‰¹å¾çš„ç›¸å…³æ€§æ£€æŸ¥
        leakage_check = self._check_target_correlation(df)
        report.update(leakage_check)
        
        # æ£€æŸ¥2ï¼šæ—¶é—´å¯¹é½éªŒè¯ï¼ˆæ­¢æŸ/æ­¢ç›ˆè·ç¦»å¿…é¡»åœ¨å¼€ä»“æ—¶è®¡ç®—ï¼‰
        time_alignment_check = self._check_time_alignment(df)
        report['time_alignment'] = time_alignment_check
        
        # æ£€æŸ¥3ï¼šç‰¹å¾å€¼åˆç†æ€§æ£€æŸ¥
        sanity_check = self._check_feature_sanity(df)
        report['sanity_check'] = sanity_check
        
        # æ£€æŸ¥4ï¼šæœªæ¥ä¿¡æ¯æ£€æµ‹ï¼ˆhold_durationä¸åº”åœ¨è®­ç»ƒæ—¶ä½¿ç”¨ï¼‰
        future_info_check = self._check_future_information(df)
        report['future_info_check'] = future_info_check
        
        logger.info(f"ğŸ” æ ‡ç­¾æ³„æ¼éªŒè¯å®Œæˆï¼š{report}")
        
        return report
    
    def _check_target_correlation(self, df: pd.DataFrame) -> Dict:
        """
        æ£€æŸ¥ç›®æ ‡å˜é‡ä¸ç‰¹å¾çš„ç›¸å…³æ€§ï¼ˆæ£€æµ‹æ³„æ¼ï¼‰
        
        è¿‡é«˜çš„ç›¸å…³æ€§ï¼ˆ>0.9ï¼‰å¯èƒ½è¡¨ç¤ºç‰¹å¾åŒ…å«æœªæ¥ä¿¡æ¯
        """
        result = {
            'correlation_check': 'passed',
            'high_correlation_features': []
        }
        
        if self.target not in df.columns:
            result['correlation_check'] = 'skipped'
            result['warnings'] = ['ç›®æ ‡å˜é‡ä¸å­˜åœ¨']
            return result
        
        # è®¡ç®—ç›¸å…³æ€§
        correlations = {}
        for feature in self.distance_features:
            if feature in df.columns:
                corr = abs(df[feature].corr(df[self.target]))
                correlations[feature] = corr
                
                # ç›¸å…³æ€§>0.9è¡¨ç¤ºå¯èƒ½æ³„æ¼
                if corr > 0.9:
                    result['high_correlation_features'].append({
                        'feature': feature,
                        'correlation': float(corr)
                    })
        
        if result['high_correlation_features']:
            result['correlation_check'] = 'warning'
            logger.warning(f"âš ï¸ æ£€æµ‹åˆ°é«˜ç›¸å…³æ€§ç‰¹å¾ï¼ˆå¯èƒ½æ³„æ¼ï¼‰ï¼š{result['high_correlation_features']}")
        else:
            logger.info(f"âœ… ç›¸å…³æ€§æ£€æŸ¥é€šè¿‡ï¼š{correlations}")
        
        return result
    
    def _check_time_alignment(self, df: pd.DataFrame) -> Dict:
        """
        éªŒè¯æ­¢æŸ/æ­¢ç›ˆè·ç¦»æ˜¯å¦åœ¨å¼€ä»“æ—¶åˆ»è®¡ç®—
        
        æ£€æŸ¥é€»è¾‘ï¼š
        - stop_distance_pct = abs((stop_loss - entry_price) / entry_price)
        - tp_distance_pct = abs((take_profit - entry_price) / entry_price)
        è¿™äº›å€¼å¿…é¡»åŸºäºå¼€ä»“æ—¶è®¾å®šçš„SL/TPï¼Œè€Œéäº‹åè®¡ç®—
        """
        result = {
            'status': 'passed',
            'verified_samples': 0,
            'mismatched_samples': 0
        }
        
        required_cols = ['entry_price', 'stop_loss', 'take_profit', 
                        'stop_distance_pct', 'tp_distance_pct']
        
        if not all(col in df.columns for col in required_cols):
            result['status'] = 'skipped'
            result['reason'] = 'ç¼ºå°‘å¿…éœ€å­—æ®µ'
            return result
        
        # éªŒè¯è®¡ç®—æ˜¯å¦æ­£ç¡®
        mismatches = 0
        for idx, row in df.iterrows():
            if pd.notna(row['stop_loss']) and pd.notna(row['stop_distance_pct']):
                expected_stop_dist = abs((row['stop_loss'] - row['entry_price']) / row['entry_price'])
                actual_stop_dist = row['stop_distance_pct']
                
                # å…è®¸0.1%çš„æµ®ç‚¹è¯¯å·®
                if abs(expected_stop_dist - actual_stop_dist) > 0.001:
                    mismatches += 1
            
            if pd.notna(row['take_profit']) and pd.notna(row['tp_distance_pct']):
                expected_tp_dist = abs((row['take_profit'] - row['entry_price']) / row['entry_price'])
                actual_tp_dist = row['tp_distance_pct']
                
                if abs(expected_tp_dist - actual_tp_dist) > 0.001:
                    mismatches += 1
        
        result['verified_samples'] = len(df)
        result['mismatched_samples'] = mismatches
        
        if mismatches > 0:
            result['status'] = 'warning'
            logger.warning(f"âš ï¸ {mismatches}/{len(df)} æ ·æœ¬çš„è·ç¦»è®¡ç®—ä¸åŒ¹é…")
        else:
            logger.info(f"âœ… æ—¶é—´å¯¹é½éªŒè¯é€šè¿‡ï¼š{len(df)} æ ·æœ¬")
        
        return result
    
    def _check_feature_sanity(self, df: pd.DataFrame) -> Dict:
        """
        æ£€æŸ¥ç‰¹å¾å€¼çš„åˆç†æ€§
        
        ä¾‹å¦‚ï¼š
        - stop_distance_pctåº”è¯¥>0ä¸”åˆç†ï¼ˆå¦‚0.5%-5%ï¼‰
        - tp_distance_pctåº”è¯¥>0ä¸”åˆç†ï¼ˆå¦‚1%-10%ï¼‰
        """
        result = {
            'status': 'passed',
            'issues': []
        }
        
        # æ£€æŸ¥æ­¢æŸè·ç¦»
        if 'stop_distance_pct' in df.columns:
            stop_dist = df['stop_distance_pct'].dropna()
            if len(stop_dist) > 0:
                # æ£€æŸ¥æ˜¯å¦æœ‰è´Ÿå€¼
                if (stop_dist < 0).any():
                    result['issues'].append('stop_distance_pctå­˜åœ¨è´Ÿå€¼')
                
                # æ£€æŸ¥æ˜¯å¦æœ‰å¼‚å¸¸å¤§çš„å€¼ï¼ˆ>20%ï¼‰
                if (stop_dist > 0.2).any():
                    outlier_count = (stop_dist > 0.2).sum()
                    result['issues'].append(f'stop_distance_pctå­˜åœ¨{outlier_count}ä¸ªå¼‚å¸¸å€¼ï¼ˆ>20%ï¼‰')
        
        # æ£€æŸ¥æ­¢ç›ˆè·ç¦»
        if 'tp_distance_pct' in df.columns:
            tp_dist = df['tp_distance_pct'].dropna()
            if len(tp_dist) > 0:
                if (tp_dist < 0).any():
                    result['issues'].append('tp_distance_pctå­˜åœ¨è´Ÿå€¼')
                
                if (tp_dist > 0.5).any():
                    outlier_count = (tp_dist > 0.5).sum()
                    result['issues'].append(f'tp_distance_pctå­˜åœ¨{outlier_count}ä¸ªå¼‚å¸¸å€¼ï¼ˆ>50%ï¼‰')
        
        if result['issues']:
            result['status'] = 'warning'
            logger.warning(f"âš ï¸ ç‰¹å¾åˆç†æ€§æ£€æŸ¥å‘ç°é—®é¢˜ï¼š{result['issues']}")
        else:
            logger.info("âœ… ç‰¹å¾åˆç†æ€§æ£€æŸ¥é€šè¿‡")
        
        return result
    
    def _check_future_information(self, df: pd.DataFrame) -> Dict:
        """
        æ£€æµ‹æ˜¯å¦ä½¿ç”¨äº†æœªæ¥ä¿¡æ¯
        
        è­¦å‘Šç‰¹å¾ï¼ˆä¸åº”åœ¨è®­ç»ƒæ—¶ä½¿ç”¨ï¼‰ï¼š
        - actual_hold_durationï¼šå®é™…æŒä»“æ—¶é—´ï¼ˆåªæœ‰å¹³ä»“åæ‰çŸ¥é“ï¼‰
        - final_pnl_pctï¼šæœ€ç»ˆç›ˆäºï¼ˆåªæœ‰å¹³ä»“åæ‰çŸ¥é“ï¼‰
        """
        result = {
            'status': 'passed',
            'future_features_found': []
        }
        
        future_features = [
            'actual_hold_duration',
            'final_pnl_pct',
            'exit_price',
            'close_time'
        ]
        
        for feature in future_features:
            if feature in df.columns:
                result['future_features_found'].append(feature)
        
        if result['future_features_found']:
            result['status'] = 'warning'
            logger.warning(
                f"âš ï¸ æ£€æµ‹åˆ°æœªæ¥ä¿¡æ¯ç‰¹å¾ï¼ˆä¸åº”ç”¨äºè®­ç»ƒï¼‰ï¼š"
                f"{result['future_features_found']}"
            )
        else:
            logger.info("âœ… æœªæ£€æµ‹åˆ°æœªæ¥ä¿¡æ¯ç‰¹å¾")
        
        return result
    
    def get_safe_features(self) -> List[str]:
        """
        è·å–å®‰å…¨ç‰¹å¾åˆ—è¡¨ï¼ˆç¡®ä¿æ— æ³„æ¼ï¼‰
        
        Returns:
            List[str]: å®‰å…¨ç‰¹å¾åˆ—è¡¨
        """
        return self.entry_time_features + self.distance_features
    
    def validate_single_signal(self, signal: Dict) -> bool:
        """
        éªŒè¯å•ä¸ªä¿¡å·çš„ç‰¹å¾æ˜¯å¦å®‰å…¨ï¼ˆç”¨äºå®æ—¶é¢„æµ‹ï¼‰
        
        Args:
            signal: äº¤æ˜“ä¿¡å·
        
        Returns:
            bool: æ˜¯å¦é€šè¿‡éªŒè¯
        """
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æœªæ¥ä¿¡æ¯
        unsafe_keys = ['exit_price', 'close_time', 'actual_pnl', 'final_pnl_pct']
        
        for key in unsafe_keys:
            if key in signal:
                logger.error(f"âŒ ä¿¡å·åŒ…å«æœªæ¥ä¿¡æ¯ï¼š{key}")
                return False
        
        # æ£€æŸ¥å¿…éœ€ç‰¹å¾æ˜¯å¦å­˜åœ¨
        required_features = ['entry_price', 'stop_loss', 'take_profit', 'confidence']
        for feature in required_features:
            if feature not in signal and feature + '_score' not in signal:
                logger.warning(f"âš ï¸ ç¼ºå°‘å¿…éœ€ç‰¹å¾ï¼š{feature}")
        
        return True
