"""
å¤šå˜é‡æ¼‚ç§»æ£€æµ‹
èŒè´£ï¼šä½¿ç”¨MMDï¼ˆMaximum Mean Discrepancyï¼‰æ£€æµ‹é«˜ç»´ç‰¹å¾çš„è”åˆåˆ†å¸ƒæ¼‚ç§»
ä¼˜ç‚¹ï¼šæ¯”é€ç‰¹å¾KSæ£€éªŒæ›´å‡†ç¡®ï¼Œèƒ½æ•æ‰ç‰¹å¾é—´ç›¸å…³æ€§å˜åŒ–
"""

import numpy as np
import pandas as pd
from typing import Dict, Optional
import logging
from sklearn.decomposition import PCA

logger = logging.getLogger(__name__)


class MultivariateDriftDetector:
    """å¤šå˜é‡æ¼‚ç§»æ£€æµ‹å™¨ï¼ˆPCA + MMDï¼‰"""
    
    def __init__(self, n_components: int = 10, mmd_threshold: float = 0.1):
        """
        åˆå§‹åŒ–æ£€æµ‹å™¨
        
        Args:
            n_components: PCAé™ç»´åçš„ç»´åº¦
            mmd_threshold: MMDé˜ˆå€¼ï¼ˆ>thresholdåˆ™è®¤ä¸ºæ¼‚ç§»ï¼‰
        """
        self.n_components = n_components
        self.mmd_threshold = mmd_threshold
        self.pca = None
        self.baseline_pca_data = None
    
    def fit_baseline(self, X: pd.DataFrame):
        """
        æ‹ŸåˆåŸºå‡†æ•°æ®ï¼ˆè®­ç»ƒPCAå¹¶ä¿å­˜åŸºå‡†ï¼‰
        
        Args:
            X: åŸºå‡†ç‰¹å¾æ•°æ®
        """
        # PCAé™ç»´
        self.pca = PCA(n_components=min(self.n_components, X.shape[1]))
        baseline_transformed = self.pca.fit_transform(X)
        
        self.baseline_pca_data = baseline_transformed
        
        logger.info(
            f"ğŸ“Š å¤šå˜é‡æ¼‚ç§»æ£€æµ‹åŸºå‡†å»ºç«‹ï¼šPCAé™ç»´ {X.shape[1]} â†’ {self.pca.n_components_} ç»´, "
            f"è§£é‡Šæ–¹å·® {self.pca.explained_variance_ratio_.sum():.2%}"
        )
    
    def detect_drift(self, X_current: pd.DataFrame) -> Dict:
        """
        æ£€æµ‹å¤šå˜é‡æ¼‚ç§»ï¼ˆä½¿ç”¨MMDï¼‰
        
        Args:
            X_current: å½“å‰ç‰¹å¾æ•°æ®
        
        Returns:
            Dict: æ¼‚ç§»æ£€æµ‹æŠ¥å‘Š
        """
        if self.pca is None or self.baseline_pca_data is None:
            logger.warning("åŸºå‡†æ•°æ®æœªå»ºç«‹ï¼Œæ— æ³•æ£€æµ‹æ¼‚ç§»")
            return {
                'has_drift': False,
                'reason': 'åŸºå‡†æ•°æ®æœªå»ºç«‹'
            }
        
        # PCAå˜æ¢å½“å‰æ•°æ®
        current_transformed = self.pca.transform(X_current)
        
        # è®¡ç®—MMD
        mmd_value = self._compute_mmd(
            self.baseline_pca_data,
            current_transformed
        )
        
        # åˆ¤æ–­æ˜¯å¦æ¼‚ç§»
        has_drift = mmd_value > self.mmd_threshold
        
        report = {
            'has_drift': has_drift,
            'mmd_value': float(mmd_value),
            'mmd_threshold': self.mmd_threshold,
            'pca_dims': self.pca.n_components_,
            'explained_variance': float(self.pca.explained_variance_ratio_.sum())
        }
        
        if has_drift:
            logger.warning(
                f"âš ï¸ æ£€æµ‹åˆ°å¤šå˜é‡æ¼‚ç§»ï¼MMD={mmd_value:.4f} > é˜ˆå€¼{self.mmd_threshold}"
            )
        else:
            logger.info(f"âœ… å¤šå˜é‡åˆ†å¸ƒç¨³å®šï¼šMMD={mmd_value:.4f}")
        
        return report
    
    def _compute_mmd(
        self,
        X: np.ndarray,
        Y: np.ndarray,
        kernel: str = 'rbf',
        gamma: Optional[float] = None
    ) -> float:
        """
        è®¡ç®—Maximum Mean Discrepancy
        
        MMDè¡¡é‡ä¸¤ä¸ªåˆ†å¸ƒä¹‹é—´çš„è·ç¦»
        
        Args:
            X: åŸºå‡†æ•°æ® (n_samples_X, n_features)
            Y: å½“å‰æ•°æ® (n_samples_Y, n_features)
            kernel: æ ¸å‡½æ•°ç±»å‹ ('rbf' or 'linear')
            gamma: RBFæ ¸çš„å¸¦å®½å‚æ•°
        
        Returns:
            float: MMDå€¼
        """
        if kernel == 'rbf':
            # RBFæ ¸ï¼ˆé«˜æ–¯æ ¸ï¼‰
            if gamma is None:
                # è‡ªåŠ¨è®¡ç®—gammaï¼ˆä¸­ä½æ•°å¯å‘å¼ï¼‰
                gamma = 1.0 / X.shape[1]
            
            # K(X, X)
            K_XX = self._rbf_kernel(X, X, gamma)
            # K(Y, Y)
            K_YY = self._rbf_kernel(Y, Y, gamma)
            # K(X, Y)
            K_XY = self._rbf_kernel(X, Y, gamma)
            
        elif kernel == 'linear':
            # çº¿æ€§æ ¸
            K_XX = np.dot(X, X.T)
            K_YY = np.dot(Y, Y.T)
            K_XY = np.dot(X, Y.T)
        
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ ¸å‡½æ•°ï¼š{kernel}")
        
        # MMD^2 = E[K(X,X)] + E[K(Y,Y)] - 2*E[K(X,Y)]
        m = X.shape[0]
        n = Y.shape[0]
        
        mmd_squared = (
            K_XX.sum() / (m * m) +
            K_YY.sum() / (n * n) -
            2 * K_XY.sum() / (m * n)
        )
        
        # è¿”å›MMDï¼ˆå–å¹³æ–¹æ ¹ï¼‰
        mmd = np.sqrt(max(mmd_squared, 0))  # maxç¡®ä¿éè´Ÿ
        
        return mmd
    
    def _rbf_kernel(self, X: np.ndarray, Y: np.ndarray, gamma: float) -> np.ndarray:
        """
        RBFï¼ˆé«˜æ–¯ï¼‰æ ¸å‡½æ•°
        
        K(x, y) = exp(-gamma * ||x - y||^2)
        
        Args:
            X: æ•°æ®çŸ©é˜µ1 (n_samples_X, n_features)
            Y: æ•°æ®çŸ©é˜µ2 (n_samples_Y, n_features)
            gamma: å¸¦å®½å‚æ•°
        
        Returns:
            np.ndarray: æ ¸çŸ©é˜µ (n_samples_X, n_samples_Y)
        """
        # è®¡ç®—æ¬§æ°è·ç¦»çš„å¹³æ–¹
        # ||x - y||^2 = ||x||^2 + ||y||^2 - 2*<x, y>
        X_norm_sq = np.sum(X ** 2, axis=1, keepdims=True)
        Y_norm_sq = np.sum(Y ** 2, axis=1, keepdims=True)
        
        distances_sq = X_norm_sq + Y_norm_sq.T - 2 * np.dot(X, Y.T)
        
        # RBFæ ¸
        K = np.exp(-gamma * distances_sq)
        
        return K
    
    def get_principal_components_drift(self, X_current: pd.DataFrame) -> Dict:
        """
        åˆ†æå„ä¸»æˆåˆ†çš„æ¼‚ç§»æƒ…å†µ
        
        Args:
            X_current: å½“å‰ç‰¹å¾æ•°æ®
        
        Returns:
            Dict: å„ä¸»æˆåˆ†æ¼‚ç§»åˆ†æ
        """
        if self.pca is None or self.baseline_pca_data is None:
            return {}
        
        current_transformed = self.pca.transform(X_current)
        
        # è®¡ç®—å„ä¸»æˆåˆ†çš„å‡å€¼å’Œæ ‡å‡†å·®å˜åŒ–
        pc_drift = {}
        for i in range(self.pca.n_components_):
            baseline_mean = self.baseline_pca_data[:, i].mean()
            baseline_std = self.baseline_pca_data[:, i].std()
            
            current_mean = current_transformed[:, i].mean()
            current_std = current_transformed[:, i].std()
            
            # å‡å€¼æ¼‚ç§»ï¼ˆæ ‡å‡†åŒ–ï¼‰
            mean_shift = abs(current_mean - baseline_mean) / (baseline_std + 1e-6)
            
            # æ ‡å‡†å·®å˜åŒ–ç‡
            std_change = abs(current_std - baseline_std) / (baseline_std + 1e-6)
            
            pc_drift[f'PC{i+1}'] = {
                'mean_shift': float(mean_shift),
                'std_change': float(std_change),
                'explained_variance': float(self.pca.explained_variance_ratio_[i])
            }
        
        return pc_drift
