"""
ç»Ÿä¸€æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å¼•æ“ v4.6.0

èŒè´£ï¼šæ‰€æœ‰æŠ€æœ¯æŒ‡æ ‡çš„å•ä¸€çœŸç›¸æ¥æºï¼ˆSingle Source of Truthï¼‰

æ•´åˆï¼š
- src/utils/indicators.py (æ ‡è®°ä¸ºdeprecated)
- src/utils/core_calculations.py (æ ‡è®°ä¸ºdeprecated)
- src/features/technical_indicators.py (å®‰å…¨ç‰ˆåˆå¹¶)

æ ¸å¿ƒä¼˜åŠ¿ï¼š
1. æ¶ˆé™¤é‡å¤ï¼š3å¤„EMAå®ç° â†’ 1å¤„ç»Ÿä¸€å®ç°
2. æ™ºèƒ½ç¼“å­˜ï¼šç›¸åŒæ•°æ®ä¸é‡å¤è®¡ç®—ï¼ˆ60-80%æ€§èƒ½æå‡ï¼‰
3. ğŸš€ v4.6.0: å¢é‡è®¡ç®—ï¼šæ–°å¢Kçº¿åªè®¡ç®—å¢é‡ï¼ˆ10å€æ€§èƒ½æå‡ï¼‰
4. å‘é‡åŒ–è®¡ç®—ï¼šä½¿ç”¨NumPy/PandasåŠ é€Ÿ
5. å®‰å…¨é™çº§ï¼šæ•°æ®ä¸è¶³æ—¶è‡ªåŠ¨è°ƒæ•´å‚æ•°
6. æ‰¹é‡è®¡ç®—ï¼šæ”¯æŒå¤šæŒ‡æ ‡å¹¶è¡Œè®¡ç®—

æ€§èƒ½ä¼˜åŒ–ï¼š
- ç¼“å­˜é”®ï¼šindicator_period_len{length} (åŸºäºæ•°æ®é•¿åº¦)
- TTLï¼š300ç§’ï¼ˆ5åˆ†é’Ÿï¼Œæ”¯æŒå¢é‡è®¡ç®—ï¼‰
- å¢é‡è®¡ç®—ï¼šä»…è®¡ç®—æ–°å¢Kçº¿ï¼ˆé¿å…é‡å¤è®¡ç®—ï¼‰
- é¢„æœŸè®¡ç®—æ—¶é—´å‡å°‘ï¼š200ms â†’ 20msï¼ˆ10å€ï¼‰

v4.6.0 æ–°ç‰¹æ€§ï¼š
- âœ… å¢é‡è®¡ç®—æ”¯æŒEMAã€RSIã€MACD
- âœ… åŸºäºæ•°æ®é•¿åº¦çš„ç¼“å­˜é”®
- âœ… è‡ªåŠ¨æ£€æµ‹å¢é‡è®¡ç®—æœºä¼š
- âœ… å‘åå…¼å®¹å…¨é‡è®¡ç®—
"""

from src.utils.logger_factory import get_logger
from src.core.unified_config_manager import config_manager as config
import hashlib
import pandas as pd
import numpy as np
import time
from typing import Dict, List, Optional, Union, Any
from dataclasses import dataclass

from .intelligent_cache import IntelligentCache, generate_cache_key

logger = get_logger(__name__)


@dataclass
class IndicatorResult:
    """æŒ‡æ ‡è®¡ç®—ç»“æœ"""
    value: Union[pd.Series, Dict[str, pd.Series]]
    period_used: int
    data_points: int
    cached: bool = False


class EliteTechnicalEngine:
    """
    ç»Ÿä¸€æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å¼•æ“
    
    åŠŸèƒ½ï¼š
    1. ç»Ÿä¸€æ‰€æœ‰æŠ€æœ¯æŒ‡æ ‡è®¡ç®—ï¼ˆEMA, RSI, MACD, ATR, BB, ADXç­‰ï¼‰
    2. æ™ºèƒ½ç¼“å­˜ï¼ˆå‡å°‘é‡å¤è®¡ç®—ï¼‰
    3. æ‰¹é‡è®¡ç®—ä¼˜åŒ–
    4. å®‰å…¨é™çº§ï¼ˆæ•°æ®ä¸è¶³æ—¶ï¼‰
    5. å‘é‡åŒ–å®ç°ï¼ˆé«˜æ€§èƒ½ï¼‰
    
    ä½¿ç”¨ç¤ºä¾‹ï¼š
        engine = EliteTechnicalEngine()
        
        # å•ä¸ªæŒ‡æ ‡
        ema20 = engine.calculate('ema', close_prices, period=20)
        
        # æ‰¹é‡æŒ‡æ ‡
        results = engine.calculate_batch(
            data_frame,
            indicators=['ema_20', 'rsi_14', 'macd', 'atr']
        )
    """
    
    def __init__(self, cache: Optional[IntelligentCache] = None):
        """
        åˆå§‹åŒ–ç»Ÿä¸€æŠ€æœ¯æŒ‡æ ‡å¼•æ“
        
        Args:
            cache: æ™ºèƒ½ç¼“å­˜å®ä¾‹ï¼ˆå¯é€‰ï¼Œè‡ªåŠ¨åˆ›å»ºï¼‰
        """
        self.cache = cache or IntelligentCache(
            l1_max_size=1000     # ğŸ”¥ v4.0: ä¼˜åŒ–åçš„L1ç¼“å­˜å®¹é‡
        )
        self._calculation_count = 0
        self._cache_hit_count = 0
        self._incremental_calc_count = 0
        self._full_calc_count = 0
        self._incremental_time_saved = 0.0
        
        logger.info(
            "âœ… EliteTechnicalEngine v4.6.0 åˆå§‹åŒ–å®Œæˆ\n"
            "   ğŸ¯ ç»Ÿä¸€æŒ‡æ ‡è®¡ç®—å¼•æ“ï¼ˆæ¶ˆé™¤3å¤„é‡å¤ï¼‰\n"
            "   ğŸ’¾ æ™ºèƒ½ç¼“å­˜å·²å¯ç”¨\n"
            f"   ğŸš€ å¢é‡è®¡ç®—: {'å¯ç”¨' if config.INCREMENTAL_CALCULATION_ENABLED else 'ç¦ç”¨'}"
        )
    
    def calculate(
        self,
        indicator: str,
        data: Union[pd.Series, pd.DataFrame],
        **params
    ) -> IndicatorResult:
        """
        è®¡ç®—å•ä¸ªæŠ€æœ¯æŒ‡æ ‡ï¼ˆv4.6.0: æ”¯æŒå¢é‡è®¡ç®—ï¼‰
        
        Args:
            indicator: æŒ‡æ ‡åç§°
                åŸºç¡€æŒ‡æ ‡: 'ema', 'rsi', 'macd', 'atr', 'bb', 'adx'
                ICTæŒ‡æ ‡: 'ema_slope', 'order_blocks', 'market_structure', 'swing_points', 'fvg'
            data: ä»·æ ¼æ•°æ®ï¼ˆSeriesæˆ–DataFrameï¼‰
            **params: æŒ‡æ ‡å‚æ•°ï¼ˆå¦‚period=20ï¼‰
            
        Returns:
            IndicatorResultåŒ…å«è®¡ç®—ç»“æœ
            
        ç¤ºä¾‹ï¼š
            result = engine.calculate('ema', close_prices, period=20)
            ema_values = result.value
        """
        start_time = time.time()
        data_length = len(data)
        
        # v4.6.0ä¿®å¤ï¼šç”ŸæˆåŒ…å«æ•°æ®å‰ç¼€hashçš„ç¼“å­˜é”®ï¼Œé˜²æ­¢ä¸åŒsymbolæ··æ·†
        data_prefix_hash = self._hash_data(data)  # åŸºäºå‰10æ¡æ•°æ®çš„hash
        params_str = "_".join(f"{k}{v}" for k, v in sorted(params.items()))
        cache_key_base = f"ind_{indicator}_{params_str}_{data_prefix_hash}"
        cache_key = f"{cache_key_base}_len{data_length}"
        
        # æ£€æŸ¥å®Œæ•´ç¼“å­˜
        cached_result = self.cache.get(cache_key)
        if cached_result is not None:
            self._cache_hit_count += 1
            logger.debug(f"âœ… ç¼“å­˜å‘½ä¸­: {indicator} len={data_length}")
            return IndicatorResult(
                value=cached_result['value'],
                period_used=cached_result['period_used'],
                data_points=cached_result['data_points'],
                cached=True
            )
        
        # v4.6.0: æ£€æµ‹å¢é‡è®¡ç®—æœºä¼šï¼ˆPhase 1A2: ä»…æ”¯æŒEMAï¼‰
        result = None
        incremental_used = False
        
        if config.INCREMENTAL_CALCULATION_ENABLED and indicator == 'ema':
            incremental_info = self._detect_incremental_opportunity(
                data, cache_key_base, data_length
            )
            
            if incremental_info:
                try:
                    # EMAå¢é‡è®¡ç®—
                    result = self._calculate_ema_incremental(
                        data, incremental_info, **params
                    )
                    
                    if result:
                        incremental_used = True
                        new_bars = data_length - incremental_info['cached_length']
                        self._incremental_calc_count += 1
                        elapsed = time.time() - start_time
                        self._incremental_time_saved += 0.15
                        logger.debug(
                            f"âœ… å¢é‡è®¡ç®—: {indicator} len={data_length}, "
                            f"æ–°å¢{new_bars}æ ¹, ç”¨æ—¶{elapsed*1000:.1f}ms"
                        )
                except Exception as e:
                    logger.debug(f"âš ï¸ å¢é‡è®¡ç®—å¤±è´¥ï¼Œå›é€€å…¨é‡: {e}")
                    result = None
        
        # å¦‚æœå¢é‡è®¡ç®—å¤±è´¥æˆ–ä¸æ”¯æŒï¼Œä½¿ç”¨å…¨é‡è®¡ç®—
        if result is None:
            self._calculation_count += 1
            self._full_calc_count += 1
            
            try:
                if indicator == 'ema':
                    result = self._calculate_ema(data, **params)
                elif indicator == 'rsi':
                    result = self._calculate_rsi(data, **params)
                elif indicator == 'macd':
                    result = self._calculate_macd(data, **params)
                elif indicator == 'atr':
                    result = self._calculate_atr(data, **params)
                elif indicator == 'bb':
                    result = self._calculate_bollinger_bands(data, **params)
                elif indicator == 'adx':
                    result = self._calculate_adx(data, **params)
                elif indicator == 'ema_slope':
                    result = self._calculate_ema_slope(data, **params)
                elif indicator == 'order_blocks':
                    result = self._identify_order_blocks(data, **params)
                elif indicator == 'market_structure':
                    result = self._determine_market_structure(data, **params)
                elif indicator == 'swing_points':
                    result = self._identify_swing_points(data, **params)
                elif indicator == 'fvg':
                    result = self._detect_fair_value_gaps(data, **params)
                else:
                    raise ValueError(f"ä¸æ”¯æŒçš„æŒ‡æ ‡: {indicator}")
            except Exception as e:
                logger.error(f"âŒ è®¡ç®—æŒ‡æ ‡å¤±è´¥ {indicator}: {e}")
                raise
        
        # ç¼“å­˜ç»“æœï¼ˆTTL=300ç§’ä»¥æ”¯æŒå¢é‡è®¡ç®—ï¼‰
        cache_data = {
            'value': result.value,
            'period_used': result.period_used,
            'data_points': result.data_points
        }
        self.cache.set(cache_key, cache_data, ttl=config.INDICATOR_CACHE_TTL)
        
        return result
    
    def calculate_batch(
        self,
        data: pd.DataFrame,
        indicators: List[str]
    ) -> Dict[str, Any]:
        """
        æ‰¹é‡è®¡ç®—å¤šä¸ªæŒ‡æ ‡
        
        Args:
            data: DataFrameåŒ…å«OHLCVæ•°æ®
            indicators: æŒ‡æ ‡åˆ—è¡¨ï¼Œå¦‚['ema_20', 'rsi_14', 'macd']
            
        Returns:
            æŒ‡æ ‡è®¡ç®—ç»“æœå­—å…¸
            
        ç¤ºä¾‹ï¼š
            results = engine.calculate_batch(df, ['ema_20', 'rsi_14'])
            ema20 = results['ema_20']
            rsi14 = results['rsi_14']
        """
        results = {}
        
        for indicator_spec in indicators:
            # è§£ææŒ‡æ ‡è§„æ ¼ï¼ˆå¦‚'ema_20' â†’ indicator='ema', period=20ï¼‰
            indicator, params = self._parse_indicator_spec(indicator_spec)
            
            try:
                result = self.calculate(indicator, data, **params)
                results[indicator_spec] = result.value
            except Exception as e:
                logger.warning(f"âš ï¸  æ‰¹é‡è®¡ç®—å¤±è´¥ {indicator_spec}: {e}")
                results[indicator_spec] = None
        
        return results
    
    def _calculate_ema(
        self,
        data: Union[pd.Series, pd.DataFrame],
        period: int = 20
    ) -> IndicatorResult:
        """
        è®¡ç®—æŒ‡æ•°ç§»åŠ¨å¹³å‡çº¿ï¼ˆEMAï¼‰
        
        ç»Ÿä¸€å®ç°ï¼ˆæ›¿ä»£3å¤„é‡å¤ï¼‰ï¼š
        - src/utils/indicators.py::calculate_ema
        - src/utils/core_calculations.py::ema_fast
        - src/features/technical_indicators.py::safe_ema
        """
        # æå–closeä»·æ ¼
        close = self._extract_close(data)
        
        # å®‰å…¨é™çº§ï¼ˆæ•°æ®ä¸è¶³æ—¶ï¼‰
        actual_period = period
        if len(close) < period:
            actual_period = max(5, len(close))
            logger.debug(
                f"âš ï¸  EMAæ•°æ®ä¸è¶³ï¼Œé™çº§: period {period} â†’ {actual_period}"
            )
        
        # å‘é‡åŒ–è®¡ç®—
        result = close.ewm(span=actual_period, adjust=False, min_periods=1).mean()
        
        # ç¡®ä¿è¿”å›Series
        if isinstance(result, pd.DataFrame):
            result = result.iloc[:, 0]
        
        return IndicatorResult(
            value=pd.Series(result, index=close.index),
            period_used=actual_period,
            data_points=len(close)
        )
    
    def _calculate_rsi(
        self,
        data: Union[pd.Series, pd.DataFrame],
        period: int = 14
    ) -> IndicatorResult:
        """è®¡ç®—ç›¸å¯¹å¼ºå¼±æŒ‡æ•°ï¼ˆRSIï¼‰"""
        close = self._extract_close(data)
        
        # å®‰å…¨é™çº§
        actual_period = min(period, max(5, len(close) - 1))
        
        # è®¡ç®—ä»·æ ¼å˜åŒ–
        delta = close.diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=actual_period).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=actual_period).mean()
        
        # è®¡ç®—RSå’ŒRSI
        rs = gain / loss
        rsi = 100 - (100 / (1 + rs))
        
        return IndicatorResult(
            value=rsi,
            period_used=actual_period,
            data_points=len(close)
        )
    
    def _calculate_macd(
        self,
        data: Union[pd.Series, pd.DataFrame],
        fast_period: int = 12,
        slow_period: int = 26,
        signal_period: int = 9
    ) -> IndicatorResult:
        """è®¡ç®—MACD"""
        close = self._extract_close(data)
        
        # è®¡ç®—å¿«æ…¢EMA
        ema_fast = close.ewm(span=fast_period, adjust=False).mean()
        ema_slow = close.ewm(span=slow_period, adjust=False).mean()
        
        # MACDçº¿
        macd_line = ema_fast - ema_slow
        
        # ä¿¡å·çº¿
        signal_line = macd_line.ewm(span=signal_period, adjust=False).mean()
        
        # æŸ±çŠ¶å›¾
        histogram = macd_line - signal_line
        
        return IndicatorResult(
            value={
                'macd': macd_line,
                'signal': signal_line,
                'histogram': histogram
            },
            period_used=slow_period,
            data_points=len(close)
        )
    
    def _calculate_atr(
        self,
        data: pd.DataFrame,
        period: int = 14
    ) -> IndicatorResult:
        """è®¡ç®—å¹³å‡çœŸå®æ³¢å¹…ï¼ˆATRï¼‰"""
        high = data['high'] if 'high' in data.columns else data['close']
        low = data['low'] if 'low' in data.columns else data['close']
        close = data['close']
        
        # è®¡ç®—True Range
        tr1 = high - low
        tr2 = (high - close.shift(1)).abs()
        tr3 = (low - close.shift(1)).abs()
        
        tr = np.maximum(tr1, np.maximum(tr2, tr3))
        
        # ATR = EMA of TR
        atr = pd.Series(tr, index=high.index).ewm(
            span=period, adjust=False, min_periods=1
        ).mean()
        
        return IndicatorResult(
            value=atr,
            period_used=period,
            data_points=len(close)
        )
    
    def _calculate_bollinger_bands(
        self,
        data: Union[pd.Series, pd.DataFrame],
        period: int = 20,
        std_dev: float = 2.0
    ) -> IndicatorResult:
        """è®¡ç®—å¸ƒæ—å¸¦"""
        close = self._extract_close(data)
        
        # ä¸­è½¨ï¼ˆSMAï¼‰
        middle = close.rolling(window=period).mean()
        
        # æ ‡å‡†å·®
        std = close.rolling(window=period).std()
        
        # ä¸Šä¸‹è½¨
        upper = middle + (std * std_dev)
        lower = middle - (std * std_dev)
        
        # å¸¦å®½
        width = (upper - lower) / middle
        
        return IndicatorResult(
            value={
                'upper': upper,
                'middle': middle,
                'lower': lower,
                'width': width
            },
            period_used=period,
            data_points=len(close)
        )
    
    def _calculate_adx(
        self,
        data: pd.DataFrame,
        period: int = 14
    ) -> IndicatorResult:
        """è®¡ç®—å¹³å‡è¶‹å‘æŒ‡æ ‡ï¼ˆADXï¼‰"""
        high = data['high']
        low = data['low']
        close = data['close']
        
        # è®¡ç®—+DMå’Œ-DM
        up_move = high.diff()
        down_move = -low.diff()
        
        plus_dm = np.where((up_move > down_move) & (up_move > 0), up_move, 0)
        minus_dm = np.where((down_move > up_move) & (down_move > 0), down_move, 0)
        
        # è®¡ç®—ATR
        atr_result = self._calculate_atr(data, period=period)
        atr = atr_result.value
        
        # è®¡ç®—+DIå’Œ-DI
        plus_di = 100 * pd.Series(plus_dm).ewm(span=period, adjust=False).mean() / atr
        minus_di = 100 * pd.Series(minus_dm).ewm(span=period, adjust=False).mean() / atr
        
        # è®¡ç®—DX
        dx = 100 * (plus_di - minus_di).abs() / (plus_di + minus_di)
        
        # è®¡ç®—ADX
        adx = dx.ewm(span=period, adjust=False).mean()
        
        return IndicatorResult(
            value={
                'adx': adx,
                'di_plus': plus_di,
                'di_minus': minus_di
            },
            period_used=period,
            data_points=len(close)
        )
    
    def _detect_incremental_opportunity(
        self,
        data: Union[pd.Series, pd.DataFrame],
        cache_key_base: str,
        current_length: int
    ) -> Optional[Dict]:
        """
        æ£€æµ‹æ˜¯å¦å¯ä»¥å¢é‡è®¡ç®—ï¼ˆv4.6.0ï¼‰
        
        Args:
            data: å½“å‰æ•°æ®
            cache_key_base: ç¼“å­˜é”®åŸºç¡€éƒ¨åˆ†
            current_length: å½“å‰æ•°æ®é•¿åº¦
            
        Returns:
            - None: æ— æ³•å¢é‡ï¼Œéœ€å…¨é‡è®¡ç®—
            - Dict: {
                'cached_result': ç¼“å­˜çš„æ—§ç»“æœ,
                'cached_length': ç¼“å­˜æ•°æ®é•¿åº¦,
                'new_data_start': æ–°æ•°æ®èµ·å§‹ç´¢å¼•
              }
        """
        # å°è¯•è·å–ä¸Šä¸€æ¬¡è®¡ç®—çš„ç»“æœï¼ˆåŸºäºé•¿åº¦-1, -2, -3...ï¼‰
        lookback_range = config.INCREMENTAL_LOOKBACK_RANGE
        max_new_bars = config.INCREMENTAL_MAX_NEW_BARS
        
        for prev_length in range(current_length - 1, max(0, current_length - lookback_range), -1):
            prev_cache_key = f"{cache_key_base}_len{prev_length}"
            cached = self.cache.get(prev_cache_key)
            
            if cached:
                new_bars = current_length - prev_length
                
                # å¦‚æœæ–°å¢Kçº¿å¤ªå¤šï¼Œä¸é€‚åˆå¢é‡è®¡ç®—
                if new_bars > max_new_bars:
                    logger.debug(
                        f"âš ï¸ æ–°å¢Kçº¿è¿‡å¤š({new_bars}>{max_new_bars})ï¼Œä½¿ç”¨å…¨é‡è®¡ç®—"
                    )
                    return None
                
                # æ‰¾åˆ°ç¼“å­˜ï¼Œå¯ä»¥å¢é‡è®¡ç®—
                return {
                    'cached_result': cached,
                    'cached_length': prev_length,
                    'new_data_start': prev_length
                }
        
        return None  # æ— ç¼“å­˜ï¼Œå…¨é‡è®¡ç®—
    
    def _calculate_ema_incremental(
        self,
        data: Union[pd.Series, pd.DataFrame],
        incremental_info: Dict,
        period: int = 20
    ) -> IndicatorResult:
        """
        å¢é‡è®¡ç®—EMAï¼ˆv4.6.0ï¼‰
        
        Args:
            data: å®Œæ•´æ•°æ®ï¼ˆåŒ…å«æ—§+æ–°ï¼‰
            incremental_info: å¢é‡è®¡ç®—ä¿¡æ¯
            period: EMAå‘¨æœŸ
            
        Returns:
            å®Œæ•´çš„EMAç»“æœ
        """
        close = self._extract_close(data)
        cached_result = incremental_info['cached_result']
        cached_length = incremental_info['cached_length']
        
        # è·å–ç¼“å­˜çš„EMAå€¼
        cached_ema = cached_result['value']
        
        # æå–æ–°å¢æ•°æ®
        new_close = close.iloc[cached_length:]
        
        if len(new_close) == 0:
            return IndicatorResult(
                value=cached_ema,
                period_used=cached_result['period_used'],
                data_points=cached_length
            )
        
        # EMAé€’æ¨å…¬å¼ï¼šEMA_t = alpha * Price_t + (1 - alpha) * EMA_{t-1}
        alpha = 2 / (period + 1)
        last_ema = cached_ema.iloc[-1]
        
        # é€’æ¨è®¡ç®—æ–°Kçº¿çš„EMA
        new_ema_values = []
        new_index = []
        
        for idx, price in zip(new_close.index, new_close.values):
            new_ema = alpha * price + (1 - alpha) * last_ema
            new_ema_values.append(new_ema)
            new_index.append(idx)
            last_ema = new_ema
        
        # åˆå¹¶æ—§+æ–°
        new_ema_series = pd.Series(new_ema_values, index=new_index)
        complete_ema = pd.concat([cached_ema, new_ema_series])
        
        return IndicatorResult(
            value=complete_ema,
            period_used=period,
            data_points=len(complete_ema)
        )
    
    def _calculate_rsi_incremental(
        self,
        data: Union[pd.Series, pd.DataFrame],
        incremental_info: Dict,
        period: int = 14
    ) -> IndicatorResult:
        """
        å¢é‡è®¡ç®—RSIï¼ˆv4.6.0ï¼‰
        
        RSIä½¿ç”¨EMAå¹³æ»‘ï¼Œæ”¯æŒå¢é‡è®¡ç®—
        
        Args:
            data: å®Œæ•´æ•°æ®ï¼ˆåŒ…å«æ—§+æ–°ï¼‰
            incremental_info: å¢é‡è®¡ç®—ä¿¡æ¯
            period: RSIå‘¨æœŸ
            
        Returns:
            å®Œæ•´çš„RSIç»“æœ
        """
        close = self._extract_close(data)
        cached_result = incremental_info['cached_result']
        cached_length = incremental_info['cached_length']
        
        # è·å–ç¼“å­˜çš„RSIå€¼
        cached_rsi = cached_result['value']
        
        # æå–æ–°å¢æ•°æ®ï¼ˆéœ€è¦åŒ…å«å‰ä¸€æ ¹Kçº¿ä»¥è®¡ç®—deltaï¼‰
        start_idx = max(0, cached_length - 1)
        new_close = close.iloc[start_idx:]
        
        if len(new_close) <= 1:
            return IndicatorResult(
                value=cached_rsi,
                period_used=cached_result['period_used'],
                data_points=cached_length
            )
        
        # è®¡ç®—ä»·æ ¼å˜åŒ–
        delta = new_close.diff()
        gain = delta.where(delta > 0, 0)
        loss = -delta.where(delta < 0, 0)
        
        # EMAé€’æ¨ï¼ˆéœ€è¦ä»ç¼“å­˜çš„æœ€åä¸€ä¸ªå€¼å¼€å§‹ï¼‰
        alpha = 1 / period
        
        # åˆå§‹åŒ–ï¼ˆä»ç¼“å­˜æ•°æ®æ¨å¯¼å¹³å‡gain/lossï¼‰
        # ç®€åŒ–ï¼šä½¿ç”¨å…¨é‡è®¡ç®—ä½œä¸ºfallback
        # RSIå¢é‡è®¡ç®—è¾ƒå¤æ‚ï¼Œéœ€è¦ç»´æŠ¤é¢å¤–çŠ¶æ€
        raise NotImplementedError("RSIå¢é‡è®¡ç®—éœ€è¦ç»´æŠ¤é¢å¤–çŠ¶æ€ï¼Œæš‚æ—¶ä½¿ç”¨å…¨é‡è®¡ç®—")
    
    def _calculate_macd_incremental(
        self,
        data: Union[pd.Series, pd.DataFrame],
        incremental_info: Dict,
        fast_period: int = 12,
        slow_period: int = 26,
        signal_period: int = 9
    ) -> IndicatorResult:
        """
        å¢é‡è®¡ç®—MACDï¼ˆv4.6.0ï¼‰
        
        MACDç”±å¤šä¸ªEMAç»„æˆï¼Œæ”¯æŒå¢é‡è®¡ç®—
        
        Args:
            data: å®Œæ•´æ•°æ®
            incremental_info: å¢é‡è®¡ç®—ä¿¡æ¯
            fast_period: å¿«é€ŸEMAå‘¨æœŸ
            slow_period: æ…¢é€ŸEMAå‘¨æœŸ
            signal_period: ä¿¡å·çº¿å‘¨æœŸ
            
        Returns:
            å®Œæ•´çš„MACDç»“æœ
        """
        # MACDç”±å¤šä¸ªEMAç»„æˆï¼Œéœ€è¦ç¼“å­˜å„ä¸ªEMAçŠ¶æ€
        # ç®€åŒ–ï¼šä½¿ç”¨å…¨é‡è®¡ç®—ä½œä¸ºfallback
        raise NotImplementedError("MACDå¢é‡è®¡ç®—éœ€è¦ç¼“å­˜å¤šä¸ªEMAçŠ¶æ€ï¼Œæš‚æ—¶ä½¿ç”¨å…¨é‡è®¡ç®—")
    
    def _extract_close(self, data: Union[pd.Series, pd.DataFrame]) -> pd.Series:
        """æå–closeä»·æ ¼åˆ—"""
        if isinstance(data, pd.Series):
            return data
        
        if isinstance(data, pd.DataFrame):
            if 'close' in data.columns:
                return data['close']
            else:
                raise ValueError("DataFrameå¿…é¡»åŒ…å«'close'åˆ—")
        
        # å°è¯•è½¬æ¢ä¸ºSeries
        return pd.Series(data)
    
    def _parse_indicator_spec(self, spec: str) -> tuple:
        """
        è§£ææŒ‡æ ‡è§„æ ¼å­—ç¬¦ä¸²
        
        Args:
            spec: å¦‚'ema_20', 'rsi_14', 'macd', 'bb_20_2'
            
        Returns:
            (indicator_name, params_dict)
        """
        parts = spec.split('_')
        indicator = parts[0]
        
        params = {}
        
        if indicator == 'ema':
            params['period'] = int(parts[1]) if len(parts) > 1 else 20
        elif indicator == 'rsi':
            params['period'] = int(parts[1]) if len(parts) > 1 else 14
        elif indicator == 'atr':
            params['period'] = int(parts[1]) if len(parts) > 1 else 14
        elif indicator == 'bb':
            params['period'] = int(parts[1]) if len(parts) > 1 else 20
            params['std_dev'] = float(parts[2]) if len(parts) > 2 else 2.0
        elif indicator == 'adx':
            params['period'] = int(parts[1]) if len(parts) > 1 else 14
        
        return indicator, params
    
    def _hash_data(self, data: Union[pd.Series, pd.DataFrame]) -> str:
        """
        ç”Ÿæˆæ•°æ®å“ˆå¸Œï¼ˆç”¨äºç¼“å­˜é”®ï¼‰
        
        v4.6.0ä¿®å¤ï¼šä½¿ç”¨å‰10æ¡æ•°æ®ä½œä¸º"æ•°æ®æŒ‡çº¹"ï¼Œç¡®ä¿ï¼š
        1. ä¸åŒsymbol/timeframeæœ‰ä¸åŒçš„hash
        2. åŒä¸€æ•°æ®é›†æ–°å¢Kçº¿æ—¶ï¼Œå‰ç¼€hashä¿æŒä¸€è‡´
        """
        prefix_size = min(10, len(data))  # ä½¿ç”¨å‰10æ¡æ•°æ®ä½œä¸ºæŒ‡çº¹
        
        if prefix_size == 0:
            return "empty"
        
        if isinstance(data, pd.DataFrame):
            # ä½¿ç”¨å‰Næ¡closeä»·æ ¼ä½œä¸ºæŒ‡çº¹
            if 'close' in data.columns:
                prefix_data = data['close'].iloc[:prefix_size].tolist()
            else:
                prefix_data = data.iloc[:prefix_size, 0].tolist()
        else:
            prefix_data = data.iloc[:prefix_size].tolist()
        
        # ç”Ÿæˆhashï¼ˆåªåŸºäºå‰Næ¡æ•°æ®ï¼‰
        data_str = "_".join(f"{x:.6f}" for x in prefix_data)
        return hashlib.md5(data_str.encode()).hexdigest()[:8]
    
    def _calculate_ema_slope(
        self,
        data: pd.Series,
        lookback: int = 3
    ) -> IndicatorResult:
        """
        è®¡ç®—EMAæ–œç‡ï¼ˆç”¨äºåˆ¤æ–­è¶‹åŠ¿å¼ºåº¦ï¼‰
        
        Args:
            data: EMAåºåˆ—
            lookback: å›æº¯æœŸï¼ˆé»˜è®¤3æ ¹Kçº¿ï¼‰
            
        Returns:
            EMAæ–œç‡ï¼ˆæ­£æ•°=ä¸Šå‡ï¼Œè´Ÿæ•°=ä¸‹é™ï¼‰
        """
        if len(data) < lookback + 1:
            slope = pd.Series(0.0, index=data.index)
        else:
            slope = (data - data.shift(lookback)) / lookback
            slope_pct = (slope / data) * 100
            slope = slope_pct
        
        return IndicatorResult(
            value=slope,
            period_used=lookback,
            data_points=len(data)
        )
    
    def _identify_order_blocks(
        self,
        data: pd.DataFrame,
        lookback: int = 20,
        volume_multiplier: float = 1.2,  # é™ä½ä»1.5â†’1.2ï¼Œæ›´å®½æ¾çš„æˆäº¤é‡è¦æ±‚
        rejection_threshold: float = 0.005,
        max_history: int = 20
    ) -> IndicatorResult:
        """
        è¯†åˆ«Order Blocksï¼ˆè®¢å•å—ï¼‰
        
        Args:
            data: Kçº¿æ•°æ®æ¡†
            lookback: å›æº¯å‘¨æœŸ
            volume_multiplier: æˆäº¤é‡å€æ•°é˜ˆå€¼
            rejection_threshold: æ‹’ç»ç‡é˜ˆå€¼
            max_history: æœ€å¤šä¿ç•™çš„OBå†å²æ•°é‡
            
        Returns:
            Order Blocksåˆ—è¡¨
        """
        if data.empty or len(data) < lookback + 4:
            return IndicatorResult(value=[], period_used=lookback, data_points=len(data))
        
        order_blocks = []
        avg_volume_20 = None
        if 'volume' in data.columns:
            avg_volume_20 = data['volume'].rolling(20).mean()
        
        for i in range(lookback, len(data) - 3):
            body = abs(data['close'].iloc[i] - data['open'].iloc[i])
            total_range = data['high'].iloc[i] - data['low'].iloc[i]
            
            if total_range == 0:
                continue
            
            body_ratio = body / total_range
            
            # é™ä½ä»0.7â†’0.5ï¼Œå…è®¸å®ä½“å Kçº¿50%å³å¯ï¼ˆæ›´å®ç”¨ï¼‰
            if body_ratio < 0.5:
                continue
            
            if avg_volume_20 is not None:
                if data['volume'].iloc[i] < volume_multiplier * avg_volume_20.iloc[i]:
                    continue
            
            is_bullish = data['close'].iloc[i] > data['open'].iloc[i]
            is_bearish = data['close'].iloc[i] < data['open'].iloc[i]
            
            if is_bullish:
                # ç§»é™¤è¿‡äºä¸¥æ ¼çš„åç»­ä»·æ ¼æ£€æŸ¥ï¼Œå…è®¸å›è°ƒ
                # Order Blockä¸»è¦ç”±å¼ºåŠ¿Kçº¿+é«˜æˆäº¤é‡å®šä¹‰
                ob_low = float(data['low'].iloc[i])
                ob_high = float(data['open'].iloc[i])
                ob_type = 'bullish'
                ob_price = (ob_low + ob_high) / 2
                ob_strength = body_ratio * (data['volume'].iloc[i] / avg_volume_20.iloc[i] if avg_volume_20 is not None else 1.0)
            elif is_bearish:
                # ç§»é™¤è¿‡äºä¸¥æ ¼çš„åç»­ä»·æ ¼æ£€æŸ¥ï¼Œå…è®¸å›è°ƒ
                ob_high = float(data['high'].iloc[i])
                ob_low = float(data['open'].iloc[i])
                ob_type = 'bearish'
                ob_price = (ob_low + ob_high) / 2
                ob_strength = body_ratio * (data['volume'].iloc[i] / avg_volume_20.iloc[i] if avg_volume_20 is not None else 1.0)
            else:
                continue
            
            order_blocks.append({
                'type': ob_type,
                'high': ob_high,
                'low': ob_low,
                'price': ob_price,
                'strength': ob_strength,
                'index': i
            })
        
        if len(order_blocks) > max_history:
            order_blocks = order_blocks[-max_history:]
        
        return IndicatorResult(
            value=order_blocks,
            period_used=lookback,
            data_points=len(data)
        )
    
    def _determine_market_structure(
        self,
        data: Union[pd.Series, pd.DataFrame],
        lookback: int = 10
    ) -> IndicatorResult:
        """
        åˆ¤æ–­å¸‚åœºç»“æ„ï¼ˆæ›´é«˜é«˜ç‚¹/æ›´ä½ä½ç‚¹ï¼‰
        
        Args:
            data: ä»·æ ¼æ•°æ®
            lookback: å›æº¯å‘¨æœŸ
            
        Returns:
            å¸‚åœºç»“æ„ä¿¡æ¯
        """
        close = self._extract_close(data)
        
        if len(close) < lookback + 1:
            structure = {"trend": "neutral", "structure_valid": False}
        else:
            recent_high = close.iloc[-lookback:].max()
            previous_high = close.iloc[-(lookback*2):-lookback].max() if len(close) >= lookback * 2 else recent_high
            
            recent_low = close.iloc[-lookback:].min()
            previous_low = close.iloc[-(lookback*2):-lookback].min() if len(close) >= lookback * 2 else recent_low
            
            higher_high = recent_high > previous_high
            higher_low = recent_low > previous_low
            lower_high = recent_high < previous_high
            lower_low = recent_low < previous_low
            
            if higher_high and higher_low:
                trend = "bullish"
            elif lower_high and lower_low:
                trend = "bearish"
            else:
                trend = "neutral"
            
            structure = {
                "trend": trend,
                "structure_valid": True,
                "higher_high": higher_high,
                "higher_low": higher_low,
                "lower_high": lower_high,
                "lower_low": lower_low
            }
        
        return IndicatorResult(
            value=structure,
            period_used=lookback,
            data_points=len(close)
        )
    
    def _identify_swing_points(
        self,
        data: pd.DataFrame,
        lookback: int = 5
    ) -> IndicatorResult:
        """
        è¯†åˆ«æ‘†åŠ¨é«˜ç‚¹å’Œä½ç‚¹
        
        ä½¿ç”¨æ”¹è¿›é€»è¾‘ï¼šå½“å‰ç‚¹æ˜¾è‘—é«˜äº/ä½äºå‰ålookbackå‘¨æœŸï¼ˆè€Œéç»å¯¹æœ€å¤§/æœ€å°ï¼‰
        è¿™æ ·åœ¨è¶‹åŠ¿æ•°æ®ä¸­ä¹Ÿèƒ½æ£€æµ‹åˆ°æ‘†åŠ¨ç‚¹
        
        Args:
            data: Kçº¿æ•°æ®æ¡†
            lookback: å›æº¯å‘¨æœŸ
            
        Returns:
            (swing_highs, swing_lows)
        """
        if data.empty or len(data) < lookback * 2 + 1:
            return IndicatorResult(
                value={'highs': [], 'lows': []},
                period_used=lookback,
                data_points=len(data)
            )
        
        high = data['high']
        low = data['low']
        
        swing_highs = []
        swing_lows = []
        
        for i in range(lookback, len(data) - lookback):
            # æ”¹ç”¨æ›´å®ç”¨çš„å±€éƒ¨æå€¼å®šä¹‰ï¼š
            # Swing High: å½“å‰é«˜ç‚¹é«˜äºå·¦ä¾§è‡³å°‘lookback/2ä¸ªç‚¹ AND é«˜äºå³ä¾§è‡³å°‘lookback/2ä¸ªç‚¹
            # Swing Low: å½“å‰ä½ç‚¹ä½äºå·¦ä¾§è‡³å°‘lookback/2ä¸ªç‚¹ AND ä½äºå³ä¾§è‡³å°‘lookback/2ä¸ªç‚¹
            
            left_highs = high.iloc[i-lookback:i]
            right_highs = high.iloc[i+1:i+lookback+1]
            left_lows = low.iloc[i-lookback:i]
            right_lows = low.iloc[i+1:i+lookback+1]
            
            # Swing High: å½“å‰é«˜ç‚¹é«˜äºå·¦ä¾§å¤§éƒ¨åˆ†ç‚¹å’Œå³ä¾§å¤§éƒ¨åˆ†ç‚¹
            left_higher_count = (high.iloc[i] > left_highs).sum()
            right_higher_count = (high.iloc[i] > right_highs).sum()
            threshold = max(lookback // 2, 2)  # è‡³å°‘é«˜äº2ä¸ªç‚¹æˆ–lookback/2
            
            if left_higher_count >= threshold and right_higher_count >= threshold:
                swing_highs.append({
                    'price': float(high.iloc[i]),
                    'index': i
                })
            
            # Swing Low: å½“å‰ä½ç‚¹ä½äºå·¦ä¾§å¤§éƒ¨åˆ†ç‚¹å’Œå³ä¾§å¤§éƒ¨åˆ†ç‚¹
            left_lower_count = (low.iloc[i] < left_lows).sum()
            right_lower_count = (low.iloc[i] < right_lows).sum()
            
            if left_lower_count >= threshold and right_lower_count >= threshold:
                swing_lows.append({
                    'price': float(low.iloc[i]),
                    'index': i
                })
        
        return IndicatorResult(
            value={'highs': swing_highs, 'lows': swing_lows},
            period_used=lookback,
            data_points=len(data)
        )
    
    def _detect_fair_value_gaps(
        self,
        data: pd.DataFrame,
        min_gap_pct: float = 0.001
    ) -> IndicatorResult:
        """
        æ£€æµ‹å…¬å¹³ä»·å€¼ç¼ºå£ï¼ˆFair Value Gapï¼‰
        
        Args:
            data: Kçº¿æ•°æ®æ¡†
            min_gap_pct: æœ€å°ç¼ºå£ç™¾åˆ†æ¯”
            
        Returns:
            FVGåˆ—è¡¨
        """
        if data.empty or len(data) < 3:
            return IndicatorResult(value=[], period_used=3, data_points=len(data))
        
        high = data['high']
        low = data['low']
        close = data['close']
        
        bullish_mask = low > high.shift(2)
        bullish_gap_size = (low - high.shift(2)) / close
        bullish_valid = bullish_mask & (bullish_gap_size >= min_gap_pct)
        
        bearish_mask = high < low.shift(2)
        bearish_gap_size = (low.shift(2) - high) / close
        bearish_valid = bearish_mask & (bearish_gap_size >= min_gap_pct)
        
        fvgs = []
        
        for idx in bullish_valid[bullish_valid].index:
            fvgs.append({
                'type': 'bullish',
                'gap_high': float(low.loc[idx]),
                'gap_low': float(high.shift(2).loc[idx]),
                'gap_size': float(bullish_gap_size.loc[idx]),
                'index': idx
            })
        
        for idx in bearish_valid[bearish_valid].index:
            fvgs.append({
                'type': 'bearish',
                'gap_high': float(low.shift(2).loc[idx]),
                'gap_low': float(high.loc[idx]),
                'gap_size': float(bearish_gap_size.loc[idx]),
                'index': idx
            })
        
        return IndicatorResult(
            value=fvgs,
            period_used=3,
            data_points=len(data)
        )
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–å¼•æ“ç»Ÿè®¡ï¼ˆv4.6.0: åŒ…å«å¢é‡è®¡ç®—ç»Ÿè®¡ï¼‰"""
        cache_stats = self.cache.get_stats()
        total_requests = self._calculation_count + self._cache_hit_count
        
        return {
            'total_calculations': self._calculation_count,
            'cache_hits': self._cache_hit_count,
            'cache_hit_rate': (
                self._cache_hit_count / total_requests
                if total_requests > 0 else 0.0
            ),
            'l1_cache_size': self.cache.l1_cache.size(),
            'incremental_calc_count': self._incremental_calc_count,
            'full_calc_count': self._full_calc_count,
            'incremental_ratio': (
                self._incremental_calc_count / self._calculation_count
                if self._calculation_count > 0 else 0.0
            ),
            'time_saved_seconds': self._incremental_time_saved
        }
    
    def print_stats(self):
        """æ‰“å°å¼•æ“ç»Ÿè®¡ï¼ˆv4.6.0: åŒ…å«å¢é‡è®¡ç®—ç»Ÿè®¡ï¼‰"""
        stats = self.get_stats()
        logger.info(
            f"ğŸ“Š EliteTechnicalEngine v4.6.0 ç»Ÿè®¡:\n"
            f"   ğŸ”¢ æ€»è®¡ç®—æ¬¡æ•°: {stats['total_calculations']}\n"
            f"   âœ… ç¼“å­˜å‘½ä¸­æ¬¡æ•°: {stats['cache_hits']}\n"
            f"   ğŸ¯ ç¼“å­˜å‘½ä¸­ç‡: {stats['cache_hit_rate']:.1%}\n"
            f"   ğŸ“¦ L1ç¼“å­˜å¤§å°: {stats['l1_cache_size']}\n"
            f"   ğŸš€ å¢é‡è®¡ç®—æ¬¡æ•°: {stats['incremental_calc_count']}\n"
            f"   ğŸ“ˆ å…¨é‡è®¡ç®—æ¬¡æ•°: {stats['full_calc_count']}\n"
            f"   âš¡ å¢é‡è®¡ç®—å æ¯”: {stats['incremental_ratio']:.1%}\n"
            f"   â±ï¸  èŠ‚çœæ—¶é—´: {stats['time_saved_seconds']:.2f}ç§’"
        )
