"""
æ™ºèƒ½å†…å­˜ç¼“å­˜ç³»ç»Ÿ v4.0 (Phase 3 ä¼˜åŒ–)

èŒè´£ï¼šæä¾›L1å†…å­˜ç¼“å­˜ï¼Œä¼˜åŒ–è®¡ç®—å’Œæ•°æ®è·å–æ€§èƒ½

æ¶æ„ï¼š
- L1ç¼“å­˜ï¼šLRUå†…å­˜ç¼“å­˜ï¼ˆå¿«é€Ÿè®¿é—®ï¼Œå®¹é‡ä¼˜åŒ–ï¼‰
- PostgreSQLï¼šæŒä¹…åŒ–æ•°æ®å­˜å‚¨ï¼ˆæ›¿ä»£L2æ–‡ä»¶ç¼“å­˜ï¼‰

ğŸ”¥ v4.0 é‡å¤§æ”¹è¿›ï¼š
- ç§»é™¤L2æŒä¹…åŒ–ç¼“å­˜ï¼ˆæ¶ˆé™¤é˜»å¡I/Oï¼‰
- ç§»é™¤pickleæ–‡ä»¶æ“ä½œï¼ˆæ¶ˆé™¤ç£ç›˜I/Oç“¶é¢ˆï¼‰
- 100%å†…å­˜æ“ä½œï¼ˆæ— äº‹ä»¶å¾ªç¯é˜»å¡ï¼‰
- PostgreSQLä½œä¸ºå”¯ä¸€æ•°æ®æŒä¹…åŒ–å±‚

æ€§èƒ½ä¼˜åŒ–ï¼š
- æŠ€æœ¯æŒ‡æ ‡ç¼“å­˜ï¼šå‡å°‘60-80%é‡å¤è®¡ç®—
- Kçº¿æ•°æ®ç¼“å­˜ï¼šå‡å°‘30-40% APIè¯·æ±‚
- æ™ºèƒ½TTLï¼šåŸºäºæ•°æ®ç±»å‹åŠ¨æ€è°ƒæ•´è¿‡æœŸæ—¶é—´
- é›¶é˜»å¡I/Oï¼šçº¯å†…å­˜æ“ä½œï¼ˆ10-50ms â†’ 0.1-1msï¼‰

é¢„æœŸæ”¶ç›Šï¼š
- ç¼“å­˜å‘½ä¸­ç‡ï¼š85-90%ï¼ˆL1ä¼˜åŒ–ï¼‰
- CPUèŠ‚çœï¼š60-80%ï¼ˆæŒ‡æ ‡è®¡ç®—ï¼‰
- å»¶è¿Ÿé™ä½ï¼šæ¶ˆé™¤æ‰€æœ‰åŒæ­¥æ–‡ä»¶I/O
- å†…å­˜èŠ‚çœï¼š250MBï¼ˆç§»é™¤L2ç¼“å­˜ï¼‰
"""

import time
import hashlib
from src.utils.logger_factory import get_logger
from typing import Any, Optional, Tuple
from collections import OrderedDict
from dataclasses import dataclass

logger = get_logger(__name__)


@dataclass
class CacheStats:
    """ç¼“å­˜ç»Ÿè®¡æ•°æ®"""
    l1_hits: int = 0
    misses: int = 0
    evictions: int = 0
    total_gets: int = 0
    
    @property
    def hit_rate(self) -> float:
        """æ€»å‘½ä¸­ç‡ï¼ˆL1ï¼‰"""
        if self.total_gets == 0:
            return 0.0
        return self.l1_hits / self.total_gets
    
    def reset(self):
        """é‡ç½®ç»Ÿè®¡"""
        self.l1_hits = 0
        self.misses = 0
        self.evictions = 0
        self.total_gets = 0


class LRUCache:
    """L1å†…å­˜LRUç¼“å­˜"""
    
    def __init__(self, max_size: int = 5000):
        """
        åˆå§‹åŒ–LRUç¼“å­˜
        
        Args:
            max_size: æœ€å¤§ç¼“å­˜æ¡ç›®æ•°
        """
        self.max_size = max_size
        self.cache: OrderedDict[str, Tuple[Any, float]] = OrderedDict()
        self._eviction_count = 0
    
    def get(self, key: str) -> Optional[Any]:
        """
        è·å–ç¼“å­˜å€¼
        
        Args:
            key: ç¼“å­˜é”®
            
        Returns:
            ç¼“å­˜å€¼æˆ–None
        """
        if key not in self.cache:
            return None
        
        value, expiry = self.cache[key]
        
        # æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
        if expiry > 0 and time.time() > expiry:
            del self.cache[key]
            return None
        
        # ç§»åŠ¨åˆ°æœ«å°¾ï¼ˆæœ€è¿‘ä½¿ç”¨ï¼‰
        self.cache.move_to_end(key)
        return value
    
    def set(self, key: str, value: Any, ttl: Optional[int] = None):
        """
        è®¾ç½®ç¼“å­˜å€¼
        
        Args:
            key: ç¼“å­˜é”®
            value: ç¼“å­˜å€¼
            ttl: è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰ï¼ŒNoneè¡¨ç¤ºæ°¸ä¸è¿‡æœŸ
        """
        # è®¡ç®—è¿‡æœŸæ—¶é—´
        expiry = time.time() + ttl if ttl else 0
        
        # å¦‚æœå·²å­˜åœ¨ï¼Œæ›´æ–°å¹¶ç§»åˆ°æœ«å°¾
        if key in self.cache:
            self.cache[key] = (value, expiry)
            self.cache.move_to_end(key)
            return
        
        # å¦‚æœè¶…å‡ºå®¹é‡ï¼Œç§»é™¤æœ€æ—§çš„
        if len(self.cache) >= self.max_size:
            oldest_key = next(iter(self.cache))
            del self.cache[oldest_key]
            self._eviction_count += 1
        
        self.cache[key] = (value, expiry)
    
    def clear(self):
        """æ¸…ç©ºç¼“å­˜"""
        self.cache.clear()
    
    def size(self) -> int:
        """å½“å‰ç¼“å­˜å¤§å°"""
        return len(self.cache)


class IntelligentCache:
    """
    æ™ºèƒ½å†…å­˜ç¼“å­˜ç³»ç»Ÿ v4.0
    
    åŠŸèƒ½ï¼š
    1. L1å†…å­˜ç¼“å­˜ï¼ˆå¿«é€Ÿè®¿é—®ï¼Œé›¶é˜»å¡ï¼‰
    2. æ™ºèƒ½TTLï¼ˆåŸºäºæ•°æ®ç±»å‹ï¼‰
    3. ç»Ÿè®¡ç›‘æ§
    
    ğŸ”¥ v4.0æ”¹è¿›ï¼š
    - ç§»é™¤L2æ–‡ä»¶ç¼“å­˜ï¼ˆæ¶ˆé™¤é˜»å¡I/Oï¼‰
    - çº¯å†…å­˜æ“ä½œï¼ˆæ— ç£ç›˜I/Oï¼‰
    - PostgreSQLä½œä¸ºæŒä¹…åŒ–å±‚
    """
    
    def __init__(self, l1_max_size: int = 1000):
        """
        åˆå§‹åŒ–æ™ºèƒ½ç¼“å­˜
        
        ğŸ”¥ v4.0ä¼˜åŒ–ï¼š
        - L1é»˜è®¤1000æ¡ç›®ï¼ˆä¼˜åŒ–åçš„å®¹é‡ï¼‰
        - L2å®Œå…¨ç§»é™¤ï¼ˆæ¶ˆé™¤é˜»å¡I/Oï¼‰
        - 100%å†…å­˜æ“ä½œï¼ˆæ— äº‹ä»¶å¾ªç¯é˜»å¡ï¼‰
        
        Args:
            l1_max_size: L1ç¼“å­˜æœ€å¤§æ¡ç›®æ•°
        """
        self.l1_cache = LRUCache(max_size=l1_max_size)
        self.stats = CacheStats()
        
        logger.info(
            f"âœ… IntelligentCache v4.0 åˆå§‹åŒ–å®Œæˆ\n"
            f"   ğŸ“¦ L1å†…å­˜ç¼“å­˜: {l1_max_size} æ¡ç›®\n"
            f"   âš¡ é›¶é˜»å¡I/Oï¼ˆçº¯å†…å­˜æ“ä½œï¼‰\n"
            f"   ğŸ’¾ æŒä¹…åŒ–: PostgreSQLï¼ˆæ›¿ä»£L2æ–‡ä»¶ç¼“å­˜ï¼‰"
        )
    
    def get(self, key: str) -> Optional[Any]:
        """
        è·å–ç¼“å­˜å€¼ï¼ˆL1å†…å­˜ç¼“å­˜ï¼‰
        
        Args:
            key: ç¼“å­˜é”®
            
        Returns:
            ç¼“å­˜å€¼æˆ–None
        """
        self.stats.total_gets += 1
        
        # L1å†…å­˜ç¼“å­˜æŸ¥æ‰¾ï¼ˆé›¶é˜»å¡ï¼‰
        value = self.l1_cache.get(key)
        if value is not None:
            self.stats.l1_hits += 1
            return value
        
        self.stats.misses += 1
        return None
    
    def set(self, key: str, value: Any, ttl: Optional[int] = None):
        """
        è®¾ç½®ç¼“å­˜å€¼ï¼ˆL1å†…å­˜ç¼“å­˜ï¼‰
        
        Args:
            key: ç¼“å­˜é”®
            value: ç¼“å­˜å€¼
            ttl: è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰
        """
        # å¦‚æœæœªæŒ‡å®šTTLï¼Œä½¿ç”¨æ™ºèƒ½TTL
        if ttl is None:
            ttl = self._calculate_smart_ttl(key, value)
        
        # å†™å…¥L1å†…å­˜ç¼“å­˜ï¼ˆé›¶é˜»å¡ï¼‰
        self.l1_cache.set(key, value, ttl=ttl)
    
    def _calculate_smart_ttl(self, key: str, value: Any) -> int:
        """
        æ™ºèƒ½è®¡ç®—TTL
        
        ğŸ”¥ v4.0ä¼˜åŒ–ï¼šåŸºäºæ•°æ®ç±»å‹çš„æ™ºèƒ½TTL
        
        ä¸åŒæ•°æ®ç±»å‹ä½¿ç”¨ä¸åŒçš„TTLï¼š
        - æŠ€æœ¯æŒ‡æ ‡ï¼š300ç§’ï¼ˆ5åˆ†é’Ÿï¼ŒåŒ¹é…ç­–ç•¥æ‰«æå‘¨æœŸï¼‰
        - Kçº¿æ•°æ®ï¼š600ç§’ï¼ˆ10åˆ†é’Ÿï¼Œè¾ƒç¨³å®šï¼‰
        - ä¿¡å·ç‰¹å¾ï¼š60ç§’ï¼ˆå¿«é€Ÿè¿‡æœŸï¼‰
        - é»˜è®¤ï¼š300ç§’ï¼ˆ5åˆ†é’Ÿï¼‰
        """
        if 'indicator' in key or 'ema' in key or 'rsi' in key:
            return 300
        elif 'kline' in key or 'ohlcv' in key:
            return 600
        elif 'signal' in key or 'feature' in key:
            return 60
        else:
            return 300
    
    def clear(self):
        """æ¸…ç©ºL1å†…å­˜ç¼“å­˜"""
        self.l1_cache.clear()
        logger.info("ğŸ—‘ï¸  L1ç¼“å­˜å·²æ¸…ç©º")
    
    def get_stats(self) -> CacheStats:
        """è·å–ç¼“å­˜ç»Ÿè®¡"""
        return self.stats
    
    def print_stats(self):
        """æ‰“å°ç¼“å­˜ç»Ÿè®¡"""
        logger.info(
            f"ğŸ“Š ç¼“å­˜ç»Ÿè®¡ (v4.0):\n"
            f"   âœ… L1å‘½ä¸­: {self.stats.l1_hits} ({self.stats.hit_rate:.1%})\n"
            f"   âŒ æœªå‘½ä¸­: {self.stats.misses}\n"
            f"   ğŸ“¦ L1å¤§å°: {self.l1_cache.size()}/{self.l1_cache.max_size}\n"
            f"   âš¡ é›¶é˜»å¡I/Oï¼ˆçº¯å†…å­˜æ“ä½œï¼‰"
        )


def generate_cache_key(*args, **kwargs) -> str:
    """
    ç”Ÿæˆç¼“å­˜é”®
    
    Args:
        *args: ä½ç½®å‚æ•°
        **kwargs: å…³é”®å­—å‚æ•°
        
    Returns:
        ç¼“å­˜é”®ï¼ˆMD5å“ˆå¸Œï¼‰
    
    ç¤ºä¾‹ï¼š
        key = generate_cache_key('BTCUSDT', '1h', period=20)
        # è¾“å‡º: 'indicator_btcusdt_1h_20_abc123...'
    """
    # ç»„åˆæ‰€æœ‰å‚æ•°
    key_parts = [str(arg) for arg in args]
    key_parts.extend(f"{k}={v}" for k, v in sorted(kwargs.items()))
    
    # ç”ŸæˆMD5å“ˆå¸Œ
    key_string = "_".join(key_parts)
    hash_obj = hashlib.md5(key_string.encode())
    
    return hash_obj.hexdigest()[:16]  # å‰16ä½è¶³å¤Ÿ
