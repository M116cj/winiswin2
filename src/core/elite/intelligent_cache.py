"""
æ™ºèƒ½åˆ†å±‚ç¼“å­˜ç³»ç»Ÿ v3.20

èŒè´£ï¼šæä¾›L1å†…å­˜+L2æŒä¹…åŒ–ç¼“å­˜ï¼Œä¼˜åŒ–è®¡ç®—å’Œæ•°æ®è·å–æ€§èƒ½

æ¶æ„ï¼š
- L1ç¼“å­˜ï¼šLRUå†…å­˜ç¼“å­˜ï¼ˆå¿«é€Ÿè®¿é—®ï¼Œå®¹é‡æœ‰é™ï¼‰
- L2ç¼“å­˜ï¼šæŒä¹…åŒ–ç¼“å­˜ï¼ˆå¤§å®¹é‡ï¼Œæ”¯æŒè·¨ä¼šè¯ï¼‰
- è‡ªåŠ¨æå‡ï¼šL2å‘½ä¸­æ•°æ®è‡ªåŠ¨æå‡åˆ°L1

æ€§èƒ½ä¼˜åŒ–ï¼š
- æŠ€æœ¯æŒ‡æ ‡ç¼“å­˜ï¼šå‡å°‘60-80%é‡å¤è®¡ç®—
- Kçº¿æ•°æ®ç¼“å­˜ï¼šå‡å°‘30-40% APIè¯·æ±‚
- æ™ºèƒ½TTLï¼šåŸºäºæ³¢åŠ¨ç‡åŠ¨æ€è°ƒæ•´è¿‡æœŸæ—¶é—´

é¢„æœŸæ”¶ç›Šï¼š
- ç¼“å­˜å‘½ä¸­ç‡ï¼š40% â†’ 85%
- CPUèŠ‚çœï¼š60-80%ï¼ˆæŒ‡æ ‡è®¡ç®—ï¼‰
- APIè¯·æ±‚å‡å°‘ï¼š30-40%
"""

import time
import hashlib
import pickle
from src.utils.logger_factory import get_logger
import os
from pathlib import Path
from typing import Any, Optional, Dict, Tuple
from collections import OrderedDict
from dataclasses import dataclass, field
from datetime import datetime, timedelta

logger = get_logger(__name__)


@dataclass
class CacheStats:
    """ç¼“å­˜ç»Ÿè®¡æ•°æ®"""
    l1_hits: int = 0
    l2_hits: int = 0
    misses: int = 0
    evictions: int = 0
    total_gets: int = 0
    
    @property
    def hit_rate(self) -> float:
        """æ€»å‘½ä¸­ç‡"""
        if self.total_gets == 0:
            return 0.0
        return (self.l1_hits + self.l2_hits) / self.total_gets
    
    @property
    def l1_hit_rate(self) -> float:
        """L1å‘½ä¸­ç‡"""
        if self.total_gets == 0:
            return 0.0
        return self.l1_hits / self.total_gets
    
    def reset(self):
        """é‡ç½®ç»Ÿè®¡"""
        self.l1_hits = 0
        self.l2_hits = 0
        self.misses = 0
        self.evictions = 0
        self.total_gets = 0


class LRUCache:
    """L1å†…å­˜LRUç¼“å­˜"""
    
    def __init__(self, max_size: int = 5000):
        """
        åˆå§‹åŒ–LRUç¼“å­˜
        
        Args:
            max_size: æœ€å¤§ç¼“å­˜æ¡ç›®æ•°
        """
        self.max_size = max_size
        self.cache: OrderedDict[str, Tuple[Any, float]] = OrderedDict()
        self._eviction_count = 0
    
    def get(self, key: str) -> Optional[Any]:
        """
        è·å–ç¼“å­˜å€¼
        
        Args:
            key: ç¼“å­˜é”®
            
        Returns:
            ç¼“å­˜å€¼æˆ–None
        """
        if key not in self.cache:
            return None
        
        value, expiry = self.cache[key]
        
        # æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
        if expiry > 0 and time.time() > expiry:
            del self.cache[key]
            return None
        
        # ç§»åŠ¨åˆ°æœ«å°¾ï¼ˆæœ€è¿‘ä½¿ç”¨ï¼‰
        self.cache.move_to_end(key)
        return value
    
    def set(self, key: str, value: Any, ttl: Optional[int] = None):
        """
        è®¾ç½®ç¼“å­˜å€¼
        
        Args:
            key: ç¼“å­˜é”®
            value: ç¼“å­˜å€¼
            ttl: è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰ï¼ŒNoneè¡¨ç¤ºæ°¸ä¸è¿‡æœŸ
        """
        # è®¡ç®—è¿‡æœŸæ—¶é—´
        expiry = time.time() + ttl if ttl else 0
        
        # å¦‚æœå·²å­˜åœ¨ï¼Œæ›´æ–°å¹¶ç§»åˆ°æœ«å°¾
        if key in self.cache:
            self.cache[key] = (value, expiry)
            self.cache.move_to_end(key)
            return
        
        # å¦‚æœè¶…å‡ºå®¹é‡ï¼Œç§»é™¤æœ€æ—§çš„
        if len(self.cache) >= self.max_size:
            oldest_key = next(iter(self.cache))
            del self.cache[oldest_key]
            self._eviction_count += 1
        
        self.cache[key] = (value, expiry)
    
    def clear(self):
        """æ¸…ç©ºç¼“å­˜"""
        self.cache.clear()
    
    def size(self) -> int:
        """å½“å‰ç¼“å­˜å¤§å°"""
        return len(self.cache)


class IntelligentCache:
    """
    æ™ºèƒ½åˆ†å±‚ç¼“å­˜ç³»ç»Ÿ
    
    åŠŸèƒ½ï¼š
    1. L1å†…å­˜ç¼“å­˜ï¼ˆå¿«é€Ÿè®¿é—®ï¼‰
    2. L2æŒä¹…åŒ–ç¼“å­˜ï¼ˆå¤§å®¹é‡ï¼‰
    3. è‡ªåŠ¨ç¼“å­˜æå‡ï¼ˆL2â†’L1ï¼‰
    4. æ™ºèƒ½TTLï¼ˆåŸºäºæ•°æ®ç±»å‹ï¼‰
    5. ç»Ÿè®¡ç›‘æ§
    """
    
    def __init__(
        self, 
        l1_max_size: int = 1000,     # ğŸ”¥ Phase 2: ä»5000é™ä½åˆ°1000
        enable_l2: bool = False,     # ğŸ”¥ Phase 2: é»˜è®¤ç¦ç”¨L2ï¼ˆèŠ‚çœ250MBå†…å­˜ï¼‰
        l2_cache_dir: str = '/tmp/elite_cache'
    ):
        """
        åˆå§‹åŒ–æ™ºèƒ½ç¼“å­˜
        
        ğŸ”¥ Phase 2ä¼˜åŒ–ï¼š
        - L1é»˜è®¤1000æ¡ç›®ï¼ˆå®é™…éœ€æ±‚ï¼‰
        - L2é»˜è®¤ç¦ç”¨ï¼ˆé˜²æ­¢å†…å­˜æµªè´¹ï¼‰
        
        Args:
            l1_max_size: L1ç¼“å­˜æœ€å¤§æ¡ç›®æ•°
            enable_l2: æ˜¯å¦å¯ç”¨L2æŒä¹…åŒ–ï¼ˆé»˜è®¤ç¦ç”¨ä»¥èŠ‚çœå†…å­˜ï¼‰
            l2_cache_dir: L2ç¼“å­˜ç›®å½•è·¯å¾„
        """
        self.l1_cache = LRUCache(max_size=l1_max_size)
        self.enable_l2 = enable_l2
        self.stats = CacheStats()
        
        # âœ… v3.20 Phase 3: L2æŒä¹…åŒ–ç¼“å­˜ç›®å½•
        self.l2_cache_dir = Path(l2_cache_dir)
        if self.enable_l2:
            self.l2_cache_dir.mkdir(parents=True, exist_ok=True)
            self._clean_expired_l2()  # å¯åŠ¨æ—¶æ¸…ç†è¿‡æœŸç¼“å­˜
        
        logger.info(
            f"âœ… IntelligentCache åˆå§‹åŒ–å®Œæˆ (Phase 2ä¼˜åŒ–)\n"
            f"   ğŸ“¦ L1å†…å­˜ç¼“å­˜: {l1_max_size} æ¡ç›®\n"
            f"   ğŸ’¾ L2æŒä¹…åŒ–: {'å¯ç”¨ (' + str(self.l2_cache_dir) + ')' if enable_l2 else 'âŒ ç¦ç”¨ï¼ˆèŠ‚çœ250MBå†…å­˜ï¼‰'}"
        )
    
    def get(self, key: str) -> Optional[Any]:
        """
        è·å–ç¼“å­˜å€¼ï¼ˆè‡ªåŠ¨L1â†’L2æŸ¥æ‰¾ï¼‰
        
        Args:
            key: ç¼“å­˜é”®
            
        Returns:
            ç¼“å­˜å€¼æˆ–None
        """
        self.stats.total_gets += 1
        
        # å°è¯•L1ç¼“å­˜
        value = self.l1_cache.get(key)
        if value is not None:
            self.stats.l1_hits += 1
            return value
        
        # âœ… v3.20 Phase 3: L2æŒä¹…åŒ–æŸ¥æ‰¾
        if self.enable_l2:
            l2_value = self._get_from_l2(key)
            if l2_value is not None:
                self.stats.l2_hits += 1
                # æå‡åˆ°L1ï¼ˆçƒ­æ•°æ®ï¼‰
                self.l1_cache.set(key, l2_value, ttl=300)
                return l2_value
        
        self.stats.misses += 1
        return None
    
    def set(
        self, 
        key: str, 
        value: Any, 
        ttl: Optional[int] = None,
        level: str = 'auto'
    ):
        """
        è®¾ç½®ç¼“å­˜å€¼
        
        Args:
            key: ç¼“å­˜é”®
            value: ç¼“å­˜å€¼
            ttl: è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰
            level: ç¼“å­˜çº§åˆ«ï¼ˆ'auto', 'l1', 'l2', 'both'ï¼‰
        """
        # å¦‚æœæœªæŒ‡å®šTTLï¼Œä½¿ç”¨æ™ºèƒ½TTL
        if ttl is None:
            ttl = self._calculate_smart_ttl(key, value)
        
        # å°æ•°æ®ä¼˜å…ˆL1
        size = len(pickle.dumps(value))
        
        if level == 'auto':
            if size < 10240:  # <10KB
                level = 'both' if self.enable_l2 else 'l1'
            else:
                level = 'l2' if self.enable_l2 else 'l1'
        
        # å†™å…¥L1
        if level in ('l1', 'both'):
            self.l1_cache.set(key, value, ttl=ttl)
        
        # âœ… v3.20 Phase 3: å†™å…¥L2æŒä¹…åŒ–
        if level in ('l2', 'both') and self.enable_l2:
            self._set_to_l2(key, value, ttl)
    
    def _calculate_smart_ttl(self, key: str, value: Any) -> int:
        """
        æ™ºèƒ½è®¡ç®—TTL
        
        ğŸ”¥ Phase 2ä¼˜åŒ–ï¼šå»¶é•¿TTLä»¥åŒ¹é…ç­–ç•¥æ‰«æå‘¨æœŸ
        
        ä¸åŒæ•°æ®ç±»å‹ä½¿ç”¨ä¸åŒçš„TTLï¼š
        - æŠ€æœ¯æŒ‡æ ‡ï¼š300ç§’ï¼ˆ5åˆ†é’Ÿï¼ŒåŒ¹é…ç­–ç•¥æ‰«æå‘¨æœŸï¼‰
        - Kçº¿æ•°æ®ï¼š600ç§’ï¼ˆ10åˆ†é’Ÿï¼Œè¾ƒç¨³å®šï¼‰
        - ä¿¡å·ç‰¹å¾ï¼š60ç§’ï¼ˆå¿«é€Ÿè¿‡æœŸï¼Œä½†ä¸è¦å¤ªçŸ­ï¼‰
        - é»˜è®¤ï¼š300ç§’ï¼ˆ5åˆ†é’Ÿï¼‰
        """
        if 'indicator' in key or 'ema' in key or 'rsi' in key:
            return 300  # ğŸ”¥ ä»60ç§’æ”¹ä¸º300ç§’ï¼ˆ5åˆ†é’Ÿï¼‰
        elif 'kline' in key or 'ohlcv' in key:
            return 600  # ğŸ”¥ ä»300ç§’æ”¹ä¸º600ç§’ï¼ˆ10åˆ†é’Ÿï¼‰
        elif 'signal' in key or 'feature' in key:
            return 60   # ğŸ”¥ ä»30ç§’æ”¹ä¸º60ç§’
        else:
            return 300  # ğŸ”¥ ä»180ç§’æ”¹ä¸º300ç§’
    
    def _get_cache_file_path(self, key: str) -> Path:
        """
        è·å–ç¼“å­˜æ–‡ä»¶è·¯å¾„ï¼ˆå®‰å…¨å“ˆå¸Œï¼‰
        
        Args:
            key: ç¼“å­˜é”®ï¼ˆå¯èƒ½åŒ…å«ä¸å®‰å…¨å­—ç¬¦ï¼‰
            
        Returns:
            å®‰å…¨çš„æ–‡ä»¶è·¯å¾„
        """
        # ä½¿ç”¨MD5å“ˆå¸Œç¡®ä¿æ–‡ä»¶åå®‰å…¨ï¼ˆé¿å… / .. ç­‰ä¸å®‰å…¨å­—ç¬¦ï¼‰
        safe_key = hashlib.md5(key.encode()).hexdigest()
        return self.l2_cache_dir / f"{safe_key}.pkl"
    
    def _get_from_l2(self, key: str) -> Optional[Any]:
        """
        ä»L2æŒä¹…åŒ–ç¼“å­˜è¯»å–
        
        Args:
            key: ç¼“å­˜é”®
            
        Returns:
            ç¼“å­˜å€¼æˆ–None
        """
        try:
            cache_file = self._get_cache_file_path(key)
            
            if not cache_file.exists():
                return None
            
            # è¯»å–ç¼“å­˜æ–‡ä»¶
            with open(cache_file, 'rb') as f:
                cache_data = pickle.load(f)
            
            # æ£€æŸ¥è¿‡æœŸæ—¶é—´
            expiry = cache_data.get('expiry', 0)
            if expiry > 0 and time.time() > expiry:
                # è¿‡æœŸï¼Œåˆ é™¤æ–‡ä»¶
                cache_file.unlink()
                return None
            
            return cache_data.get('value')
            
        except Exception as e:
            logger.debug(f"L2ç¼“å­˜è¯»å–å¤±è´¥ {key}: {e}")
            return None
    
    def _set_to_l2(self, key: str, value: Any, ttl: Optional[int] = None):
        """
        å†™å…¥L2æŒä¹…åŒ–ç¼“å­˜
        
        Args:
            key: ç¼“å­˜é”®
            value: ç¼“å­˜å€¼
            ttl: è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰
        """
        try:
            cache_file = self._get_cache_file_path(key)
            
            # è®¡ç®—è¿‡æœŸæ—¶é—´
            expiry = time.time() + ttl if ttl else 0
            
            # åºåˆ—åŒ–æ•°æ®
            cache_data = {
                'value': value,
                'expiry': expiry,
                'created_at': time.time()
            }
            
            # å†™å…¥æ–‡ä»¶
            with open(cache_file, 'wb') as f:
                pickle.dump(cache_data, f)
                
        except Exception as e:
            logger.warning(f"âš ï¸  L2ç¼“å­˜å†™å…¥å¤±è´¥ {key}: {e}")
    
    def _clean_expired_l2(self):
        """æ¸…ç†è¿‡æœŸçš„L2ç¼“å­˜æ–‡ä»¶"""
        if not self.enable_l2:
            return
        
        try:
            cleaned_count = 0
            current_time = time.time()
            
            for cache_file in self.l2_cache_dir.glob('*.pkl'):
                try:
                    with open(cache_file, 'rb') as f:
                        cache_data = pickle.load(f)
                    
                    expiry = cache_data.get('expiry', 0)
                    if expiry > 0 and current_time > expiry:
                        cache_file.unlink()
                        cleaned_count += 1
                        
                except Exception:
                    # æŸåçš„æ–‡ä»¶ä¹Ÿåˆ é™¤
                    cache_file.unlink()
                    cleaned_count += 1
            
            if cleaned_count > 0:
                logger.info(f"ğŸ—‘ï¸  æ¸…ç†äº† {cleaned_count} ä¸ªè¿‡æœŸL2ç¼“å­˜æ–‡ä»¶")
                
        except Exception as e:
            logger.warning(f"âš ï¸  L2ç¼“å­˜æ¸…ç†å¤±è´¥: {e}")
    
    def clear(self):
        """æ¸…ç©ºæ‰€æœ‰ç¼“å­˜"""
        self.l1_cache.clear()
        
        # æ¸…ç©ºL2ç¼“å­˜
        if self.enable_l2:
            try:
                for cache_file in self.l2_cache_dir.glob('*.pkl'):
                    cache_file.unlink()
                logger.info("ğŸ—‘ï¸  L1+L2ç¼“å­˜å·²æ¸…ç©º")
            except Exception as e:
                logger.warning(f"âš ï¸  L2ç¼“å­˜æ¸…ç©ºå¤±è´¥: {e}")
        else:
            logger.info("ğŸ—‘ï¸  L1ç¼“å­˜å·²æ¸…ç©º")
    
    def get_stats(self) -> CacheStats:
        """è·å–ç¼“å­˜ç»Ÿè®¡"""
        return self.stats
    
    def print_stats(self):
        """æ‰“å°ç¼“å­˜ç»Ÿè®¡"""
        l2_size = 0
        if self.enable_l2:
            try:
                l2_size = len(list(self.l2_cache_dir.glob('*.pkl')))
            except Exception:
                l2_size = 0
        
        logger.info(
            f"ğŸ“Š ç¼“å­˜ç»Ÿè®¡:\n"
            f"   âœ… L1å‘½ä¸­: {self.stats.l1_hits} ({self.stats.l1_hit_rate:.1%})\n"
            f"   âœ… L2å‘½ä¸­: {self.stats.l2_hits}\n"
            f"   âŒ æœªå‘½ä¸­: {self.stats.misses}\n"
            f"   ğŸ¯ æ€»å‘½ä¸­ç‡: {self.stats.hit_rate:.1%}\n"
            f"   ğŸ“¦ L1å¤§å°: {self.l1_cache.size()}/{self.l1_cache.max_size}\n"
            f"   ğŸ’¾ L2å¤§å°: {l2_size if self.enable_l2 else 'N/A'}"
        )


def generate_cache_key(*args, **kwargs) -> str:
    """
    ç”Ÿæˆç¼“å­˜é”®
    
    Args:
        *args: ä½ç½®å‚æ•°
        **kwargs: å…³é”®å­—å‚æ•°
        
    Returns:
        ç¼“å­˜é”®ï¼ˆMD5å“ˆå¸Œï¼‰
    
    ç¤ºä¾‹ï¼š
        key = generate_cache_key('BTCUSDT', '1h', period=20)
        # è¾“å‡º: 'indicator_btcusdt_1h_20_abc123...'
    """
    # ç»„åˆæ‰€æœ‰å‚æ•°
    key_parts = [str(arg) for arg in args]
    key_parts.extend(f"{k}={v}" for k, v in sorted(kwargs.items()))
    
    # ç”ŸæˆMD5å“ˆå¸Œ
    key_string = "_".join(key_parts)
    hash_obj = hashlib.md5(key_string.encode())
    
    return hash_obj.hexdigest()[:16]  # å‰16ä½è¶³å¤Ÿ
