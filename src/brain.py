"""
üß† Brain Process - Ring Buffer Reader + SMC/ML/Trade Execution
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

Runs in separate process with own GIL.
Polls ring buffer for new candles, runs SMC analysis, executes trades.
Has dedicated CPU core. Never GIL-blocked by feed process.
"""

import logging
import asyncio
import gc
import os
from time import time, sleep
from typing import Optional, List

try:
    import uvloop
    asyncio.set_event_loop_policy(uvloop.EventLoopPolicy())
except ImportError:
    pass

from src.ring_buffer import get_ring_buffer
from src.bus import bus, Topic
from src import trade
from src.indicators import Indicators
from src.market_universe import BinanceUniverse
from src.timeframe_analyzer import get_timeframe_analyzer
import numpy as np
import uuid

# ML & Experience Buffer
from src.ml_model import get_ml_model
from src.experience_buffer import get_experience_buffer

# ‚úÖ NEW: Percentage Return + Position Sizing
from src.percentage_return_model import PercentageReturnModel
from src.position_sizing import PositionSizingFactory
from src.capital_tracker import init_capital_tracker, get_capital_tracker, get_total_equity

# ‚úÖ Railway Êó•Ë™åÈÅéÊøæ
from src.utils.railway_logger import setup_railway_logger

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - [Brain] - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)
setup_railway_logger(logger)

# Global symbols list (synchronized with feed process)
_symbols: List[str] = []


def optimize_gc():
    """Optimize GC for brain process"""
    gc.set_threshold(700, 10, 10)
    gc.collect()
    try:
        gc.freeze()
    except AttributeError:
        pass


def detect_pattern(candle: tuple) -> dict:
    """Legacy function - replaced by timeframe analyzer"""
    return {'strength': 0.5}


async def process_candle(candle: tuple, symbol: str = "BTC/USDT") -> None:
    """
    Process multi-timeframe signal (1D ‚Üí 1H ‚Üí 15m ‚Üí 5m/1m)
    Only generates signals when all timeframes align
    """
    # Get real multi-timeframe data from buffer
    from src.timeframe_buffer import get_timeframe_buffer
    
    buffer = get_timeframe_buffer()
    
    # Add this candle to the buffer (it will be aggregated to all timeframes)
    buffer.add_tick(symbol, candle)
    
    # Check if we have enough data for analysis
    # üîç Lowered from min_candles_per_tf=3 to 1 to enable signal generation earlier
    has_data = buffer.has_sufficient_data(symbol, min_candles_per_tf=1)
    if not has_data:
        # üîç Diagnostic: Log every 50 candles to see data accumulation
        static_candle_count = getattr(process_candle, 'call_count', 0) + 1
        process_candle.call_count = static_candle_count
        if static_candle_count % 50 == 0:
            logger.critical(f"üîç process_candle({symbol}): Insufficient data [{static_candle_count} calls], skipping")
        return
    
    # Get complete multi-timeframe candles
    candles_by_tf = buffer.get_candles_by_tf(symbol)
    
    # ‚úÖ P0 ‰øÆÂæ©: Ë™øÁî®ÁúüÂØ¶ÊåáÊ®ôË®àÁÆóËÄå‰∏çÊòØÁ°¨Á∑®Á¢º
    # Extract historical data for technical analysis (minimum 20 candles for RSI-14)
    min_candles = 20
    if not candles_by_tf or '1m' not in candles_by_tf or len(candles_by_tf['1m']) < min_candles:
        # Not enough data yet
        return
    
    # Get closes, highs, lows from available candles (use all available, not just 50)
    recent_candles = candles_by_tf['1m'][-50:] if len(candles_by_tf['1m']) > 50 else candles_by_tf['1m']
    closes = np.array([c[4] for c in recent_candles], dtype=np.float64)  # Close price
    highs = np.array([c[2] for c in recent_candles], dtype=np.float64)    # High price
    lows = np.array([c[3] for c in recent_candles], dtype=np.float64)     # Low price
    
    # ‚úÖ Ë®àÁÆóÁúüÂØ¶ÊåáÊ®ôÔºà‰∏çÊòØÁ°¨Á∑®Á¢ºÔºÅÔºâ
    rsi_value = Indicators.rsi(closes, period=14)
    logger.critical(f"‚úÖ ÂãïÊÖãË®àÁÆó RSI: {rsi_value:.2f} (0-100, ÈùûÁ°¨Á∑®Á¢º 50)")
    
    # ‚úÖ ‰øÆÂæ©ÁöÑ MACDÔºà‰ΩøÁî®ÁúüÊ≠£ÁöÑ EMAÔºâ
    macd_line, signal_line, histogram = Indicators.macd(closes, fast=12, slow=26, signal_period=9)
    logger.critical(f"‚úÖ ÂãïÊÖãË®àÁÆó MACD: macd_line={macd_line:.4f}, signal={signal_line:.4f} (ÈùûÁ°¨Á∑®Á¢º 0)")
    
    atr_value = Indicators.atr(highs, lows, closes, period=14)
    logger.critical(f"‚úÖ ÂãïÊÖãË®àÁÆó ATR: {atr_value:.4f}")
    
    bb_width_value = Indicators.bollinger_bands(closes, period=20, std_dev=2.0)
    logger.critical(f"‚úÖ ÂãïÊÖãË®àÁÆó BB Width: {bb_width_value:.4f}")
    
    # ‚úÖ P1 Êñ∞Â¢û: FVG Ê™¢Ê∏¨
    fvg_value = Indicators.detect_fvg(closes, highs, lows)
    
    # ‚úÖ P1 Êñ∞Â¢û: ÊµÅÂãïÊÄßË®àÁÆóÔºàÂü∫ÊñºË®ÇÂñÆÁ∞øÊ∑±Â∫¶ÁöÑÁ∞°ÂåñÁâàÊú¨Ôºâ
    # Âú®ÂØ¶ÈöõÁ≥ªÁµ±‰∏≠ÊáâË©≤‰ΩøÁî® Binance Ë®ÇÂñÆÁ∞øÊï∏Êìö
    # ÈÄôË£°‰ΩøÁî®Êàê‰∫§ÈáèÂíåÊ≥¢ÂãïÊÄßÁöÑÁµÑÂêà‰ΩúÁÇ∫Ëøë‰ººÂÄº
    volume = recent_candles[-1][5] if len(recent_candles[-1]) > 5 else 1000  # Volume
    volume_ma = np.mean([c[5] if len(c) > 5 else 1000 for c in recent_candles[-20:]])
    bid_price = candle[4] * 0.9995  # Approximate bid
    ask_price = candle[4] * 1.0005  # Approximate ask
    liquidity_value = Indicators.calculate_liquidity(bid_price, ask_price, volume, volume_ma)
    
    # ‚úÖ Âü∫ÊñºÊäÄË°ìÈù¢Ë®àÁÆó confidenceÔºà‰∏çÊòØÁ°¨Á∑®Á¢º 0.65ÔºÅÔºâ
    # ÊäÄË°ìÈù¢‰ø°ÂøÉÂ∫¶ÂÖ¨ÂºèÔºö
    # - RSI Âú® 30-70 ÁØÑÂúç: È´ò‰ø°ÂøÉÂ∫¶
    # - MACD Ê≠£Âêë: Â¢ûÂä†‰ø°ÂøÉÂ∫¶
    # - ATR Ê≠£Â∏∏ÁØÑÂúç: Ê≠£Â∏∏‰ø°ÂøÉÂ∫¶
    rsi_score = (50 - abs(rsi_value - 50)) / 50  # 50=1.0, 30/70=0.6, 20/80=0.4
    macd_score = 0.5 + (0.5 * min(max(macd_line / 100, -1), 1))  # Normalize MACD
    atr_score = 0.5 + (0.5 * min(atr_value / 0.05, 1.0))  # 0.05 = normal ATR
    
    # Ë®àÁÆóÂàùÂßã confidenceÔºàÂü∫ÊñºÊäÄË°ìÊåáÊ®ôÔºâ
    technical_confidence = (rsi_score * 0.4) + (macd_score * 0.35) + (atr_score * 0.25)
    
    signal_data = {
        'symbol': symbol,
        'direction': 'LONG' if closes[-1] > closes[-2] else 'SHORT',
        'percentage_return': 2.5,  # Expected 2.5% return
        'confidence': technical_confidence,  # ‚úÖ Âü∫ÊñºÊäÄË°ìÊåáÊ®ôË®àÁÆóÔºå‰∏çÊòØÁ°¨Á∑®Á¢ºÔºÅ
        'strength': 0.7,
        'entry_price': candle[4],
        'timestamp': candle[0],
        # ‚úÖ ÁúüÂØ¶ÂãïÊÖãÁâπÂæµË®àÁÆóÔºà‰∏çÊòØÁ°¨Á∑®Á¢ºÔºÅÔºâ
        'fvg': fvg_value,            # ‚úÖ ÂãïÊÖã FVG Ê™¢Ê∏¨
        'liquidity': liquidity_value, # ‚úÖ ÂãïÊÖãÊµÅÂãïÊÄßË®àÁÆó
        'rsi': rsi_value,            # ‚úÖ ÂãïÊÖã RSI
        'atr': atr_value,            # ‚úÖ ÂãïÊÖã ATR
        'macd': macd_line,           # ‚úÖ ÂãïÊÖã MACDÔºàÊ≠£Á¢∫ÁöÑ EMAÔºâ
        'bb_width': bb_width_value,  # ‚úÖ ÂãïÊÖã BB ÂØ¨Â∫¶
        'timeframe_analysis': {}
    }
    
    if not signal_data:
        logger.debug(f"üîç {symbol}: Signal generation FAILED")
        return
    
    # ‚úÖ Multi-timeframe validation passed
    # Extract current market price from latest candle (close price)
    current_price = candle[4] if len(candle) > 4 else 1.0
    
    # Create complete signal object (Áµ±‰∏ÄÊ†ºÂºè - ‰ΩøÁî®ÊØ´ÁßíÊôÇÈñìÊà≥)
    from src.data_formats import CANDLE_IDX_TIMESTAMP, CANDLE_IDX_CLOSE
    
    signal = {
        'signal_id': str(uuid.uuid4()),
        'symbol': symbol,
        'timestamp': int(candle[CANDLE_IDX_TIMESTAMP]),  # ‚úì ÊØ´ÁßíÊôÇÈñìÊà≥ (Áµ±‰∏ÄÊ†ºÂºè)
        'confidence': signal_data['confidence'],
        'direction': signal_data['direction'],
        'strength': signal_data['strength'],
        'features': {
            'confidence': signal_data['confidence'],
            'direction': signal_data['direction'],
            'strength': signal_data['strength'],
            'fvg': signal_data.get('fvg', 0.5),
            'liquidity': signal_data.get('liquidity', 0.5),
            'rsi': signal_data.get('rsi', 50),
            'atr': signal_data.get('atr', 0),
            'macd': signal_data.get('macd', 0),
            'bb_width': signal_data.get('bb_width', 0),
            'position_size': 100.0,
            'position_size_pct': 0.01,
            'timeframe_analysis': signal_data.get('timeframe_analysis', {})
        },
        'entry_price': current_price,  # üéØ Real market price for virtual trading
    }
    
    # ü§ñ ML model enhancement (optional)
    ml_model = get_ml_model()
    if ml_model.is_trained:
        signal = await ml_model.adjust_confidence(signal)
    
    # ‚úÖ NEW: Percentage Return Prediction + Position Sizing Integration
    try:
        # 1Ô∏è‚É£ Predict percentage return using ML confidence
        ml_return_model = PercentageReturnModel()
        prediction = ml_return_model.predict_signal(
            signal_data=signal,
            historical_stats={
                'win_rate': 0.65,  # Default historical win rate
                'atr': signal_data.get('atr', 0.02),
                'market_volatility': 1.0
            }
        )
        
        # Add prediction to signal
        signal['predicted_return_pct'] = prediction['predicted_return_pct']
        signal['prediction_details'] = prediction
        
        # 2Ô∏è‚É£ Calculate position sizing (Version B: Kelly + ATR)
        total_capital = get_total_equity()
        
        sizing = PositionSizingFactory.calculate(
            version='B',  # Dynamic Kelly + ATR sizing
            total_capital=total_capital,
            predicted_return_pct=prediction['predicted_return_pct'],
            confidence=signal['confidence'],
            win_rate=0.65,  # Will be updated as virtual trades accumulate
            atr_pct=signal_data.get('atr', 0.02),
            current_price=current_price,
            symbol=symbol,
            use_kelly=True
        )
        
        # Add position sizing to signal
        signal['position_sizing'] = sizing
        signal['order_amount'] = sizing['order_amount']
        signal['tp_pct'] = sizing['tp_pct']
        signal['sl_pct'] = sizing['sl_pct']
        
        logger.info(
            f"üí° {symbol} Position Sizing: "
            f"Order ${sizing['order_amount']:.2f} | "
            f"Return +{prediction['predicted_return_pct']:.2%} | "
            f"Kelly {sizing['kelly_pct']:.2%} | "
            f"SL {sizing['sl_pct']:.2%}"
        )
    
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Position sizing error for {symbol}: {e}")
        signal['position_sizing'] = {'recommended': False, 'error': str(e)}
    
    # üíæ Record in experience buffer
    experience_buffer = get_experience_buffer()
    await experience_buffer.record_signal(signal['signal_id'], signal)
    
    # üîç Build timeframe_analysis structure with safe access
    tf_analysis = signal.get('features', {}).get('timeframe_analysis', {})
    tf_1d_conf = tf_analysis.get('1d', {}).get('confidence', 0)
    tf_1h_conf = tf_analysis.get('1h', {}).get('confidence', 0)
    tf_15m_conf = tf_analysis.get('15m', {}).get('confidence', 0)
    
    # Publish to EventBus
    await bus.publish(Topic.SIGNAL_GENERATED, signal)


async def run_brain() -> None:
    """
    Run brain process: Ring buffer reader + analysis + trading
    
    Flow:
    1. Discover all symbols to monitor
    2. Poll ring buffer for new candles (non-blocking)
    3. Detect SMC patterns
    4. Generate signals
    5. Publish to EventBus
    6. Trade module executes orders
    """
    global _symbols
    
    optimize_gc()
    
    logger.info("üöÄ Brain process started")
    
    # Discover all symbols
    logger.info("üîç Discovering symbols...")
    universe = BinanceUniverse()
    _symbols = await universe.get_active_pairs()
    
    if not _symbols:
        _symbols = [
            "BTC/USDT", "ETH/USDT", "BNB/USDT", "XRP/USDT", "SOL/USDT",
            "ADA/USDT", "DOGE/USDT", "AVAX/USDT", "LINK/USDT", "MATIC/USDT",
            "FTT/USDT", "TRX/USDT", "ARB/USDT", "OP/USDT", "LTC/USDT",
            "BCH/USDT", "ETC/USDT", "XLM/USDT", "ATOM/USDT", "UNI/USDT"
        ]
    
    logger.info(f"‚úÖ Will analyze {len(_symbols)} symbols")
    logger.info(f"üìä Symbols: {_symbols[:10]}...")
    
    # Initialize modules
    await trade.init()
    logger.info("‚úÖ Trade module initialized")
    
    # Initialize ML model
    ml_model = get_ml_model()
    logger.info("‚úÖ ML model initialized")
    
    # Initialize experience buffer
    experience_buffer = get_experience_buffer()
    logger.info("‚úÖ Experience buffer initialized")
    
    # ‚úÖ Initialize Capital Tracker (for virtual learning account: $10,000)
    tracker = init_capital_tracker(initial_balance=10000)
    logger.info("‚úÖ Capital Tracker initialized with $10,000 virtual account")
    
    # Get ring buffer (attach to existing)
    ring_buffer = get_ring_buffer(create=False)
    if ring_buffer is None:
        logger.error("‚ùå Failed to attach to ring buffer")
        return
    logger.info("‚úÖ Attached to ring buffer")
    logger.critical(f"üîç Ring Buffer Diagnostic: pending={ring_buffer.pending_count()}, ready to read")
    
    try:
        candle_count = 0
        latencies = []
        symbol_index = 0
        last_pending_log = 0  # Track last pending count for diagnostic logging
        
        while True:
            # Poll for pending candles (non-blocking)
            if ring_buffer is None:
                await asyncio.sleep(0.001)
                continue
            
            # ‚úÖ FIXED: Don't check pending_count - always try to read!
            # Ring buffer will return empty generator if no data
            candle_read_count = 0
            for candle in ring_buffer.read_new():
                if candle is None:
                    break
                
                try:
                    # Measure latency
                    write_time = candle[0] / 1000.0  # Convert ms to seconds
                    read_time = time()
                    latency_us = (read_time - write_time) * 1_000_000
                    
                    latencies.append(latency_us)
                    
                    # Track which symbol this candle belongs to (round-robin)
                    current_symbol = _symbols[symbol_index % len(_symbols)]
                    symbol_index += 1
                    
                    # Process candle (no need to pass candles_by_tf - it's fetched from buffer)
                    await process_candle(candle, current_symbol)
                    
                    candle_count += 1
                    candle_read_count += 1
                    
                    if candle_count % 1000 == 0:
                        avg_latency = np.mean(latencies[-1000:])
                        remaining_pending = ring_buffer.pending_count()
                        logger.critical(f"üìä Brain: {candle_count} candles | {len(_symbols)} symbols | Latency: {avg_latency:.1f}¬µs | Remaining Pending: {remaining_pending}")
                except Exception as e:
                    logger.error(f"Error processing candle: {e}", exc_info=True)
                    continue
            
            # If no candles read, yield to other tasks
            if candle_read_count == 0:
                await asyncio.sleep(0.001)
    
    except KeyboardInterrupt:
        logger.info("‚èπÔ∏è Brain shutdown")
    except Exception as e:
        logger.error(f"‚ùå Brain error: {e}", exc_info=True)


async def main():
    """Main brain process entry"""
    try:
        await run_brain()
    except Exception as e:
        logger.critical(f"Fatal: {e}", exc_info=True)


if __name__ == "__main__":
    """Entry point for supervisord"""
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        logger.info("üß† Brain process stopped")
    except Exception as e:
        logger.critical(f"Fatal error in Brain: {e}", exc_info=True)
