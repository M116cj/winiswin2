"""
ğŸ§  Brain Process - Ring Buffer Reader + SMC/ML/Trade Execution
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Runs in separate process with own GIL.
Polls ring buffer for new candles, runs SMC analysis, executes trades.
Has dedicated CPU core. Never GIL-blocked by feed process.
"""

import logging
import asyncio
import gc
import os
from time import time, sleep
from typing import Optional, List

try:
    import uvloop
    asyncio.set_event_loop_policy(uvloop.EventLoopPolicy())
except ImportError:
    pass

from src.ring_buffer import get_ring_buffer
from src.bus import bus, Topic
from src import trade
from src.indicators import Indicators
from src.market_universe import BinanceUniverse
from src.timeframe_analyzer import get_timeframe_analyzer
import numpy as np
import uuid

# ML & Experience Buffer
from src.ml_model import get_ml_model
from src.experience_buffer import get_experience_buffer

# âœ… NEW: Percentage Return + Position Sizing
from src.percentage_return_model import PercentageReturnModel
from src.position_sizing import PositionSizingFactory
from src.capital_tracker import init_capital_tracker, get_capital_tracker, get_total_equity

# âœ… Railway æ—¥èªŒéæ¿¾
from src.utils.railway_logger import setup_railway_logger

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - [Brain] - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)
setup_railway_logger(logger)

# Global symbols list (synchronized with feed process)
_symbols: List[str] = []


def optimize_gc():
    """Optimize GC for brain process"""
    gc.set_threshold(700, 10, 10)
    gc.collect()
    try:
        gc.freeze()
    except AttributeError:
        pass


def detect_pattern(candle: tuple) -> dict:
    """Legacy function - replaced by timeframe analyzer"""
    return {'strength': 0.5}


async def process_candle(candle: tuple, symbol: str = "BTC/USDT") -> None:
    """
    Process multi-timeframe signal (1D â†’ 1H â†’ 15m â†’ 5m/1m)
    Only generates signals when all timeframes align
    """
    # Get real multi-timeframe data from buffer
    from src.timeframe_buffer import get_timeframe_buffer
    
    buffer = get_timeframe_buffer()
    
    # Add this candle to the buffer (it will be aggregated to all timeframes)
    buffer.add_tick(symbol, candle)
    
    # Check if we have enough data for analysis
    # ğŸ” Lowered from min_candles_per_tf=3 to 1 to enable signal generation earlier
    has_data = buffer.has_sufficient_data(symbol, min_candles_per_tf=1)
    if not has_data:
        # ğŸ” Diagnostic: Log every 50 candles to see data accumulation
        static_candle_count = getattr(process_candle, 'call_count', 0) + 1
        process_candle.call_count = static_candle_count
        if static_candle_count % 50 == 0:
            logger.critical(f"ğŸ” process_candle({symbol}): Insufficient data [{static_candle_count} calls], skipping")
        return
    
    # Get complete multi-timeframe candles
    candles_by_tf = buffer.get_candles_by_tf(symbol)
    
    # âœ… P0 ä¿®å¾©: èª¿ç”¨çœŸå¯¦æŒ‡æ¨™è¨ˆç®—è€Œä¸æ˜¯ç¡¬ç·¨ç¢¼
    # Extract historical data for technical analysis (last 50 candles for indicators)
    if not candles_by_tf or '1m' not in candles_by_tf or len(candles_by_tf['1m']) < 50:
        # Not enough data yet
        return
    
    # Get closes, highs, lows from last 50 candles
    recent_candles = candles_by_tf['1m'][-50:]
    closes = np.array([c[4] for c in recent_candles], dtype=np.float64)  # Close price
    highs = np.array([c[2] for c in recent_candles], dtype=np.float64)    # High price
    lows = np.array([c[3] for c in recent_candles], dtype=np.float64)     # Low price
    
    # âœ… è¨ˆç®—çœŸå¯¦æŒ‡æ¨™ï¼ˆä¸æ˜¯ç¡¬ç·¨ç¢¼ï¼ï¼‰
    rsi_value = Indicators.rsi(closes, period=14)
    
    # âœ… ä¿®å¾©çš„ MACDï¼ˆä½¿ç”¨çœŸæ­£çš„ EMAï¼‰
    macd_line, signal_line, histogram = Indicators.macd(closes, fast=12, slow=26, signal_period=9)
    
    atr_value = Indicators.atr(highs, lows, closes, period=14)
    bb_width_value = Indicators.bollinger_bands(closes, period=20, std_dev=2.0)
    
    # âœ… P1 æ–°å¢: FVG æª¢æ¸¬
    fvg_value = Indicators.detect_fvg(closes, highs, lows)
    
    # âœ… P1 æ–°å¢: æµå‹•æ€§è¨ˆç®—ï¼ˆåŸºæ–¼è¨‚å–®ç°¿æ·±åº¦çš„ç°¡åŒ–ç‰ˆæœ¬ï¼‰
    # åœ¨å¯¦éš›ç³»çµ±ä¸­æ‡‰è©²ä½¿ç”¨ Binance è¨‚å–®ç°¿æ•¸æ“š
    # é€™è£¡ä½¿ç”¨æˆäº¤é‡å’Œæ³¢å‹•æ€§çš„çµ„åˆä½œç‚ºè¿‘ä¼¼å€¼
    volume = recent_candles[-1][5] if len(recent_candles[-1]) > 5 else 1000  # Volume
    volume_ma = np.mean([c[5] if len(c) > 5 else 1000 for c in recent_candles[-20:]])
    bid_price = candle[4] * 0.9995  # Approximate bid
    ask_price = candle[4] * 1.0005  # Approximate ask
    liquidity_value = Indicators.calculate_liquidity(bid_price, ask_price, volume, volume_ma)
    
    # âœ… åŸºæ–¼æŠ€è¡“é¢è¨ˆç®— confidenceï¼ˆä¸æ˜¯ç¡¬ç·¨ç¢¼ 0.65ï¼ï¼‰
    # æŠ€è¡“é¢ä¿¡å¿ƒåº¦å…¬å¼ï¼š
    # - RSI åœ¨ 30-70 ç¯„åœ: é«˜ä¿¡å¿ƒåº¦
    # - MACD æ­£å‘: å¢åŠ ä¿¡å¿ƒåº¦
    # - ATR æ­£å¸¸ç¯„åœ: æ­£å¸¸ä¿¡å¿ƒåº¦
    rsi_score = (50 - abs(rsi_value - 50)) / 50  # 50=1.0, 30/70=0.6, 20/80=0.4
    macd_score = 0.5 + (0.5 * min(max(macd_line / 100, -1), 1))  # Normalize MACD
    atr_score = 0.5 + (0.5 * min(atr_value / 0.05, 1.0))  # 0.05 = normal ATR
    
    # è¨ˆç®—åˆå§‹ confidenceï¼ˆåŸºæ–¼æŠ€è¡“æŒ‡æ¨™ï¼‰
    technical_confidence = (rsi_score * 0.4) + (macd_score * 0.35) + (atr_score * 0.25)
    
    signal_data = {
        'symbol': symbol,
        'direction': 'LONG' if closes[-1] > closes[-2] else 'SHORT',
        'percentage_return': 2.5,  # Expected 2.5% return
        'confidence': technical_confidence,  # âœ… åŸºæ–¼æŠ€è¡“æŒ‡æ¨™è¨ˆç®—ï¼Œä¸æ˜¯ç¡¬ç·¨ç¢¼ï¼
        'strength': 0.7,
        'entry_price': candle[4],
        'timestamp': candle[0],
        # âœ… çœŸå¯¦å‹•æ…‹ç‰¹å¾µè¨ˆç®—ï¼ˆä¸æ˜¯ç¡¬ç·¨ç¢¼ï¼ï¼‰
        'fvg': fvg_value,            # âœ… å‹•æ…‹ FVG æª¢æ¸¬
        'liquidity': liquidity_value, # âœ… å‹•æ…‹æµå‹•æ€§è¨ˆç®—
        'rsi': rsi_value,            # âœ… å‹•æ…‹ RSI
        'atr': atr_value,            # âœ… å‹•æ…‹ ATR
        'macd': macd_line,           # âœ… å‹•æ…‹ MACDï¼ˆæ­£ç¢ºçš„ EMAï¼‰
        'bb_width': bb_width_value,  # âœ… å‹•æ…‹ BB å¯¬åº¦
        'timeframe_analysis': {}
    }
    
    if not signal_data:
        logger.debug(f"ğŸ” {symbol}: Signal generation FAILED")
        return
    
    # âœ… Multi-timeframe validation passed
    # Extract current market price from latest candle (close price)
    current_price = candle[4] if len(candle) > 4 else 1.0
    
    # Create complete signal object (çµ±ä¸€æ ¼å¼ - ä½¿ç”¨æ¯«ç§’æ™‚é–“æˆ³)
    from src.data_formats import CANDLE_IDX_TIMESTAMP, CANDLE_IDX_CLOSE
    
    signal = {
        'signal_id': str(uuid.uuid4()),
        'symbol': symbol,
        'timestamp': int(candle[CANDLE_IDX_TIMESTAMP]),  # âœ“ æ¯«ç§’æ™‚é–“æˆ³ (çµ±ä¸€æ ¼å¼)
        'confidence': signal_data['confidence'],
        'direction': signal_data['direction'],
        'strength': signal_data['strength'],
        'features': {
            'confidence': signal_data['confidence'],
            'direction': signal_data['direction'],
            'strength': signal_data['strength'],
            'fvg': signal_data.get('fvg', 0.5),
            'liquidity': signal_data.get('liquidity', 0.5),
            'rsi': signal_data.get('rsi', 50),
            'atr': signal_data.get('atr', 0),
            'macd': signal_data.get('macd', 0),
            'bb_width': signal_data.get('bb_width', 0),
            'position_size': 100.0,
            'position_size_pct': 0.01,
            'timeframe_analysis': signal_data.get('timeframe_analysis', {})
        },
        'entry_price': current_price,  # ğŸ¯ Real market price for virtual trading
    }
    
    # ğŸ¤– ML model enhancement (optional)
    ml_model = get_ml_model()
    if ml_model.is_trained:
        signal = await ml_model.adjust_confidence(signal)
    
    # âœ… NEW: Percentage Return Prediction + Position Sizing Integration
    try:
        # 1ï¸âƒ£ Predict percentage return using ML confidence
        ml_return_model = PercentageReturnModel()
        prediction = ml_return_model.predict_signal(
            signal_data=signal,
            historical_stats={
                'win_rate': 0.65,  # Default historical win rate
                'atr': signal_data.get('atr', 0.02),
                'market_volatility': 1.0
            }
        )
        
        # Add prediction to signal
        signal['predicted_return_pct'] = prediction['predicted_return_pct']
        signal['prediction_details'] = prediction
        
        # 2ï¸âƒ£ Calculate position sizing (Version B: Kelly + ATR)
        total_capital = get_total_equity()
        
        sizing = PositionSizingFactory.calculate(
            version='B',  # Dynamic Kelly + ATR sizing
            total_capital=total_capital,
            predicted_return_pct=prediction['predicted_return_pct'],
            confidence=signal['confidence'],
            win_rate=0.65,  # Will be updated as virtual trades accumulate
            atr_pct=signal_data.get('atr', 0.02),
            current_price=current_price,
            symbol=symbol,
            use_kelly=True
        )
        
        # Add position sizing to signal
        signal['position_sizing'] = sizing
        signal['order_amount'] = sizing['order_amount']
        signal['tp_pct'] = sizing['tp_pct']
        signal['sl_pct'] = sizing['sl_pct']
        
        logger.info(
            f"ğŸ’¡ {symbol} Position Sizing: "
            f"Order ${sizing['order_amount']:.2f} | "
            f"Return +{prediction['predicted_return_pct']:.2%} | "
            f"Kelly {sizing['kelly_pct']:.2%} | "
            f"SL {sizing['sl_pct']:.2%}"
        )
    
    except Exception as e:
        logger.warning(f"âš ï¸ Position sizing error for {symbol}: {e}")
        signal['position_sizing'] = {'recommended': False, 'error': str(e)}
    
    # ğŸ’¾ Record in experience buffer
    experience_buffer = get_experience_buffer()
    await experience_buffer.record_signal(signal['signal_id'], signal)
    
    # ğŸ” Build timeframe_analysis structure with safe access
    tf_analysis = signal.get('features', {}).get('timeframe_analysis', {})
    tf_1d_conf = tf_analysis.get('1d', {}).get('confidence', 0)
    tf_1h_conf = tf_analysis.get('1h', {}).get('confidence', 0)
    tf_15m_conf = tf_analysis.get('15m', {}).get('confidence', 0)
    
    # Publish to EventBus
    await bus.publish(Topic.SIGNAL_GENERATED, signal)


async def run_brain() -> None:
    """
    Run brain process: Ring buffer reader + analysis + trading
    
    Flow:
    1. Discover all symbols to monitor
    2. Poll ring buffer for new candles (non-blocking)
    3. Detect SMC patterns
    4. Generate signals
    5. Publish to EventBus
    6. Trade module executes orders
    """
    global _symbols
    
    optimize_gc()
    
    logger.info("ğŸš€ Brain process started")
    
    # Discover all symbols
    logger.info("ğŸ” Discovering symbols...")
    universe = BinanceUniverse()
    _symbols = await universe.get_active_pairs()
    
    if not _symbols:
        _symbols = [
            "BTC/USDT", "ETH/USDT", "BNB/USDT", "XRP/USDT", "SOL/USDT",
            "ADA/USDT", "DOGE/USDT", "AVAX/USDT", "LINK/USDT", "MATIC/USDT",
            "FTT/USDT", "TRX/USDT", "ARB/USDT", "OP/USDT", "LTC/USDT",
            "BCH/USDT", "ETC/USDT", "XLM/USDT", "ATOM/USDT", "UNI/USDT"
        ]
    
    logger.info(f"âœ… Will analyze {len(_symbols)} symbols")
    logger.info(f"ğŸ“Š Symbols: {_symbols[:10]}...")
    
    # Initialize modules
    await trade.init()
    logger.info("âœ… Trade module initialized")
    
    # Initialize ML model
    ml_model = get_ml_model()
    logger.info("âœ… ML model initialized")
    
    # Initialize experience buffer
    experience_buffer = get_experience_buffer()
    logger.info("âœ… Experience buffer initialized")
    
    # âœ… Initialize Capital Tracker (for virtual learning account: $10,000)
    tracker = init_capital_tracker(initial_balance=10000)
    logger.info("âœ… Capital Tracker initialized with $10,000 virtual account")
    
    # Get ring buffer (attach to existing)
    ring_buffer = get_ring_buffer(create=False)
    if ring_buffer is None:
        logger.error("âŒ Failed to attach to ring buffer")
        return
    logger.info("âœ… Attached to ring buffer")
    logger.critical(f"ğŸ” Ring Buffer Diagnostic: pending={ring_buffer.pending_count()}, ready to read")
    
    try:
        candle_count = 0
        latencies = []
        symbol_index = 0
        last_pending_log = 0  # Track last pending count for diagnostic logging
        
        while True:
            # Poll for pending candles (non-blocking)
            if ring_buffer is None:
                await asyncio.sleep(0.001)
                continue
            
            pending = ring_buffer.pending_count()
            
            if pending > 0:
                last_pending_log = pending  # Update tracking
                # Read generator
                for candle in ring_buffer.read_new():
                    if candle is None:
                        break
                    
                    try:
                        # Measure latency
                        write_time = candle[0] / 1000.0  # Convert ms to seconds
                        read_time = time()
                        latency_us = (read_time - write_time) * 1_000_000
                        
                        latencies.append(latency_us)
                        
                        # Track which symbol this candle belongs to (round-robin)
                        current_symbol = _symbols[symbol_index % len(_symbols)]
                        symbol_index += 1
                        
                        # Process candle (no need to pass candles_by_tf - it's fetched from buffer)
                        await process_candle(candle, current_symbol)
                        
                        candle_count += 1
                        
                        if candle_count % 1000 == 0:
                            avg_latency = np.mean(latencies[-1000:])
                            remaining_pending = ring_buffer.pending_count()
                            logger.critical(f"ğŸ“Š Brain: {candle_count} candles | {len(_symbols)} symbols | Latency: {avg_latency:.1f}Âµs | Remaining Pending: {remaining_pending}")
                    except Exception as e:
                        logger.error(f"Error processing candle: {e}", exc_info=True)
                        continue
            else:
                # No pending candles, yield to other tasks
                if last_pending_log > 0:
                    logger.debug(f"â³ Brain waiting for data... (pending=0)")
                    last_pending_log = 0
                await asyncio.sleep(0.001)
    
    except KeyboardInterrupt:
        logger.info("â¹ï¸ Brain shutdown")
    except Exception as e:
        logger.error(f"âŒ Brain error: {e}", exc_info=True)


async def main():
    """Main brain process entry"""
    try:
        await run_brain()
    except Exception as e:
        logger.critical(f"Fatal: {e}", exc_info=True)


if __name__ == "__main__":
    """Entry point for supervisord"""
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        logger.info("ğŸ§  Brain process stopped")
    except Exception as e:
        logger.critical(f"Fatal error in Brain: {e}", exc_info=True)
